import pdfplumber
import json
import os
import re
from typing import List, Dict

print("=" * 60)
print("üéå –ü–ê–†–°–ï–† PDF –°–õ–û–í–ê–†–ï–ô HSK 1-6")
print("=" * 60)

class HSKPDFParser:
    def __init__(self):
        self.words = []
    
    def process_all_levels(self):
        """–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º HSK 1-6"""
        for level in range(1, 7):
            pdf_file = f"data/hsk{level}.pdf"
            if os.path.exists(pdf_file):
                print(f"\nüìñ –û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é HSK {level}...")
                words = self.process_pdf(pdf_file, level)
                print(f"   ‚úÖ –ù–∞–π–¥–µ–Ω–æ —Å–ª–æ–≤: {len(words)}")
                self.words.extend(words)
            else:
                print(f"\n‚ö†Ô∏è  –§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {pdf_file}")
    
    def process_pdf(self, pdf_path: str, level: int) -> List[Dict]:
        """–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –æ–¥–∏–Ω PDF —Ñ–∞–π–ª"""
        words = []
        
        try:
            with pdfplumber.open(pdf_path) as pdf:
                for page_num, page in enumerate(pdf.pages):
                    text = page.extract_text()
                    if not text:
                        continue
                    
                    # –†–∞–∑–±–∏–≤–∞–µ–º —Ç–µ–∫—Å—Ç –Ω–∞ —Å—Ç—Ä–æ–∫–∏
                    lines = text.split('\n')
                    
                    for line in lines:
                        line = line.strip()
                        if not line:
                            continue
                        
                        # –ü—Ä–æ–±—É–µ–º —Ä–∞–∑–Ω—ã–µ —Ñ–æ—Ä–º–∞—Ç—ã
                        word = self.parse_line(line, level)
                        if word:
                            words.append(word)
            
            print(f"   üìÑ –°—Ç—Ä–∞–Ω–∏—Ü –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {len(pdf.pages)}")
            
        except Exception as e:
            print(f"   ‚ùå –û—à–∏–±–∫–∞: {str(e)}")
        
        return words
    
    def parse_line(self, line: str, level: int) -> Dict:
        """–ü–∞—Ä—Å–∏–º —Å—Ç—Ä–æ–∫—É —Å –∫–∏—Ç–∞–π—Å–∫–∏–º —Å–ª–æ–≤–æ–º"""
        try:
            # –£–±–∏—Ä–∞–µ–º –ª–∏—à–Ω–∏–µ –ø—Ä–æ–±–µ–ª—ã
            line = re.sub(r'\s+', ' ', line)
            
            # –ü—ã—Ç–∞–µ–º—Å—è –Ω–∞–π—Ç–∏ –∫–∏—Ç–∞–π—Å–∫–∏–µ –∏–µ—Ä–æ–≥–ª–∏—Ñ—ã
            chinese_match = re.search(r'[\u4e00-\u9fff]+', line)
            if not chinese_match:
                return None
            
            character = chinese_match.group(0)
            
            # –ò—â–µ–º –ø–∏–Ω—å–∏–Ω—å (–ª–∞—Ç–∏–Ω—Å–∫–∏–µ –±—É–∫–≤—ã —Å —Ü–∏—Ñ—Ä–∞–º–∏-—Ç–æ–Ω–∞–º–∏)
            pinyin_match = re.search(r'[a-zA-Z√º√úƒÅ√°«é√†ƒì√©ƒõ√®ƒ´√≠«ê√¨≈ç√≥«í√≤≈´√∫«î√π«ñ«ò«ö«ú\s]+[1-5]', line)
            pinyin = pinyin_match.group(0).strip() if pinyin_match else ""
            
            # –ò—â–µ–º –ø–µ—Ä–µ–≤–æ–¥ (–≤—Å—ë –ø–æ—Å–ª–µ –ø–∏–Ω—å–∏–Ω—è –∏–ª–∏ –ø–æ—Å–ª–µ –∏–µ—Ä–æ–≥–ª–∏—Ñ–æ–≤)
            translation = ""
            if pinyin:
                # –ù–∞—Ö–æ–¥–∏–º –ø–æ–∑–∏—Ü–∏—é –ø–æ—Å–ª–µ –ø–∏–Ω—å–∏–Ω—è
                pinyin_end = pinyin_match.end()
                translation = line[pinyin_end:].strip()
            else:
                # –ï—Å–ª–∏ –Ω–µ—Ç –ø–∏–Ω—å–∏–Ω—è, –±–µ—Ä—ë–º –≤—Å—ë –ø–æ—Å–ª–µ –∏–µ—Ä–æ–≥–ª–∏—Ñ–æ–≤
                chinese_end = chinese_match.end()
                translation = line[chinese_end:].strip()
            
            # –û—á–∏—â–∞–µ–º –ø–µ—Ä–µ–≤–æ–¥
            translation = re.sub(r'[\[\]()\d]', '', translation).strip()
            translation = translation.split(';')[0].split('.')[0].strip()
            
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —á–∞—Å—Ç—å —Ä–µ—á–∏
            part_of_speech = self.detect_part_of_speech(translation)
            
            if len(character) > 0 and len(translation) > 0:
                return {
                    "character": character,
                    "pinyin": pinyin,
                    "translation": translation[:150],  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–ª–∏–Ω—É
                    "hsk_level": level,
                    "part_of_speech": part_of_speech,
                    "frequency": "È´òÈ¢ë" if level <= 3 else "‰∏≠È¢ë" if level <= 5 else "‰ΩéÈ¢ë"
                }
        
        except Exception as e:
            # print(f"–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ —Å—Ç—Ä–æ–∫–∏: {line[:30]}... - {e}")
            pass
        
        return None
    
    def detect_part_of_speech(self, translation: str) -> str:
        """–û–ø—Ä–µ–¥–µ–ª—è–µ–º —á–∞—Å—Ç—å —Ä–µ—á–∏ –ø–æ –ø–µ—Ä–µ–≤–æ–¥—É"""
        translation_lower = translation.lower()
        
        pos_patterns = {
            "–≥–ª–∞–≥–æ–ª": ["–≥–ª", "verb", "v.", "–¥–µ–ª–∞—Ç—å", "—Ö–æ–¥–∏—Ç—å", "–≥–æ–≤–æ—Ä–∏—Ç—å", "—Å–º–æ—Ç—Ä–µ—Ç—å"],
            "—Å—É—â–µ—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ–µ": ["—Å—É—â", "noun", "n.", "–ø—Ä–µ–¥–º–µ—Ç", "—á–µ–ª–æ–≤–µ–∫", "–º–µ—Å—Ç–æ", "–≤–µ—â—å"],
            "–ø—Ä–∏–ª–∞–≥–∞—Ç–µ–ª—å–Ω–æ–µ": ["–ø—Ä–∏–ª", "adjective", "adj.", "–∫—Ä–∞—Å–∏–≤—ã–π", "–±–æ–ª—å—à–æ–π", "–º–∞–ª–µ–Ω—å–∫–∏–π"],
            "–Ω–∞—Ä–µ—á–∏–µ": ["–Ω–∞—Ä", "adverb", "adv.", "–±—ã—Å—Ç—Ä–æ", "–º–µ–¥–ª–µ–Ω–Ω–æ", "—Ö–æ—Ä–æ—à–æ"],
            "–º–µ—Å—Ç–æ–∏–º–µ–Ω–∏–µ": ["–º–µ—Å—Ç", "pronoun", "pron.", "—è", "—Ç—ã", "–æ–Ω", "–æ–Ω–∞"],
            "—á–∏—Å–ª–∏—Ç–µ–ª—å–Ω–æ–µ": ["—á–∏—Å–ª", "numeral", "num.", "–æ–¥–∏–Ω", "–¥–≤–∞", "—Ç—Ä–∏", "–ø–µ—Ä–≤—ã–π"],
            "–ø—Ä–µ–¥–ª–æ–≥": ["–ø—Ä–µ–¥–ª", "preposition", "prep.", "–≤", "–Ω–∞", "–ø–æ–¥", "–Ω–∞–¥"],
            "—Å–æ—é–∑": ["—Å–æ—é–∑", "conjunction", "conj.", "–∏", "–∏–ª–∏", "–Ω–æ"],
            "—á–∞—Å—Ç–∏—Ü–∞": ["—á–∞—Å—Ç", "particle", "part.", "–∂–µ", "–ª–∏", "–±—ã"]
        }
        
        for pos, patterns in pos_patterns.items():
            for pattern in patterns:
                if pattern in translation_lower:
                    return pos
        
        return "–Ω–µ —É–∫–∞–∑–∞–Ω–æ"
    
    def save_results(self):
        """–°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã"""
        if not self.words:
            print("\n‚ùå –ù–µ –Ω–∞–π–¥–µ–Ω–æ –Ω–∏ –æ–¥–Ω–æ–≥–æ —Å–ª–æ–≤–∞!")
            return
        
        # –°–æ–∑–¥–∞–µ–º –ø–∞–ø–∫–∏
        os.makedirs("data", exist_ok=True)
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤—Å–µ —Å–ª–æ–≤–∞
        all_file = "data/hsk_all_words.json"
        with open(all_file, "w", encoding="utf-8") as f:
            json.dump(self.words, f, ensure_ascii=False, indent=2)
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø–æ —É—Ä–æ–≤–Ω—è–º
        for level in range(1, 7):
            level_words = [w for w in self.words if w["hsk_level"] == level]
            if level_words:
                level_file = f"data/hsk{level}_words.json"
                with open(level_file, "w", encoding="utf-8") as f:
                    json.dump(level_words, f, ensure_ascii=False, indent=2)
        
        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
        self.show_stats()
        
        print(f"\nüíæ –û—Å–Ω–æ–≤–Ω–æ–π —Ñ–∞–π–ª: {all_file}")
        for level in range(1, 7):
            level_words = [w for w in self.words if w["hsk_level"] == level]
            if level_words:
                print(f"üìÅ HSK {level}: {len(level_words)} —Å–ª–æ–≤ -> data/hsk{level}_words.json")
    
    def show_stats(self):
        """–ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É"""
        print("\n" + "=" * 60)
        print("üìä –°–¢–ê–¢–ò–°–¢–ò–ö–ê –ë–ê–ó–´ –î–ê–ù–ù–´–•")
        print("=" * 60)
        
        total = len(self.words)
        print(f"üéØ –í—Å–µ–≥–æ —Å–ª–æ–≤: {total}")
        
        # –ü–æ —É—Ä–æ–≤–Ω—è–º
        print("\nüìà –ü–æ —É—Ä–æ–≤–Ω—è–º HSK:")
        for level in range(1, 7):
            level_words = [w for w in self.words if w["hsk_level"] == level]
            count = len(level_words)
            percentage = (count / total * 100) if total > 0 else 0
            print(f"  HSK {level}: {count:4d} —Å–ª–æ–≤ ({percentage:.1f}%)")
        
        # –ü–æ —á–∞—Å—Ç—è–º —Ä–µ—á–∏
        print("\nüî§ –ü–æ —á–∞—Å—Ç—è–º —Ä–µ—á–∏:")
        pos_stats = {}
        for word in self.words:
            pos = word["part_of_speech"]
            pos_stats[pos] = pos_stats.get(pos, 0) + 1
        
        for pos, count in sorted(pos_stats.items(), key=lambda x: x[1], reverse=True)[:10]:
            percentage = (count / total * 100) if total > 0 else 0
            print(f"  {pos:15s}: {count:4d} —Å–ª–æ–≤ ({percentage:.1f}%)")
        
        # –ü—Ä–∏–º–µ—Ä—ã —Å–ª–æ–≤
        print("\nüìù –ü—Ä–∏–º–µ—Ä—ã —Å–ª–æ–≤:")
        for level in range(1, 4):  # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º HSK 1-3
            level_words = [w for w in self.words if w["hsk_level"] == level]
            if level_words:
                sample = level_words[:3]
                print(f"  HSK {level}: ", end="")
                for word in sample:
                    print(f"{word['character']} ({word['pinyin']}) = {word['translation'][:20]}...", end=" | ")
                print()

# –ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è
def main():
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–∞–ø–∫—É —Å PDF
    pdf_folder = "data"
    if not os.path.exists(pdf_folder):
        print(f"‚ùå –ü–∞–ø–∫–∞ '{pdf_folder}' –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç!")
        print("\nüìÅ –°–æ–∑–¥–∞–π—Ç–µ —Å—Ç—Ä—É–∫—Ç—É—Ä—É –ø–∞–ø–æ–∫:")
        print("saiyan/")
        print("‚îú‚îÄ‚îÄ data/")
        print("‚îÇ   ‚îî‚îÄ‚îÄ pdf/")
        print("‚îÇ       ‚îú‚îÄ‚îÄ hsk1.pdf")
        print("‚îÇ       ‚îú‚îÄ‚îÄ hsk2.pdf")
        print("‚îÇ       ‚îú‚îÄ‚îÄ ...")
        print("‚îÇ       ‚îî‚îÄ‚îÄ hsk6.pdf")
        print("‚îî‚îÄ‚îÄ src/")
        print("    ‚îî‚îÄ‚îÄ pdf_processor.py")
        return
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ —Ñ–∞–π–ª–æ–≤
    missing_files = []
    for level in range(1, 7):
        if not os.path.exists(f"data/hsk{level}.pdf"):
            missing_files.append(f"hsk{level}.pdf")
    
    if missing_files:
        print("‚ö†Ô∏è  –ù–µ –Ω–∞–π–¥–µ–Ω—ã —Ñ–∞–π–ª—ã:")
        for file in missing_files:
            print(f"   - {file}")
        print(f"\nüìÅ –ü–æ–ª–æ–∂–∏—Ç–µ —Ñ–∞–π–ª—ã –≤: {os.path.abspath('data')}/")
    
    # –ó–∞–ø—É—Å–∫–∞–µ–º –ø–∞—Ä—Å–µ—Ä
    parser = HSKPDFParser()
    parser.process_all_levels()
    parser.save_results()
    
    print("\n" + "=" * 60)
    print("üéâ –û–ë–†–ê–ë–û–¢–ö–ê –ó–ê–í–ï–†–®–ï–ù–ê!")
    print("=" * 60)
    print("\nüöÄ –î–ê–õ–¨–®–ï:")
    print("1. –ó–∞–ø—É—Å—Ç–∏ —Å–µ—Ä–≤–µ—Ä: python src/main.py")
    print("2. –û—Ç–∫—Ä–æ–π –≤ –±—Ä–∞—É–∑–µ—Ä–µ: http://localhost:8000")
    print("3. –¢–µ—Å—Ç–∏—Ä—É–π API: http://localhost:8000/docs")
    print("\nüìö –î–æ—Å—Ç—É–ø–Ω—ã–µ –∫–æ–º–∞–Ω–¥—ã API:")
    print("   ‚Ä¢ GET /stats - —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –±–∞–∑—ã")
    print("   ‚Ä¢ GET /search/‰Ω†Â•Ω - –ø–æ–∏—Å–∫ —Å–ª–æ–≤–∞")
    print("   ‚Ä¢ GET /test/1 - —Ç–µ—Å—Ç HSK 1")
    print("   ‚Ä¢ GET /words/level/2 - —Å–ª–æ–≤–∞ HSK 2")
    print("=" * 60)

if __name__ == "__main__":
    main()