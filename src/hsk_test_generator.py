# src/hsk_test_generator.py
import json
import random
import asyncio
from typing import Dict, List, Optional, Any, Tuple
from datetime import datetime
from openai import OpenAI
import os
from dotenv import load_dotenv
import re
import logging

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# –ó–∞–≥—Ä—É–∑–∫–∞ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è
load_dotenv()

class HSKTestGenerator:
    """AI-–≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä —Ç–µ—Å—Ç–æ–≤ HSK - –£–°–ò–õ–ï–ù–ù–ê–Ø –í–ï–†–°–ò–Ø"""
    
    def __init__(self):
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∫–ª–∏–µ–Ω—Ç–∞ DeepSeek
        api_key = os.getenv("DEEPSEEK_API_KEY")
        if api_key:
            self.client = OpenAI(
                api_key=api_key,
                base_url="https://api.deepseek.com"
            )
            self.ai_enabled = True
            logger.info("‚úÖ DeepSeek AI –≤–∫–ª—é—á–µ–Ω")
        else:
            self.client = None
            self.ai_enabled = False
            logger.warning("‚ö†Ô∏è DeepSeek API –∫–ª—é—á –Ω–µ –Ω–∞–π–¥–µ–Ω. –†–∞–±–æ—Ç–∞ –≤ –æ—Ñ—Ñ–ª–∞–π–Ω-—Ä–µ–∂–∏–º–µ.")
        
        # –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö
        self.all_words = self.load_all_words()
        self.grammar_topics = self.load_grammar_topics()
        
        # HSK 3.0 —Å—Ç–∞–Ω–¥–∞—Ä—Ç—ã
        self.hsk_standards = {
            1: {"words": 500, "chars": 300, "test_time": 40, "score": 200},
            2: {"words": 1272, "chars": 600, "test_time": 55, "score": 200},
            3: {"words": 2245, "chars": 900, "test_time": 85, "score": 300},
            4: {"words": 3245, "chars": 1200, "test_time": 100, "score": 300},
            5: {"words": 4316, "chars": 1500, "test_time": 120, "score": 300},
            6: {"words": 5456, "chars": 1800, "test_time": 135, "score": 300}
        }
        
        # –¢–∏–ø—ã –≤–æ–ø—Ä–æ—Å–æ–≤ –ø–æ —É—Ä–æ–≤–Ω—è–º
        self.question_types_by_level = {
            1: ["single_choice", "matching", "picture_choice"],
            2: ["single_choice", "matching", "sentence_formation"],
            3: ["single_choice", "short_answer", "dialogue", "sentence_reorder"],
            4: ["single_choice", "reading_comprehension", "dialogue", "short_essay"],
            5: ["reading_comprehension", "essay", "dialogue_analysis", "gap_filling"],
            6: ["reading_comprehension", "argumentative_essay", "translation", "summarization"]
        }
        
        logger.info(f"‚úÖ –ó–∞–≥—Ä—É–∑–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞: {len(self.all_words)} —Å–ª–æ–≤, {len(self.grammar_topics)} –≥—Ä–∞–º–º–∞—Ç–∏—á–µ—Å–∫–∏—Ö —Ç–µ–º")
    
    def load_all_words(self) -> List[Dict]:
        """–ó–∞–≥—Ä—É–∑–∫–∞ –≤—Å–µ—Ö —Å–ª–æ–≤ HSK"""
        words = []
        try:
            # –ü—Ä–æ–±—É–µ–º —Ä–∞–∑–Ω—ã–µ —Ñ–∞–π–ª—ã
            files_to_try = [
                "data/hsk_all_words.json",
                "data/hsk_words.json",
                "data/words.json"
            ]
            
            for file_path in files_to_try:
                if os.path.exists(file_path):
                    with open(file_path, "r", encoding="utf-8") as f:
                        words = json.load(f)
                    logger.info(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(words)} —Å–ª–æ–≤ –∏–∑ {file_path}")
                    
                    # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ —É—Ä–æ–≤–Ω—è–º
                    level_stats = {}
                    for word in words:
                        level = word.get("hsk_level", 0)
                        level_stats[level] = level_stats.get(level, 0) + 1
                    
                    logger.info(f"üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ —É—Ä–æ–≤–Ω—è–º: {level_stats}")
                    break
            
            if not words:
                logger.error("‚ùå –§–∞–π–ª—ã —Å–æ —Å–ª–æ–≤–∞–º–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã")
                words = self.create_sample_words()
        
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ —Å–ª–æ–≤: {e}")
            words = self.create_sample_words()
        
        # –î–æ–±–∞–≤–ª—è–µ–º ID
        for i, word in enumerate(words):
            if "id" not in word:
                word["id"] = f"word_{word.get('hsk_level', 1)}_{i}"
        
        return words
    
    def create_sample_words(self) -> List[Dict]:
        """–°–æ–∑–¥–∞–Ω–∏–µ –ø—Ä–∏–º–µ—Ä–Ω—ã—Ö —Å–ª–æ–≤ –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è"""
        sample_words = [
            {"character": "‰Ω†Â•Ω", "pinyin": "n«ê h«éo", "translation": "–ø—Ä–∏–≤–µ—Ç", "hsk_level": 1},
            {"character": "Ë∞¢Ë∞¢", "pinyin": "xi√® xie", "translation": "—Å–ø–∞—Å–∏–±–æ", "hsk_level": 1},
            {"character": "Â≠¶‰π†", "pinyin": "xu√© x√≠", "translation": "—É—á–∏—Ç—å—Å—è", "hsk_level": 1},
            {"character": "ÊúãÂèã", "pinyin": "p√©ng you", "translation": "–¥—Ä—É–≥", "hsk_level": 2},
            {"character": "ÂÆ∂Â∫≠", "pinyin": "jiƒÅ t√≠ng", "translation": "—Å–µ–º—å—è", "hsk_level": 2},
            {"character": "ÂèëÂ±ï", "pinyin": "fƒÅ zh«én", "translation": "—Ä–∞–∑–≤–∏—Ç–∏–µ", "hsk_level": 3},
            {"character": "Á§æ‰ºö", "pinyin": "sh√® hu√¨", "translation": "–æ–±—â–µ—Å—Ç–≤–æ", "hsk_level": 4},
            {"character": "ÁªèÊµé", "pinyin": "jƒ´ng j√¨", "translation": "—ç–∫–æ–Ω–æ–º–∏–∫–∞", "hsk_level": 5},
            {"character": "ÂÖ®ÁêÉÂåñ", "pinyin": "qu√°n qi√∫ hu√†", "translation": "–≥–ª–æ–±–∞–ª–∏–∑–∞—Ü–∏—è", "hsk_level": 6},
        ]
        logger.warning("‚ö†Ô∏è –ò—Å–ø–æ–ª—å–∑—É—é –ø—Ä–∏–º–µ—Ä–Ω—ã–µ —Å–ª–æ–≤–∞ (—Ñ–∞–π–ª—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã)")
        return sample_words
    
    def load_grammar_topics(self) -> List[Dict]:
        """–ó–∞–≥—Ä—É–∑–∫–∞ –≥—Ä–∞–º–º–∞—Ç–∏—á–µ—Å–∫–∏—Ö —Ç–µ–º"""
        try:
            with open("data/grammar_topics.json", "r", encoding="utf-8") as f:
                topics = json.load(f)
            logger.info(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(topics)} –≥—Ä–∞–º–º–∞—Ç–∏—á–µ—Å–∫–∏—Ö —Ç–µ–º")
            return topics
        except FileNotFoundError:
            logger.warning("‚ö†Ô∏è –§–∞–π–ª grammar_topics.json –Ω–µ –Ω–∞–π–¥–µ–Ω")
            return []
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –≥—Ä–∞–º–º–∞—Ç–∏–∫–∏: {e}")
            return []
    
    def get_words_by_level(self, level: int, max_count: int = 100) -> List[Dict]:
        """–ü–æ–ª—É—á–∏—Ç—å —Å–ª–æ–≤–∞ –ø–æ —É—Ä–æ–≤–Ω—é HSK"""
        return [w for w in self.all_words if w.get("hsk_level") == level][:max_count]
    
    def get_grammar_by_level(self, level: int) -> List[Dict]:
        """–ü–æ–ª—É—á–∏—Ç—å –≥—Ä–∞–º–º–∞—Ç–∏–∫—É –ø–æ —É—Ä–æ–≤–Ω—é HSK"""
        level_mapping = {
            1: ["Âàù", "HSK1-2", "beginner"],
            2: ["Âàù", "HSK1-2", "beginner"],
            3: ["‰∏≠", "HSK3-4", "intermediate"],
            4: ["‰∏≠", "HSK3-4", "intermediate"],
            5: ["È´ò", "HSK5-6", "advanced"],
            6: ["È´ò", "HSK5-6", "advanced"]
        }
        target_levels = level_mapping.get(level, ["Âàù"])
        return [g for g in self.grammar_topics if g.get("level") in target_levels]
    
    async def generate_ai_questions(self, level: int, section: str, count: int, context: str = "") -> List[Dict]:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ç–µ—Å—Ç–æ–≤—ã—Ö –≤–æ–ø—Ä–æ—Å–æ–≤ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º AI (–£–°–ò–õ–ï–ù–ù–ê–Ø –í–ï–†–°–ò–Ø)"""
        
        # –ï—Å–ª–∏ AI –æ—Ç–∫–ª—é—á–µ–Ω, —Å—Ä–∞–∑—É –ø–µ—Ä–µ—Ö–æ–¥–∏–º –∫ –æ—Ñ—Ñ–ª–∞–π–Ω-–≥–µ–Ω–µ—Ä–∞—Ü–∏–∏
        if not self.ai_enabled or not self.client:
            logger.warning(f"‚ö†Ô∏è AI –æ—Ç–∫–ª—é—á–µ–Ω, –∏—Å–ø–æ–ª—å–∑—É—é –æ—Ñ—Ñ–ª–∞–π–Ω-–≥–µ–Ω–µ—Ä–∞—Ü–∏—é –¥–ª—è {section}")
            return await self.generate_offline_questions(level, section, count)
        
        try:
            # –®–∞–≥ 1: –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –ø—Ä–æ–º–ø—Ç–∞
            prompt = self.build_enhanced_ai_prompt(level, section, count, context)
            
            # –®–∞–≥ 2: –ó–∞–ø—Ä–æ—Å –∫ AI —Å –ø–æ–≤—Ç–æ—Ä–Ω—ã–º–∏ –ø–æ–ø—ã—Ç–∫–∞–º–∏
            max_retries = 3
            for attempt in range(max_retries):
                try:
                    logger.info(f"ü§ñ –ó–∞–ø—Ä–æ—Å –∫ AI (–ø–æ–ø—ã—Ç–∫–∞ {attempt + 1}/{max_retries}) –¥–ª—è HSK{level} {section}")
                    
                    response = await asyncio.to_thread(
                        self.client.chat.completions.create,
                        model="deepseek-chat",
                        messages=[
                            {"role": "system", "content": "–¢—ã —ç–∫—Å–ø–µ—Ä—Ç –ø–æ —Å–æ–∑–¥–∞–Ω–∏—é —Ç–µ—Å—Ç–æ–≤ HSK. –°—Ç—Ä–æ–≥–æ —Å–ª–µ–¥—É–π —Ñ–æ—Ä–º–∞—Ç—É JSON."},
                            {"role": "user", "content": prompt}
                        ],
                        temperature=0.7,
                        max_tokens=4000,
                        response_format={"type": "json_object"}
                    )
                    
                    content = response.choices[0].message.content
                    logger.debug(f"üìÑ –ü–æ–ª—É—á–µ–Ω –æ—Ç–≤–µ—Ç –æ—Ç AI: {content[:200]}...")
                    
                    # –®–∞–≥ 3: –ü–∞—Ä—Å–∏–Ω–≥ –æ—Ç–≤–µ—Ç–∞
                    questions = self.parse_enhanced_ai_response(content, section, level)
                    
                    if questions and len(questions) >= min(count, 3):
                        logger.info(f"‚úÖ –£—Å–ø–µ—à–Ω–æ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–æ {len(questions)} –≤–æ–ø—Ä–æ—Å–æ–≤")
                        return questions
                    else:
                        logger.warning(f"‚ö†Ô∏è AI –≤–µ—Ä–Ω—É–ª –Ω–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –≤–æ–ø—Ä–æ—Å–æ–≤ ({len(questions) if questions else 0})")
                        
                except Exception as e:
                    logger.error(f"‚ùå –û—à–∏–±–∫–∞ AI (–ø–æ–ø—ã—Ç–∫–∞ {attempt + 1}): {e}")
                    if attempt < max_retries - 1:
                        await asyncio.sleep(1)  # –ü–∞—É–∑–∞ –ø–µ—Ä–µ–¥ –ø–æ–≤—Ç–æ—Ä–Ω–æ–π –ø–æ–ø—ã—Ç–∫–æ–π
                    continue
            
            # –ï—Å–ª–∏ –≤—Å–µ –ø–æ–ø—ã—Ç–∫–∏ –Ω–µ —É–¥–∞–ª–∏—Å—å
            logger.error("‚ùå –í—Å–µ –ø–æ–ø—ã—Ç–∫–∏ AI –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –ø—Ä–æ–≤–∞–ª–∏–ª–∏—Å—å, –ø–µ—Ä–µ–∫–ª—é—á–∞—é—Å—å –Ω–∞ –æ—Ñ—Ñ–ª–∞–π–Ω-—Ä–µ–∂–∏–º")
            return await self.generate_offline_questions(level, section, count)
            
        except Exception as e:
            logger.error(f"‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –≤ AI –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏: {e}")
            return await self.generate_offline_questions(level, section, count)
    
    def build_enhanced_ai_prompt(self, level: int, section: str, count: int, context: str) -> str:
        """–°–æ–∑–¥–∞–Ω–∏–µ –£–°–ò–õ–ï–ù–ù–û–ì–û –ø—Ä–æ–º–ø—Ç–∞ –¥–ª—è AI"""
        
        # –ü–æ–ª—É—á–∞–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
        level_words = self.get_words_by_level(level, 30)
        grammar_points = self.get_grammar_by_level(level)[:5]
        
        # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º –ø—Ä–∏–º–µ—Ä—ã
        word_examples = "\n".join([f"- {w['character']} ({w['pinyin']}): {w['translation']}" 
                                  for w in level_words[:10]])
        
        # –ë–∞–∑–æ–≤—ã–π –ø—Ä–æ–º–ø—Ç
        prompt = f"""–ó–ê–î–ê–ù–ò–Ø –î–û–õ–ñ–ù–´ –ü–û–õ–ù–û–°–¢–¨–Æ –°–û–û–¢–í–ï–¢–°–¢–í–û–í–ê–¢–¨ {level} HSK, –¢—ã —ç–∫—Å–ø–µ—Ä—Ç –ø–æ —Å–æ–∑–¥–∞–Ω–∏—é —Ç–µ—Å—Ç–æ–≤ HSK (Ê±âËØ≠Ê∞¥Âπ≥ËÄÉËØï). –°–≥–µ–Ω–µ—Ä–∏—Ä—É–π {count} –í–´–°–û–ö–û–ö–ê–ß–ï–°–¢–í–ï–ù–ù–´–• –≤–æ–ø—Ä–æ—Å–æ–≤ –¥–ª—è HSK {level}, —Ä–∞–∑–¥–µ–ª: {section}.

–¢–†–ï–ë–û–í–ê–ù–ò–Ø –ö –ö–ê–ß–ï–°–¢–í–£:
1. –ê—É—Ç–µ–Ω—Ç–∏—á–Ω–æ—Å—Ç—å: –≤–æ–ø—Ä–æ—Å—ã –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ –±–ª–∏–∑–∫–∏ –∫ —Ä–µ–∞–ª—å–Ω—ã–º —Ç–µ—Å—Ç–∞–º HSK
2. –£—Ä–æ–≤–µ–Ω—å —Å–ª–æ–∂–Ω–æ—Å—Ç–∏: —Å—Ç—Ä–æ–≥–æ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç HSK {level}
3. –†–∞–∑–Ω–æ–æ–±—Ä–∞–∑–∏–µ: —Ä–∞–∑–Ω—ã–µ —Ç–µ–º—ã, —Å–∏—Ç—É–∞—Ü–∏–∏, —è–∑—ã–∫–æ–≤—ã–µ –∫–æ–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏
4. –û–±—É—á–∞—é—â–∞—è —Ü–µ–Ω–Ω–æ—Å—Ç—å: –≤–æ–ø—Ä–æ—Å—ã –¥–æ–ª–∂–Ω—ã –ø—Ä–æ–≤–µ—Ä—è—Ç—å –ø–æ–Ω–∏–º–∞–Ω–∏–µ, –∞ –Ω–µ –ø—Ä–æ—Å—Ç–æ –ø–∞–º—è—Ç—å
5. –ß–µ—Ç–∫–æ—Å—Ç—å: —Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∫–∏ —è—Å–Ω—ã–µ, –æ–¥–Ω–æ–∑–Ω–∞—á–Ω—ã–µ

–ö–û–ù–¢–ï–ö–°–¢ –î–õ–Ø –°–û–ó–î–ê–ù–ò–Ø –í–û–ü–†–û–°–û–í:
- –£—Ä–æ–≤–µ–Ω—å: HSK {level}
- –°–ª–æ–≤–∞—Ä—å –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è: {word_examples}
- –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –≤–æ–ø—Ä–æ—Å–æ–≤: {count}

–í–ê–ñ–ù–û:
- –í–°–ï–ì–î–ê –≤–æ–∑–≤—Ä–∞—â–∞–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç –≤ —Ñ–æ—Ä–º–∞—Ç–µ VALID JSON
- –ö–∞–∂–¥—ã–π –≤–æ–ø—Ä–æ—Å –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –ø–æ–ª–Ω—ã–º –∏ —Å–∞–º–æ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω—ã–º
- –ù–µ –∏—Å–ø–æ–ª—å–∑—É–π markdown, —Ç–æ–ª—å–∫–æ —á–∏—Å—Ç—ã–π JSON
"""
        
        # –°–ø–µ—Ü–∏—Ñ–∏—á–Ω—ã–µ –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —Ä–∞–∑–¥–µ–ª–∞
        if section == "listening":
            prompt += f"""
–ó–ê–î–ê–ù–ò–ï –î–õ–Ø –ê–£–î–ò–†–û–í–ê–ù–ò–Ø:
–°–æ–∑–¥–∞–π {count} –≤–æ–ø—Ä–æ—Å–æ–≤ –¥–ª—è –∞—É–¥–∏—Ä–æ–≤–∞–Ω–∏—è HSK {level}.

–°–¢–†–£–ö–¢–£–†–ê –ö–ê–ñ–î–û–ì–û –í–û–ü–†–û–°–ê:
{{
  "id": "L1",
  "audio_text": "–ö–æ—Ä–æ—Ç–∫–∏–π –¥–∏–∞–ª–æ–≥ –∏–ª–∏ –º–æ–Ω–æ–ª–æ–≥ (2-4 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è, –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω—ã–π —è–∑—ã–∫)",
  "question": "–í–æ–ø—Ä–æ—Å –Ω–∞ —Ä—É—Å—Å–∫–æ–º, –ø—Ä–æ–≤–µ—Ä—è—é—â–∏–π –ø–æ–Ω–∏–º–∞–Ω–∏–µ –∞—É–¥–∏–æ",
  "options": ["–í–∞—Ä–∏–∞–Ω—Ç A", "–í–∞—Ä–∏–∞–Ω—Ç B", "–í–∞—Ä–∏–∞–Ω—Ç C", "–í–∞—Ä–∏–∞–Ω—Ç D"],
  "correct_index": 0,
  "explanation": "–ö—Ä–∞—Ç–∫–æ–µ –æ–±—ä—è—Å–Ω–µ–Ω–∏–µ, –ø–æ—á–µ–º—É —ç—Ç–æ—Ç –æ—Ç–≤–µ—Ç –ø—Ä–∞–≤–∏–ª—å–Ω—ã–π"
}}

–ü–†–ò–ú–ï–†–´ –¢–ï–ú –î–õ–Ø HSK {level}:
- –†–∞—Å–ø–∏—Å–∞–Ω–∏–µ (–≤—Ä–µ–º—è, –¥–Ω–∏ –Ω–µ–¥–µ–ª–∏)
- –ü–æ–∫—É–ø–∫–∏ (—Ü–µ–Ω—ã, –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ)
- –°–µ–º—å—è –∏ –¥—Ä—É–∑—å—è
- –ï–¥–∞ –∏ –Ω–∞–ø–∏—Ç–∫–∏
- –•–æ–±–±–∏ –∏ –∏–Ω—Ç–µ—Ä–µ—Å—ã
- –ü–æ–≥–æ–¥–∞ –∏ –≤—Ä–µ–º–µ–Ω–∞ –≥–æ–¥–∞
- –¢—Ä–∞–Ω—Å–ø–æ—Ä—Ç –∏ –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏—è

–ì–ï–ù–ï–†–ò–†–£–ô –†–ê–ó–ù–û–û–ë–†–ê–ó–ù–´–ï –°–¶–ï–ù–ê–†–ò–ò!
"""
        
        elif section == "reading":
            prompt += f"""
–ó–ê–î–ê–ù–ò–ï –î–õ–Ø –ß–¢–ï–ù–ò–Ø:
–°–æ–∑–¥–∞–π {count} –≤–æ–ø—Ä–æ—Å–æ–≤ –¥–ª—è —á—Ç–µ–Ω–∏—è HSK {level}.

–¢–ò–ü–´ –¢–ï–ö–°–¢–û–í –î–õ–Ø HSK {level}:
- –û–±—ä—è–≤–ª–µ–Ω–∏—è (–≤ —à–∫–æ–ª–µ, –º–∞–≥–∞–∑–∏–Ω–µ, —Ç—Ä–∞–Ω—Å–ø–æ—Ä—Ç–µ)
- –ö–æ—Ä–æ—Ç–∫–∏–µ —Å–æ–æ–±—â–µ–Ω–∏—è (—ç–ª–µ–∫—Ç—Ä–æ–Ω–Ω–∞—è –ø–æ—á—Ç–∞, SMS)
- –ü—Ä–æ—Å—Ç—ã–µ —Ä–∞—Å—Å–∫–∞–∑—ã
- –û–ø–∏—Å–∞–Ω–∏—è –ø—Ä–µ–¥–º–µ—Ç–æ–≤ –∏–ª–∏ –ª—é–¥–µ–π
- –†–∞—Å–ø–∏—Å–∞–Ω–∏—è –∏ –ø–ª–∞–Ω—ã

–°–¢–†–£–ö–¢–£–†–ê –ö–ê–ñ–î–û–ì–û –í–û–ü–†–û–°–ê:
{{
  "id": "R1",
  "text": "–ö–æ—Ä–æ—Ç–∫–∏–π —Ç–µ–∫—Å—Ç –Ω–∞ –∫–∏—Ç–∞–π—Å–∫–æ–º (3-8 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π)",
  "question": "–í–æ–ø—Ä–æ—Å –Ω–∞ —Ä—É—Å—Å–∫–æ–º –æ —Å–æ–¥–µ—Ä–∂–∞–Ω–∏–∏ —Ç–µ–∫—Å—Ç–∞",
  "options": ["–í–∞—Ä–∏–∞–Ω—Ç A", "–í–∞—Ä–∏–∞–Ω—Ç B", "–í–∞—Ä–∏–∞–Ω—Ç C", "–í–∞—Ä–∏–∞–Ω—Ç D"],
  "correct_index": 0,
  "explanation": "–ö—Ä–∞—Ç–∫–æ–µ –æ–±—ä—è—Å–Ω–µ–Ω–∏–µ —Å —É–∫–∞–∑–∞–Ω–∏–µ–º –º–µ—Å—Ç–∞ –≤ —Ç–µ–∫—Å—Ç–µ"
}}

–¢–ï–ú–´ –î–õ–Ø –¢–ï–ö–°–¢–û–í:
- –ü–æ–≤—Å–µ–¥–Ω–µ–≤–Ω–∞—è –∂–∏–∑–Ω—å
- –û–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –∏ —É—á–µ–±–∞
- –ö—É–ª—å—Ç—É—Ä–∞ –∏ —Ç—Ä–∞–¥–∏—Ü–∏–∏
- –ù–∞—É–∫–∞ –∏ —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–∏
- –ó–¥–æ—Ä–æ–≤—å–µ –∏ —Å–ø–æ—Ä—Ç
"""
        
        else:  # writing
            prompt += f"""
–ó–ê–î–ê–ù–ò–ï –î–õ–Ø –ü–ò–°–¨–ú–ê:
–°–æ–∑–¥–∞–π {count} –∑–∞–¥–∞–Ω–∏–π –¥–ª—è –ø–∏—Å—å–º–µ–Ω–Ω–æ–π —á–∞—Å—Ç–∏ HSK {level}.

–¢–ò–ü–´ –ó–ê–î–ê–ù–ò–ô –î–õ–Ø HSK {level}:
- –ù–∞–ø–∏—Å–∞–Ω–∏–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π –ø–æ –∫–∞—Ä—Ç–∏–Ω–∫–µ
- –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –∑–∞–¥–∞–Ω–Ω—ã—Ö —Å–ª–æ–≤ –≤ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–∏
- –ö–æ—Ä–æ—Ç–∫–∏–π —Ä–∞—Å—Å–∫–∞–∑ (–¥–ª—è —É—Ä–æ–≤–Ω–µ–π 3+)
- –û–ø–∏—Å–∞–Ω–∏–µ –≥—Ä–∞—Ñ–∏–∫–∞ –∏–ª–∏ —Ç–∞–±–ª–∏—Ü—ã (–¥–ª—è —É—Ä–æ–≤–Ω–µ–π 4+)
- –ú–Ω–µ–Ω–∏–µ –ø–æ –≤–æ–ø—Ä–æ—Å—É (–¥–ª—è —É—Ä–æ–≤–Ω–µ–π 5+)

–°–¢–†–£–ö–¢–£–†–ê –ö–ê–ñ–î–û–ì–û –ó–ê–î–ê–ù–ò–Ø:
{{
  "id": "W1",
  "task": "–ß–µ—Ç–∫–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ –∑–∞–¥–∞–Ω–∏—è –Ω–∞ —Ä—É—Å—Å–∫–æ–º",
  "requirements": "–¢—Ä–µ–±–æ–≤–∞–Ω–∏—è (—Å–ª–æ–≤–∞, –¥–ª–∏–Ω–∞, –≤—Ä–µ–º—è)",
  "example_response": "–ü—Ä–∏–º–µ—Ä –ø—Ä–∞–≤–∏–ª—å–Ω–æ–≥–æ –æ—Ç–≤–µ—Ç–∞",
  "evaluation_criteria": ["–ö—Ä–∏—Ç–µ—Ä–∏–π 1", "–ö—Ä–∏—Ç–µ—Ä–∏–π 2", "–ö—Ä–∏—Ç–µ—Ä–∏–π 3"]
}}

–¢–†–ï–ë–û–í–ê–ù–ò–Ø –ö –î–õ–ò–ù–ï –î–õ–Ø HSK {level}:
- HSK 1-2: 1-2 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è
- HSK 3: 3-5 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π
- HSK 4: 80-100 –∏–µ—Ä–æ–≥–ª–∏—Ñ–æ–≤
- HSK 5: 120-150 –∏–µ—Ä–æ–≥–ª–∏—Ñ–æ–≤
- HSK 6: 180-200 –∏–µ—Ä–æ–≥–ª–∏—Ñ–æ–≤
"""
        
        # –§–∏–Ω–∞–ª—å–Ω–∞—è –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏—è –ø–æ —Ñ–æ—Ä–º–∞—Ç—É
        prompt += f"""

–§–û–†–ú–ê–¢ –í–û–ó–í–†–ê–©–ê–ï–ú–´–• –î–ê–ù–ù–´–•:
–¢—ã –¥–æ–ª–∂–µ–Ω –≤–µ—Ä–Ω—É—Ç—å –í–ê–õ–ò–î–ù–´–ô JSON –º–∞—Å—Å–∏–≤ —Å {count} –æ–±—ä–µ–∫—Ç–∞–º–∏. –ù–∞–ø—Ä–∏–º–µ—Ä:
[
  {{
    "id": "L1",
    "audio_text": "...",
    "question": "...",
    "options": ["...", "...", "...", "..."],
    "correct_index": 0,
    "explanation": "..."
  }},
  // ... –µ—â–µ {count-1} –≤–æ–ø—Ä–æ—Å–æ–≤
]

–í–ê–ñ–ù–û: –í–µ—Ä–Ω–∏ –¢–û–õ–¨–ö–û JSON, –±–µ–∑ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞!
"""
        
        return prompt
    
    def parse_enhanced_ai_response(self, content: str, section: str, level: int) -> List[Dict]:
        """–ü–∞—Ä—Å–∏–Ω–≥ –æ—Ç–≤–µ—Ç–∞ –æ—Ç AI —Å —É–ª—É—á—à–µ–Ω–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–æ–π –æ—à–∏–±–æ–∫ –∏ —Ñ–∏–∫—Å–∞–º–∏ –±–∏—Ç–æ–≥–æ JSON"""
        try:
            # –û—á–∏—Å—Ç–∫–∞ –∫–æ–Ω—Ç–µ–Ω—Ç–∞ –æ—Ç –≤–æ–∑–º–æ–∂–Ω—ã—Ö –ª–∏—à–Ω–∏—Ö —Å–∏–º–≤–æ–ª–æ–≤
            content = content.strip()
            
            # –£–¥–∞–ª—è–µ–º markdown –∫–æ–¥–æ–≤—ã–µ –±–ª–æ–∫–∏ –µ—Å–ª–∏ –µ—Å—Ç—å
            if content.startswith("```json"):
                content = content[7:]
            if content.endswith("```"):
                content = content[:-3]
            content = content.strip()
            
            # –§–ò–ö–° –î–õ–Ø –ë–ò–¢–û–ì–û JSON: –ò—â–µ–º –∏ –∏—Å–ø—Ä–∞–≤–ª—è–µ–º –Ω–µ–∑–∞–∫—Ä—ã—Ç—ã–µ –∫–∞–≤—ã—á–∫–∏
            content = self.fix_broken_json(content)
            
            logger.debug(f"üìÑ –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã–π –∫–æ–Ω—Ç–µ–Ω—Ç (–ø–µ—Ä–≤—ã–µ 500 —Å–∏–º–≤–æ–ª–æ–≤): {content[:500]}")
            
            # –ü—ã—Ç–∞–µ–º—Å—è –ø–∞—Ä—Å–∏—Ç—å JSON
            data = json.loads(content)
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É –¥–∞–Ω–Ω—ã—Ö
            questions = []
            if isinstance(data, list):
                questions = data
            elif isinstance(data, dict) and "questions" in data:
                questions = data["questions"]
            elif isinstance(data, dict) and any(key in data for key in ["listening", "reading", "writing"]):
                questions = data.get(section, [])
            else:
                logger.warning(f"‚ö†Ô∏è –ù–µ–æ–∂–∏–¥–∞–Ω–Ω–∞—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∞ –¥–∞–Ω–Ω—ã—Ö –æ—Ç AI: {type(data)}")
                return []
            
            # –í–∞–ª–∏–¥–∞—Ü–∏—è –∏ –æ–±–æ–≥–∞—â–µ–Ω–∏–µ –≤–æ–ø—Ä–æ—Å–æ–≤
            validated_questions = []
            for i, q in enumerate(questions):
                try:
                    # –ë–∞–∑–æ–≤—ã–µ –ø—Ä–æ–≤–µ—Ä–∫–∏
                    if not isinstance(q, dict):
                        continue
                    
                    # –î–æ–±–∞–≤–ª—è–µ–º –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ –ø–æ–ª—è
                    q["id"] = q.get("id", f"{section[0].upper()}{i+1}")
                    
                    # –î–ª—è listening/reading –ø—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –æ–ø—Ü–∏–π
                    if section in ["listening", "reading"]:
                        if "options" not in q or not isinstance(q["options"], list):
                            q["options"] = ["–í–∞—Ä–∏–∞–Ω—Ç A", "–í–∞—Ä–∏–∞–Ω—Ç B", "–í–∞—Ä–∏–∞–Ω—Ç C", "–í–∞—Ä–∏–∞–Ω—Ç D"]
                        
                        if len(q["options"]) < 4:
                            q["options"] = q["options"] + ["–î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–π –≤–∞—Ä–∏–∞–Ω—Ç"] * (4 - len(q["options"]))
                        
                        if "correct_index" not in q or not isinstance(q["correct_index"], int):
                            q["correct_index"] = 0
                        
                        if q["correct_index"] >= len(q["options"]):
                            q["correct_index"] = 0
                    
                    # –î–ª—è writing –ø—Ä–æ–≤–µ—Ä—è–µ–º –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ –ø–æ–ª—è
                    if section == "writing":
                        required_fields = ["task", "requirements"]
                        for field in required_fields:
                            if field not in q:
                                q[field] = "–ù–µ —É–∫–∞–∑–∞–Ω–æ"
                        
                        if "evaluation_criteria" not in q or not isinstance(q["evaluation_criteria"], list):
                            q["evaluation_criteria"] = ["–ì—Ä–∞–º–º–∞—Ç–∏–∫–∞", "–°–ª–æ–≤–∞—Ä–Ω—ã–π –∑–∞–ø–∞—Å", "–°–æ–¥–µ—Ä–∂–∞–Ω–∏–µ"]
                    
                    validated_questions.append(q)
                    
                except Exception as e:
                    logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–∏ –≤–æ–ø—Ä–æ—Å–∞ {i}: {e}")
                    continue
            
            logger.info(f"‚úÖ –£—Å–ø–µ—à–Ω–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ {len(validated_questions)} –≤–æ–ø—Ä–æ—Å–æ–≤ –∏–∑ {len(questions)}")
            return validated_questions
            
        except json.JSONDecodeError as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ JSON –æ—Ç AI: {e}")
            logger.debug(f"–°–æ–¥–µ—Ä–∂–∏–º–æ–µ –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏ (–ø–µ—Ä–≤—ã–µ 1000 —Å–∏–º–≤–æ–ª–æ–≤): {content[:1000]}")
            
            # –ü–æ–ø—ã—Ç–∫–∞ –∏–∑–≤–ª–µ—á—å JSON —Å –ø–æ–º–æ—â—å—é —Ä–µ–≥—É–ª—è—Ä–Ω—ã—Ö –≤—ã—Ä–∞–∂–µ–Ω–∏–π
            json_match = re.search(r'\[\s*{.*}\s*\]', content, re.DOTALL)
            if json_match:
                try:
                    json_str = json_match.group()
                    logger.info(f"üîç –ù–∞–π–¥–µ–Ω JSON —á–µ—Ä–µ–∑ regex: {len(json_str)} —Å–∏–º–≤–æ–ª–æ–≤")
                    # –ï—â–µ —Ä–∞–∑ –ø–æ–ø—Ä–æ–±—É–µ–º –ø–æ—á–∏–Ω–∏—Ç—å
                    json_str = self.fix_broken_json(json_str)
                    return json.loads(json_str)
                except Exception as e2:
                    logger.error(f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–∞—Ä—Å–∏—Ç—å –¥–∞–∂–µ regex JSON: {e2}")
            
            # –ü–æ—Å–ª–µ–¥–Ω—è—è –ø–æ–ø—ã—Ç–∫–∞: –Ω–∞–π—Ç–∏ –ª—é–±–æ–π –ø–æ—Ö–æ–∂–∏–π –Ω–∞ JSON —Ç–µ–∫—Å—Ç
            try:
                # –ò—â–µ–º –æ—Ç–∫—Ä—ã–≤–∞—é—â—É—é —Å–∫–æ–±–∫—É –∏ –±–µ—Ä–µ–º –¥–æ –∫–æ–Ω—Ü–∞
                start = content.find('[')
                if start != -1:
                    # –ë–µ—Ä–µ–º –æ—Ç –æ—Ç–∫—Ä—ã–≤–∞—é—â–µ–π —Å–∫–æ–±–∫–∏ –¥–æ –∫–æ–Ω—Ü–∞
                    potential_json = content[start:]
                    potential_json = self.fix_broken_json(potential_json)
                    return json.loads(potential_json)
            except:
                pass
            
            return []
        
        except Exception as e:
            logger.error(f"‚ùå –ù–µ–æ–∂–∏–¥–∞–Ω–Ω–∞—è –æ—à–∏–±–∫–∞ –ø—Ä–∏ –ø–∞—Ä—Å–∏–Ω–≥–µ: {e}")
            return []

    def fix_broken_json(self, json_str: str) -> str:
        """–ò—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –±–∏—Ç–æ–≥–æ JSON —Å –Ω–µ–∑–∞–∫—Ä—ã—Ç—ã–º–∏ –∫–∞–≤—ã—á–∫–∞–º–∏ –∏ –¥—Ä—É–≥–∏–º–∏ –æ—à–∏–±–∫–∞–º–∏"""
        try:
            # –§—É–Ω–∫—Ü–∏—è –¥–ª—è –∑–∞–∫—Ä—ã—Ç–∏—è –Ω–µ–∑–∞–∫—Ä—ã—Ç—ã—Ö –∫–∞–≤—ã—á–µ–∫ –≤–Ω—É—Ç—Ä–∏ —Å—Ç—Ä–æ–∫
            def fix_unterminated_strings(text):
                import re
                # –ò—â–µ–º –Ω–µ–∑–∞–∫—Ä—ã—Ç—ã–µ –¥–≤–æ–π–Ω—ã–µ –∫–∞–≤—ã—á–∫–∏
                pattern = r'"([^"\\]*(?:\\.[^"\\]*)*)'
                matches = list(re.finditer(pattern, text))
                
                result = text
                fixed = False
                
                # –ü—Ä–æ—Ö–æ–¥–∏–º –ø–æ –≤—Å–µ–º —Å—Ç—Ä–æ–∫–∞–º –∏ –ø—Ä–æ–≤–µ—Ä—è–µ–º –±–∞–ª–∞–Ω—Å –∫–∞–≤—ã—á–µ–∫
                lines = result.split('\n')
                for i, line in enumerate(lines):
                    # –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ–º –∫–∞–≤—ã—á–∫–∏ –≤ —Å—Ç—Ä–æ–∫–µ
                    quotes_count = line.count('"')
                    if quotes_count % 2 != 0:  # –ù–µ—á–µ—Ç–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–∞–≤—ã—á–µ–∫
                        # –î–æ–±–∞–≤–ª—è–µ–º –∑–∞–∫—Ä—ã–≤–∞—é—â—É—é –∫–∞–≤—ã—á–∫—É –≤ –∫–æ–Ω—Ü–µ —Å—Ç—Ä–æ–∫–∏
                        lines[i] = line + '"'
                        fixed = True
                        logger.debug(f"üîß –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–∞ —Å—Ç—Ä–æ–∫–∞ {i+1}: –¥–æ–±–∞–≤–ª–µ–Ω–∞ –∑–∞–∫—Ä—ã–≤–∞—é—â–∞—è –∫–∞–≤—ã—á–∫–∞")
                
                if fixed:
                    result = '\n'.join(lines)
                
                return result
            
            # –ü—Ä–∏–º–µ–Ω—è–µ–º –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è
            json_str = fix_unterminated_strings(json_str)
            
            # –£–¥–∞–ª—è–µ–º –ª–∏—à–Ω–∏–µ –∑–∞–ø—è—Ç—ã–µ –ø–µ—Ä–µ–¥ –∑–∞–∫—Ä—ã–≤–∞—é—â–∏–º–∏ —Å–∫–æ–±–∫–∞–º–∏
            json_str = re.sub(r',\s*]', ']', json_str)
            json_str = re.sub(r',\s*}', '}', json_str)
            
            # –ó–∞–∫—Ä—ã–≤–∞–µ–º –Ω–µ–∑–∞–∫—Ä—ã—Ç—ã–µ —Ñ–∏–≥—É—Ä–Ω—ã–µ —Å–∫–æ–±–∫–∏
            open_braces = json_str.count('{')
            close_braces = json_str.count('}')
            if open_braces > close_braces:
                json_str = json_str + '}' * (open_braces - close_braces)
                logger.debug(f"üîß –î–æ–±–∞–≤–ª–µ–Ω–æ {open_braces - close_braces} –∑–∞–∫—Ä—ã–≤–∞—é—â–∏—Ö —Ñ–∏–≥—É—Ä–Ω—ã—Ö —Å–∫–æ–±–æ–∫")
            
            # –ó–∞–∫—Ä—ã–≤–∞–µ–º –Ω–µ–∑–∞–∫—Ä—ã—Ç—ã–µ –∫–≤–∞–¥—Ä–∞—Ç–Ω—ã–µ —Å–∫–æ–±–∫–∏
            open_brackets = json_str.count('[')
            close_brackets = json_str.count(']')
            if open_brackets > close_brackets:
                json_str = json_str + ']' * (open_brackets - close_brackets)
                logger.debug(f"üîß –î–æ–±–∞–≤–ª–µ–Ω–æ {open_brackets - close_brackets} –∑–∞–∫—Ä—ã–≤–∞—é—â–∏—Ö –∫–≤–∞–¥—Ä–∞—Ç–Ω—ã—Ö —Å–∫–æ–±–æ–∫")
            
            return json_str
            
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–∏ JSON: {e}")
            return json_str
        
    async def generate_speaking_questions(self, level: int, count: int) -> List[Dict]:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –≤–æ–ø—Ä–æ—Å–æ–≤ –¥–ª—è –≥–æ–≤–æ—Ä–µ–Ω–∏—è"""
        
        if not self.ai_enabled or not self.client:
            return self.generate_speaking_offline(level, count)
        
        try:
            # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
            level_words = self.get_words_by_level(level, 20)
            word_examples = "\n".join([f"- {w['character']} ({w['pinyin']}): {w['translation']}" 
                                    for w in level_words[:8]])
            
            prompt = f"""–¢—ã —ç–∫—Å–ø–µ—Ä—Ç –ø–æ HSK –≥–æ–≤–æ—Ä–µ–Ω–∏—é. –°–≥–µ–Ω–µ—Ä–∏—Ä—É–π {count} –∑–∞–¥–∞–Ω–∏–π –¥–ª—è —É—Å—Ç–Ω–æ–π —á–∞—Å—Ç–∏ HSK {level}.

    –¢–†–ï–ë–û–í–ê–ù–ò–Ø:
    1. –ó–∞–¥–∞–Ω–∏—è –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å –ø—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏–º–∏ –∏ –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω—ã–º–∏
    2. –£—á–∏—Ç—ã–≤–∞—Ç—å —É—Ä–æ–≤–µ–Ω—å HSK {level}
    3. –î–∞–≤–∞—Ç—å —á–µ—Ç–∫–∏–µ –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏ –∏ –∫—Ä–∏—Ç–µ—Ä–∏–∏ –æ—Ü–µ–Ω–∫–∏

    –ö–û–ù–¢–ï–ö–°–¢:
    - –£—Ä–æ–≤–µ–Ω—å: HSK {level}
    - –°–ª–æ–≤–∞ –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è: {word_examples}

    –¢–ò–ü–´ –ó–ê–î–ê–ù–ò–ô –î–õ–Ø HSK {level}:
    - –û–ø–∏—Å–∞–Ω–∏–µ –∫–∞—Ä—Ç–∏–Ω–∫–∏
    - –û—Ç–≤–µ—Ç—ã –Ω–∞ –≤–æ–ø—Ä–æ—Å—ã
    - –ö–æ—Ä–æ—Ç–∫–∏–π —Ä–∞—Å—Å–∫–∞–∑ –Ω–∞ —Ç–µ–º—É
    - –í—ã—Ä–∞–∂–µ–Ω–∏–µ –º–Ω–µ–Ω–∏—è

    –§–û–†–ú–ê–¢ –ö–ê–ñ–î–û–ì–û –ó–ê–î–ê–ù–ò–Ø:
    {{
    "id": "S1",
    "task": "–û–ø–∏—Å–∞–Ω–∏–µ –∑–∞–¥–∞–Ω–∏—è –Ω–∞ —Ä—É—Å—Å–∫–æ–º",
    "preparation_time": "1 –º–∏–Ω—É—Ç–∞",
    "speaking_time": "2 –º–∏–Ω—É—Ç—ã", 
    "keywords": "–∫–ª—é—á–µ–≤—ã–µ, —Å–ª–æ–≤–∞, –¥–ª—è, –ø–æ–º–æ—â–∏",
    "evaluation_criteria": ["–ü—Ä–æ–∏–∑–Ω–æ—à–µ–Ω–∏–µ", "–ì—Ä–∞–º–º–∞—Ç–∏–∫–∞", "–°–ª–æ–≤–∞—Ä–Ω—ã–π –∑–∞–ø–∞—Å", "–°–≤—è–∑–Ω–æ—Å—Ç—å"],
    "example": "–ü—Ä–∏–º–µ—Ä –æ—Ç–≤–µ—Ç–∞ –Ω–∞ –∫–∏—Ç–∞–π—Å–∫–æ–º —Å –ø–µ—Ä–µ–≤–æ–¥–æ–º"
    }}

    –í–µ—Ä–Ω–∏ –¢–û–õ–¨–ö–û JSON –º–∞—Å—Å–∏–≤ —Å {count} –∑–∞–¥–∞–Ω–∏—è–º–∏.
    """
            
            response = await asyncio.to_thread(
                self.client.chat.completions.create,
                model="deepseek-chat",
                messages=[
                    {"role": "system", "content": "–¢—ã —Å–æ–∑–¥–∞–µ—à—å –∑–∞–¥–∞–Ω–∏—è –¥–ª—è HSK –≥–æ–≤–æ—Ä–µ–Ω–∏—è. –í–µ—Ä–Ω–∏ —Ç–æ–ª—å–∫–æ JSON."},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.7,
                max_tokens=2000
            )
            
            content = response.choices[0].message.content
            # –ü–∞—Ä—Å–∏–Ω–≥ JSON
            json_match = re.search(r'\[.*\]', content, re.DOTALL)
            if json_match:
                questions = json.loads(json_match.group())
                
                # –í–∞–ª–∏–¥–∞—Ü–∏—è –∏ –¥–æ–±–∞–≤–ª–µ–Ω–∏–µ –ø–æ–ª–µ–π
                for i, q in enumerate(questions):
                    q["id"] = q.get("id", f"S{i+1}")
                    if "preparation_time" not in q:
                        q["preparation_time"] = "1 –º–∏–Ω—É—Ç–∞"
                    if "speaking_time" not in q:
                        q["speaking_time"] = "2 –º–∏–Ω—É—Ç—ã"
                    if "keywords" not in q:
                        q["keywords"] = "ËØ¥, ÊÉ≥, ËßâÂæó, Âõ†‰∏∫"
                
                return questions
                
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ speaking: {e}")
        
        # Fallback –Ω–∞ –æ—Ñ—Ñ–ª–∞–π–Ω
        return self.generate_speaking_offline(level, count)

    def generate_speaking_offline(self, level: int, count: int) -> List[Dict]:
        """–û—Ñ—Ñ–ª–∞–π–Ω-–≥–µ–Ω–µ—Ä–∞—Ü–∏—è speaking –∑–∞–¥–∞–Ω–∏–π"""
        logger.info(f"üé§ –û—Ñ—Ñ–ª–∞–π–Ω-–≥–µ–Ω–µ—Ä–∞—Ü–∏—è speaking –¥–ª—è HSK{level}")
        
        # –¢–µ–º—ã –¥–ª—è —Ä–∞–∑–Ω—ã—Ö —É—Ä–æ–≤–Ω–µ–π
        topics_by_level = {
            1: ["Ëá™Êàë‰ªãÁªç", "ÊàëÁöÑÂÆ∂Â∫≠", "ÊàëÁöÑÁà±Â•Ω", "ÂñúÊ¨¢ÁöÑÈ£üÁâ©"],
            2: ["ÊàëÁöÑ‰∏ÄÂ§©", "ÊàëÁöÑÊúãÂèã", "ÊàëÁöÑÂ≠¶Ê†°", "Âë®Êú´ËÆ°Âàí"],
            3: ["ÈöæÂøòÁöÑÊóÖË°å", "ÊàëÁöÑÊ¢¶ÊÉ≥", "ÂñúÊ¨¢ÁöÑÁîµÂΩ±", "ÁéØÂ¢É‰øùÊä§"],
            4: ["ÁßëÊäÄÁöÑÂΩ±Âìç", "ÊïôËÇ≤ÁöÑÈáçË¶ÅÊÄß", "‰º†ÁªüÊñáÂåñ", "ÂÅ•Â∫∑ÁîüÊ¥ª"],
            5: ["ÂÖ®ÁêÉÂåñ", "Á§æ‰∫§ÁΩëÁªú", "ËÅå‰∏öËßÑÂàí", "ÂüéÂ∏Ç‰∏éÂÜúÊùë"],
            6: ["‰∫∫Â∑•Êô∫ËÉΩ", "ÊñáÂåñÂ∑ÆÂºÇ", "Á§æ‰ºöÈóÆÈ¢ò", "Êú™Êù•ÂèëÂ±ï"]
        }
        
        topics = topics_by_level.get(level, topics_by_level[3])
        
        questions = []
        for i in range(min(count, len(topics))):
            questions.append({
                "id": f"S{i+1}",
                "task": f"–†–∞—Å—Å–∫–∞–∂–∏—Ç–µ –Ω–∞ —Ç–µ–º—É: '{topics[i]}'",
                "preparation_time": "1 –º–∏–Ω—É—Ç–∞",
                "speaking_time": "2 –º–∏–Ω—É—Ç—ã",
                "keywords": "ËØ¥, ÊÉ≥, ËßâÂæó, Âõ†‰∏∫, ÊâÄ‰ª•, ‰ΩÜÊòØ",
                "evaluation_criteria": ["–ü—Ä–æ–∏–∑–Ω–æ—à–µ–Ω–∏–µ", "–ì—Ä–∞–º–º–∞—Ç–∏–∫–∞", "–°–ª–æ–≤–∞—Ä–Ω—ã–π –∑–∞–ø–∞—Å", "–°–≤—è–∑–Ω–æ—Å—Ç—å", "–°–æ–¥–µ—Ä–∂–∞–Ω–∏–µ"],
                "example": f"ÊàëÊÉ≥Ë∞àË∞à{topics[i]}„ÄÇÊàëËÆ§‰∏∫Ëøô‰∏™ËØùÈ¢òÂæàÈáçË¶ÅÔºåÂõ†‰∏∫... (–Ø —Ö–æ—á—É –ø–æ–≥–æ–≤–æ—Ä–∏—Ç—å –æ {topics[i]}. –Ø —Å—á–∏—Ç–∞—é —ç—Ç—É —Ç–µ–º—É –≤–∞–∂–Ω–æ–π, –ø–æ—Ç–æ–º—É —á—Ç–æ...)"
            })
        
        return questions
    
    async def generate_offline_questions(self, level: int, section: str, count: int) -> List[Dict]:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –≤–æ–ø—Ä–æ—Å–æ–≤ –±–µ–∑ AI - –£–ú–ù–ê–Ø –û–§–§–õ–ê–ô–ù-–í–ï–†–°–ò–Ø"""
        logger.info(f"üìö –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ñ—Ñ–ª–∞–π–Ω-–≤–æ–ø—Ä–æ—Å–æ–≤ –¥–ª—è HSK{level} {section}")
        
        words = self.get_words_by_level(level, 50)
        grammar = self.get_grammar_by_level(level)[:10]
        
        questions = []
        
        for i in range(count):
            try:
                if section == "listening":
                    # –ë–æ–ª–µ–µ —Å–ª–æ–∂–Ω—ã–µ –æ—Ñ—Ñ–ª–∞–π–Ω –≤–æ–ø—Ä–æ—Å—ã –¥–ª—è –∞—É–¥–∏—Ä–æ–≤–∞–Ω–∏—è
                    if words and len(words) >= 4:
                        correct_word = random.choice(words)
                        other_words = random.sample([w for w in words if w != correct_word], 3)
                        
                        # –°–æ–∑–¥–∞–µ–º –±–æ–ª–µ–µ –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω—ã–π –¥–∏–∞–ª–æ–≥
                        scenarios = [
                            f"Áî≤Ôºö‰Ω†ÂñúÊ¨¢{correct_word['character']}ÂêóÔºü\n‰πôÔºöÊòØÁöÑÔºåÊàëÈùûÂ∏∏ÂñúÊ¨¢{correct_word['character']}„ÄÇ",
                            f"Áî≤Ôºö‰Ω†Êò®Â§©‰π∞‰∫Ü‰ªÄ‰πàÔºü\n‰πôÔºöÊàë‰π∞‰∫Ü‰∏Ä‰∫õ{correct_word['character']}„ÄÇ",
                            f"Áî≤ÔºöÂë®Êú´‰Ω†ÊÉ≥ÂÅö‰ªÄ‰πàÔºü\n‰πôÔºöÊàëÊÉ≥ÂíåÊúãÂèã‰∏ÄËµ∑Âéª{correct_word['character']}„ÄÇ",
                            f"Áî≤Ôºö‰Ω†ÁöÑÁà±Â•ΩÊòØ‰ªÄ‰πàÔºü\n‰πôÔºöÊàëÂñúÊ¨¢{correct_word['character']}„ÄÇ"
                        ]
                        
                        question = {
                            "id": f"L{i+1}",
                            "audio_text": random.choice(scenarios),
                            "question": f"‰ªñ‰ª¨Ë∞àËÆ∫ÁöÑÊòØ‰ªÄ‰πàÔºü",
                            "options": [
                                correct_word['translation'],
                                other_words[0]['translation'],
                                other_words[1]['translation'],
                                other_words[2]['translation']
                            ],
                            "correct_index": 0,
                            "explanation": f"–í –¥–∏–∞–ª–æ–≥–µ —É–ø–æ–º–∏–Ω–∞–µ—Ç—Å—è '{correct_word['character']}' ({correct_word['translation']})"
                        }
                        questions.append(question)
                
                elif section == "reading":
                    # –ë–æ–ª–µ–µ —Å–ª–æ–∂–Ω—ã–µ –æ—Ñ—Ñ–ª–∞–π–Ω –≤–æ–ø—Ä–æ—Å—ã –¥–ª—è —á—Ç–µ–Ω–∏—è
                    if words and len(words) >= 3:
                        selected_words = random.sample(words, 3)
                        
                        # –°–æ–∑–¥–∞–µ–º –±–æ–ª–µ–µ –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç
                        texts = [
                            f"‰ªäÂ§©Â§©Ê∞îÂæàÂ•Ω„ÄÇÊàëÂíåÊúãÂèã‰∏ÄËµ∑Âéª{selected_words[0]['character']}„ÄÇÊàë‰ª¨ÂæàÂñúÊ¨¢{selected_words[1]['character']}„ÄÇ{selected_words[2]['character']}‰πüÂæàÈáçË¶Å„ÄÇ",
                            f"ËøôÊòØÊàëÁöÑ{selected_words[0]['character']}„ÄÇ‰ªñÂñúÊ¨¢{selected_words[1]['character']}„ÄÇÊàë‰∏çÂñúÊ¨¢{selected_words[2]['character']}„ÄÇ",
                            f"Â≠¶Ê†°ÊúâÂæàÂ§ö{selected_words[0]['character']}„ÄÇËÄÅÂ∏àÊïôÊàë‰ª¨{selected_words[1]['character']}„ÄÇÂ≠¶ÁîüÈúÄË¶ÅÂ≠¶‰π†{selected_words[2]['character']}„ÄÇ"
                        ]
                        
                        question = {
                            "id": f"R{i+1}",
                            "text": random.choice(texts),
                            "question": "–ß—Ç–æ —É–ø–æ–º–∏–Ω–∞–µ—Ç—Å—è –≤ —Ç–µ–∫—Å—Ç–µ?",
                            "options": [
                                f"{selected_words[0]['translation']}, {selected_words[1]['translation']}, {selected_words[2]['translation']}",
                                "Êó∂Èó¥, Âú∞ÁÇπ, ‰∫∫Áâ©",
                                "Â§©Ê∞î, È£üÁâ©, Ë°£Êúç",
                                "Â≠¶‰π†, Â∑•‰Ωú, ‰ºëÊÅØ"
                            ],
                            "correct_index": 0,
                            "explanation": f"–í —Ç–µ–∫—Å—Ç–µ —É–ø–æ–º–∏–Ω–∞—é—Ç—Å—è: {selected_words[0]['character']}, {selected_words[1]['character']}, {selected_words[2]['character']}"
                        }
                        questions.append(question)
                
                else:  # writing
                    # –ë–æ–ª–µ–µ –ø–æ–ª–µ–∑–Ω—ã–µ –æ—Ñ—Ñ–ª–∞–π–Ω –∑–∞–¥–∞–Ω–∏—è –¥–ª—è –ø–∏—Å—å–º–∞
                    writing_tasks = [
                        {
                            "task": f"‰ΩøÁî®'{random.choice(words)['character'] if words else 'Â≠¶‰π†'}'Ëøô‰∏™ËØçÂÜô‰∏Ä‰∏™Âè•Â≠ê",
                            "requirements": "Ëá≥Â∞ë10‰∏™Â≠óÔºåËØ≠Ê≥ïÊ≠£Á°Æ",
                            "example_response": f"ÊàëÊØèÂ§©{random.choice(words)['character'] if words else 'Â≠¶‰π†'}‰∏≠Êñá„ÄÇ",
                            "evaluation_criteria": ["ËØ≠Ê≥ïÊ≠£Á°ÆÊÄß", "Áî®ËØçÂáÜÁ°ÆÊÄß", "Âè•Â≠êÂÆåÊï¥ÊÄß"]
                        },
                        {
                            "task": "ÂÜô‰∏ÄÊÆµÂÖ≥‰∫é‰Ω†‰∏ÄÂ§©ÁöÑÁü≠Êñá",
                            "requirements": "‰ΩøÁî®Êó∂Èó¥ËØçËØ≠ÔºàÊó©‰∏ä„ÄÅ‰∏ãÂçà„ÄÅÊôö‰∏äÔºâÔºåËá≥Â∞ë5Âè•ËØù",
                            "example_response": "Êó©‰∏äÊàë‰∏ÉÁÇπËµ∑Â∫ä„ÄÇÂÖ´ÁÇπÂêÉÊó©È•≠„ÄÇ‰πùÁÇπÂºÄÂßãÂ≠¶‰π†‰∏≠Êñá„ÄÇ‰∏ãÂçàÊàëÂíåÊúãÂèãËßÅÈù¢„ÄÇÊôö‰∏äÊàëÁúãÁîµËßÜ„ÄÇ",
                            "evaluation_criteria": ["ÂÜÖÂÆπÂÆåÊï¥ÊÄß", "Êó∂Èó¥È°∫Â∫è", "ËØ≠Ê≥ïÊ≠£Á°ÆÊÄß"]
                        }
                    ]
                    
                    question = {
                        "id": f"W{i+1}",
                        **random.choice(writing_tasks)
                    }
                    questions.append(question)
                    
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ—Ñ—Ñ–ª–∞–π–Ω-–≤–æ–ø—Ä–æ—Å–∞ {i}: {e}")
                continue
        
        # –ï—Å–ª–∏ –Ω–µ —É–¥–∞–ª–æ—Å—å —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –≤–æ–ø—Ä–æ—Å–æ–≤, –¥–æ–±–∞–≤–ª—è–µ–º –ø—Ä–æ—Å—Ç—ã–µ
        if len(questions) < count:
            logger.warning(f"‚ö†Ô∏è –°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–æ —Ç–æ–ª—å–∫–æ {len(questions)} –∏–∑ {count} –≤–æ–ø—Ä–æ—Å–æ–≤")
            # –î–æ–±–∞–≤–ª—è–µ–º –ø—Ä–æ—Å—Ç—ã–µ –≤–æ–ø—Ä–æ—Å—ã –¥–ª—è –∑–∞–ø–æ–ª–Ω–µ–Ω–∏—è
            for i in range(len(questions), count):
                simple_question = self.create_simple_question(section, i+1, level)
                if simple_question:
                    questions.append(simple_question)
        
        return questions[:count]
    
    def create_simple_question(self, section: str, index: int, level: int) -> Optional[Dict]:
        """–°–æ–∑–¥–∞–Ω–∏–µ –ø—Ä–æ—Å—Ç–æ–≥–æ –≤–æ–ø—Ä–æ—Å–∞ –∫–∞–∫ –ø–æ—Å–ª–µ–¥–Ω–µ–µ —Å—Ä–µ–¥—Å—Ç–≤–æ"""
        try:
            if section == "listening":
                return {
                    "id": f"L{index}",
                    "audio_text": "‰Ω†Â•ΩÂêóÔºüÊàëÂæàÂ•Ω„ÄÇ",
                    "question": "–ö–∞–∫ –¥–µ–ª–∞ —É –≥–æ–≤–æ—Ä—è—â–µ–≥–æ?",
                    "options": ["–•–æ—Ä–æ—à–æ", "–ü–ª–æ—Ö–æ", "–ù–æ—Ä–º–∞–ª—å–Ω–æ", "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ"],
                    "correct_index": 0,
                    "explanation": "–í –∞—É–¥–∏–æ —Å–∫–∞–∑–∞–Ω–æ 'ÊàëÂæàÂ•Ω' (—É –º–µ–Ω—è –≤—Å–µ —Ö–æ—Ä–æ—à–æ)"
                }
            elif section == "reading":
                return {
                    "id": f"R{index}",
                    "text": "‰ªäÂ§©Â§©Ê∞îÂæàÂ•Ω„ÄÇ",
                    "question": "–ö–∞–∫–∞—è —Å–µ–≥–æ–¥–Ω—è –ø–æ–≥–æ–¥–∞?",
                    "options": ["–•–æ—Ä–æ—à–∞—è", "–ü–ª–æ—Ö–∞—è", "–î–æ–∂–¥–ª–∏–≤–∞—è", "–°–Ω–µ–∂–Ω–∞—è"],
                    "correct_index": 0,
                    "explanation": "–í —Ç–µ–∫—Å—Ç–µ –Ω–∞–ø–∏—Å–∞–Ω–æ 'Â§©Ê∞îÂæàÂ•Ω' (–ø–æ–≥–æ–¥–∞ —Ö–æ—Ä–æ—à–∞—è)"
                }
            else:
                return {
                    "id": f"W{index}",
                    "task": "ÂÜô‰∏Ä‰∏™ÂÖ≥‰∫éÂ§©Ê∞îÁöÑÂè•Â≠ê",
                    "requirements": "Ëá≥Â∞ë5‰∏™Â≠ó",
                    "example_response": "‰ªäÂ§©Â§©Ê∞îÂæàÂ•Ω„ÄÇ",
                    "evaluation_criteria": ["ËØ≠Ê≥ïÊ≠£Á°Æ", "Áî®ËØçÂáÜÁ°Æ", "Âè•Â≠êÂÆåÊï¥"]
                }
        except:
            return None
    
    async def generate_full_test(self, level: int, test_type: str = "adaptive") -> Dict:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –ø–æ–ª–Ω–æ–≥–æ —Ç–µ—Å—Ç–∞ HSK - –§–ò–ö–°–ò–†–û–í–ê–ù–ù–ê–Ø –í–ï–†–°–ò–Ø –í–°–ï–• –†–ê–ó–î–ï–õ–û–í"""
        logger.info(f"üéØ –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –ø–æ–ª–Ω–æ–≥–æ HSK{level} —Ç–µ—Å—Ç–∞ ({test_type} —Ä–µ–∂–∏–º)...")
        
        test_id = f"hsk{level}_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
        standard = self.hsk_standards.get(level, self.hsk_standards[3])
        
        # –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –≤–æ–ø—Ä–æ—Å–æ–≤ –î–õ–Ø –í–°–ï–• —Ä–∞–∑–¥–µ–ª–æ–≤
        question_counts = self.get_adaptive_counts(level) if test_type == "adaptive" else self.get_full_counts(level)
        
        # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –í–°–ï–• —Ä–∞–∑–¥–µ–ª–æ–≤
        sections = {}
        
        # 1. –ê—É–¥–∏—Ä–æ–≤–∞–Ω–∏–µ (–≤—Å–µ–≥–¥–∞ –µ—Å—Ç—å)
        logger.info(f"üéß –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∞—É–¥–∏—Ä–æ–≤–∞–Ω–∏—è...")
        listening_q = await self.generate_ai_questions(level, "listening", question_counts["listening"])
        sections["listening"] = {
            "section_name": "Âê¨Âäõ",
            "total_score": 100,
            "instructions": "ÊØèÈ¢òÂê¨‰∏ÄÈÅçÔºåÈÄâÊã©Ê≠£Á°ÆÁ≠îÊ°à„ÄÇ",
            "questions": listening_q if isinstance(listening_q, list) else [],
            "count": len(listening_q) if isinstance(listening_q, list) else 0
        }
        
        # 2. –ß—Ç–µ–Ω–∏–µ (–≤—Å–µ–≥–¥–∞ –µ—Å—Ç—å)
        logger.info(f"üìñ –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —á—Ç–µ–Ω–∏—è...")
        reading_q = await self.generate_ai_questions(level, "reading", question_counts["reading"])
        sections["reading"] = {
            "section_name": "ÈòÖËØª",
            "total_score": 100,
            "instructions": "ÈòÖËØªÊùêÊñôÔºåÈÄâÊã©Ê≠£Á°ÆÁ≠îÊ°à„ÄÇ",
            "questions": reading_q if isinstance(reading_q, list) else [],
            "count": len(reading_q) if isinstance(reading_q, list) else 0
        }
        
        # 3. –ü–∏—Å—å–º–æ (HSK 3+)
        if level >= 3:
            logger.info(f"‚úçÔ∏è –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –ø–∏—Å—å–º–∞...")
            writing_q = await self.generate_ai_questions(level, "writing", question_counts["writing"])
            
            # –£–±–µ–¥–∏–º—Å—è, —á—Ç–æ –µ—Å—Ç—å –≤–æ–ø—Ä–æ—Å—ã
            if writing_q and isinstance(writing_q, list) and len(writing_q) > 0:
                sections["writing"] = {
                    "section_name": "‰π¶ÂÜô",
                    "total_score": 100,
                    "instructions": "ÂÆåÊàêÂÜô‰Ωú‰ªªÂä°„ÄÇ",
                    "questions": writing_q,
                    "count": len(writing_q),
                    "tasks": writing_q  # –î–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏ —Å —Ñ—Ä–æ–Ω—Ç–µ–Ω–¥–æ–º
                }
            else:
                # –ï—Å–ª–∏ –≤–æ–ø—Ä–æ—Å–æ–≤ –Ω–µ—Ç, —Å–æ–∑–¥–∞–µ–º —Ö–æ—Ç—è –±—ã –æ–¥–∏–Ω –ø—Ä–∏–º–µ—Ä–Ω—ã–π
                sections["writing"] = {
                    "section_name": "‰π¶ÂÜô",
                    "total_score": 100,
                    "instructions": "ÂÆåÊàêÂÜô‰Ωú‰ªªÂä°„ÄÇ",
                    "questions": [self.create_sample_writing_task(level)],
                    "count": 1,
                    "tasks": [self.create_sample_writing_task(level)]
                }
        else:
            # –î–ª—è HSK 1-2 —Å–æ–∑–¥–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–æ–Ω–Ω—ã–π —Ä–∞–∑–¥–µ–ª
            sections["writing"] = {
                "section_name": "‰π¶ÂÜô",
                "total_score": 0,
                "instructions": "–î–ª—è HSK 1-2 –ø–∏—Å—å–º–µ–Ω–Ω–∞—è —á–∞—Å—Ç—å –Ω–µ –ø—Ä–µ–¥—É—Å–º–æ—Ç—Ä–µ–Ω–∞.",
                "questions": [{
                    "id": "W1",
                    "task": "–ü–∏—Å—å–º–µ–Ω–Ω–∞—è —á–∞—Å—Ç—å –¥–æ—Å—Ç—É–ø–Ω–∞ —Å HSK 3",
                    "requirements": "–ü–µ—Ä–µ–π–¥–∏—Ç–µ –Ω–∞ —É—Ä–æ–≤–µ–Ω—å HSK 3 –∏–ª–∏ –≤—ã—à–µ",
                    "example_response": "",
                    "evaluation_criteria": []
                }],
                "count": 1
            }
        
        # 4. –ì–æ–≤–æ—Ä–µ–Ω–∏–µ (–í–°–ï–ì–î–ê —Å–æ–∑–¥–∞–µ–º —Ä–∞–∑–¥–µ–ª, –¥–∞–∂–µ –ø—É—Å—Ç–æ–π)
        logger.info(f"üé§ –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –≥–æ–≤–æ—Ä–µ–Ω–∏—è...")
        speaking_q = await self.generate_speaking_questions(level, question_counts.get("speaking", 2))
        sections["speaking"] = {
            "section_name": "Âè£ËØ≠",
            "total_score": 100,
            "instructions": "ÂÆåÊàêÂè£ËØ≠‰ªªÂä°„ÄÇ",
            "questions": speaking_q if isinstance(speaking_q, list) else [],
            "tasks": speaking_q if isinstance(speaking_q, list) else [],  # –î–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏ —Å —Ñ—Ä–æ–Ω—Ç–µ–Ω–¥–æ–º
            "count": len(speaking_q) if isinstance(speaking_q, list) else 0
        }
        
        # –°–±–æ—Ä–∫–∞ –ø–æ–ª–Ω–æ–≥–æ —Ç–µ—Å—Ç–∞
        test_data = {
            "test_id": test_id,
            "level": level,
            "type": test_type,
            "generated_at": datetime.now().isoformat(),
            "total_score": standard["score"],
            "time_limit": standard["test_time"],
            "standards": standard,
            "ai_generated": self.ai_enabled,
            "sections": sections
        }
        
        logger.info(f"‚úÖ –ü–æ–ª–Ω—ã–π —Ç–µ—Å—Ç —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω: {test_id}")
        logger.info(f"üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞: –ê—É–¥–∏—Ä–æ–≤–∞–Ω–∏–µ: {len(listening_q)}, –ß—Ç–µ–Ω–∏–µ: {len(reading_q)}, –ü–∏—Å—å–º–æ: {len(writing_q if level >= 3 else [])}, –ì–æ–≤–æ—Ä–µ–Ω–∏–µ: {len(speaking_q)}")
        
        return test_data
    
    def get_adaptive_counts(self, level: int) -> Dict[str, int]:
        """–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –≤–æ–ø—Ä–æ—Å–æ–≤ –¥–ª—è –∞–¥–∞–ø—Ç–∏–≤–Ω–æ–≥–æ —Ç–µ—Å—Ç–∞ (–í–°–ï –†–ê–ó–î–ï–õ–´)"""
        base_counts = {
            1: {"listening": 10, "reading": 10, "writing": 0, "speaking": 2},
            2: {"listening": 15, "reading": 15, "writing": 0, "speaking": 2},
            3: {"listening": 20, "reading": 20, "writing": 5, "speaking": 3},
            4: {"listening": 25, "reading": 25, "writing": 8, "speaking": 3},
            5: {"listening": 30, "reading": 30, "writing": 10, "speaking": 4},
            6: {"listening": 35, "reading": 35, "writing": 12, "speaking": 4}
        }
        return base_counts.get(level, base_counts[3])

    def get_full_counts(self, level: int) -> Dict[str, int]:
        """–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –≤–æ–ø—Ä–æ—Å–æ–≤ –¥–ª—è –ø–æ–ª–Ω–æ–≥–æ —Ç–µ—Å—Ç–∞ (–í–°–ï –†–ê–ó–î–ï–õ–´)"""
        full_counts = {
            1: {"listening": 15, "reading": 15, "writing": 0, "speaking": 2},
            2: {"listening": 25, "reading": 20, "writing": 0, "speaking": 3},
            3: {"listening": 30, "reading": 25, "writing": 8, "speaking": 3},
            4: {"listening": 35, "reading": 30, "writing": 10, "speaking": 4},
            5: {"listening": 40, "reading": 35, "writing": 12, "speaking": 4},
            6: {"listening": 45, "reading": 40, "writing": 15, "speaking": 5}
        }
        return full_counts.get(level, full_counts[3])
    
    def create_sample_writing_task(self, level: int) -> Dict:
        """–°–æ–∑–¥–∞–Ω–∏–µ –ø—Ä–∏–º–µ—Ä–Ω–æ–≥–æ –∑–∞–¥–∞–Ω–∏—è –¥–ª—è –ø–∏—Å—å–º–∞"""
        sample_tasks = {
            3: {
                "id": "W1",
                "task": "ÂÜô‰∏ÄÊÆµÂÖ≥‰∫é‰Ω†ÊúÄÂ•ΩÁöÑÊúãÂèãÁöÑÁü≠Êñá",
                "requirements": "‰ΩøÁî®‰ª•‰∏ãËØçËØ≠: ÊúãÂèã, ‰∏ÄËµ∑, Â∏ÆÂä©, Âø´‰πê (Ëá≥Â∞ë60Â≠ó)",
                "example_response": "ÊàëÊúÄÂ•ΩÁöÑÊúãÂèãÂè´Â∞èÊòé„ÄÇÊàë‰ª¨ÁªèÂ∏∏‰∏ÄËµ∑Â≠¶‰π†‰∏≠Êñá„ÄÇ‰ªñÁªèÂ∏∏Â∏ÆÂä©ÊàëÂ≠¶‰π†ÈöæÁöÑÊ±âÂ≠ó„ÄÇÂíå‰ªñÂú®‰∏ÄËµ∑ÊàëÂæàÂø´‰πê„ÄÇ",
                "evaluation_criteria": ["ËØ≠Ê≥ïÊ≠£Á°Æ", "ËØçÊ±á‰ΩøÁî®", "ÂÜÖÂÆπÂÆåÊï¥", "Â≠óÊï∞ËææÊ†á"]
            },
            4: {
                "id": "W1",
                "task": "ÊèèËø∞‰Ω†ÊúÄÂñúÊ¨¢ÁöÑÂ≠£ËäÇ",
                "requirements": "ËØ¥ÊòéÂéüÂõ†ÂíåÊ¥ªÂä® (80-100Â≠ó)",
                "example_response": "ÊàëÊúÄÂñúÊ¨¢ÁöÑÂ≠£ËäÇÊòØÊò•Â§©„ÄÇÊò•Â§©Â§©Ê∞î‰∏çÂÜ∑‰πü‰∏çÁÉ≠ÔºåÈùûÂ∏∏ËàíÊúç„ÄÇËä±ÂºÄ‰∫ÜÔºåÊ†ëÁªø‰∫ÜÔºåÂæàÊºÇ‰∫Æ„ÄÇÊàëÁªèÂ∏∏ÂíåÊúãÂèãÂéªÂÖ¨Âõ≠Êï£Ê≠•„ÄÇÊò•Â§©ËÆ©ÊàëÊÑüÂà∞Âø´‰πêÂíåÂÖÖÊª°Â∏åÊúõ„ÄÇ",
                "evaluation_criteria": ["ËØ≠Ê≥ïÊ≠£Á°Æ", "ËØçÊ±á‰∏∞ÂØå", "ÈÄªËæëÊ∏ÖÊô∞", "Â≠óÊï∞ËææÊ†á"]
            },
            5: {
                "id": "W1",
                "task": "‰Ω†ÂØπÊâãÊú∫‰ΩøÁî®ÁöÑÁúãÊ≥ï",
                "requirements": "Âà©ÂºäÂàÜÊûê (120-150Â≠ó)",
                "example_response": "ÊâãÊú∫ÁªôÊàë‰ª¨ÁöÑÁîüÊ¥ªÂ∏¶Êù•‰∫ÜÂæàÂ§ö‰æøÂà©Ôºå‰ΩÜ‰πüÂ∏¶Êù•‰∫Ü‰∏Ä‰∫õÈóÆÈ¢ò„ÄÇÂ•ΩÂ§ÑÊòØÊàë‰ª¨ÂèØ‰ª•ÈöèÊó∂ËÅîÁ≥ªÊúãÂèãÔºåËé∑Âèñ‰ø°ÊÅØÔºå‰ΩøÁî®ÂêÑÁßçÂ∫îÁî®„ÄÇ‰ΩÜÊòØÔºåËøáÂ∫¶‰ΩøÁî®ÊâãÊú∫‰ºöÂΩ±ÂìçÂ≠¶‰π†„ÄÅÂ∑•‰ΩúÂíåÂÅ•Â∫∑„ÄÇÊàë‰ª¨Â∫îËØ•ÂêàÁêÜ‰ΩøÁî®ÊâãÊú∫Ôºå‰∏çË¶ÅÊàê‰∏∫ÊâãÊú∫ÁöÑÂ•¥Èö∂„ÄÇ",
                "evaluation_criteria": ["ËßÇÁÇπÊòéÁ°Æ", "ËÆ∫ÊçÆÂÖÖÂàÜ", "ÁªìÊûÑÂêàÁêÜ", "ËØ≠Ë®ÄÂáÜÁ°Æ"]
            },
            6: {
                "id": "W1",
                "task": "ÂÖ®ÁêÉÂåñÂØπÊñáÂåñÁöÑÂΩ±Âìç",
                "requirements": "ÂàÜÊûêÂà©Âºä (180-200Â≠ó)",
                "example_response": "ÂÖ®ÁêÉÂåñÊòØ‰∏ÄÊääÂèåÂàÉÂâëÔºåÂØπÊñáÂåñ‰∫ßÁîüÊ∑±ËøúÂΩ±Âìç„ÄÇ‰∏ÄÊñπÈù¢ÔºåÂÖ®ÁêÉÂåñ‰øÉËøõ‰∫ÜÊñáÂåñ‰∫§ÊµÅÔºåËÆ©‰∏çÂêåÂõΩÂÆ∂ÁöÑ‰∫∫‰ª¨‰∫ÜËß£ÂΩºÊ≠§ÁöÑÊñáÂåñ‰º†Áªü„ÄÅÈ•ÆÈ£ü‰π†ÊÉØÂíåËâ∫ÊúØÂΩ¢Âºè„ÄÇÂè¶‰∏ÄÊñπÈù¢ÔºåÂÖ®ÁêÉÂåñÂèØËÉΩÂØºËá¥ÊñáÂåñÂêåË¥®ÂåñÔºåÂ∞èËØ≠ÁßçÂíå‰º†ÁªüÊñáÂåñÈù¢‰∏¥Ê∂àÂ§±ÁöÑÂç±Èô©„ÄÇÊàëËÆ§‰∏∫Êàë‰ª¨Â∫îËØ•Âú®ÂÖ®ÁêÉÂåñËøáÁ®ã‰∏≠‰øùÊä§ÊñáÂåñÂ§öÊ†∑ÊÄßÔºåËÆ©ÂêÑÁßçÊñáÂåñÈÉΩËÉΩÂæóÂà∞Â∞äÈáçÂíåÂèëÂ±ï„ÄÇ",
                "evaluation_criteria": ["Ê∑±Â∫¶ÂàÜÊûê", "ÈÄªËæë‰∏•Ë∞®", "ËØ≠Ë®Ä‰∏∞ÂØå", "ËßÇÁÇπÊñ∞È¢ñ"]
            }
        }
        
        return sample_tasks.get(level, sample_tasks[3])
    
    async def evaluate_writing(self, text: str, task_data: Dict) -> Dict:
        """–û—Ü–µ–Ω–∫–∞ –ø–∏—Å—å–º–µ–Ω–Ω–æ–π —Ä–∞–±–æ—Ç—ã —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º AI"""
        if not self.ai_enabled or not self.client:
            return self.evaluate_writing_offline(text, task_data)
        
        try:
            prompt = f"""–û—Ü–µ–Ω–∏ —Å–ª–µ–¥—É—é—â—É—é –ø–∏—Å—å–º–µ–Ω–Ω—É—é —Ä–∞–±–æ—Ç—É –¥–ª—è HSK:

–ó–∞–¥–∞–Ω–∏–µ: {task_data.get('task', '')}
–¢—Ä–µ–±–æ–≤–∞–Ω–∏—è: {task_data.get('requirements', '')}

–†–∞–±–æ—Ç–∞ —Å—Ç—É–¥–µ–Ω—Ç–∞: {text}

–û—Ü–µ–Ω–∏ –ø–æ —Å–ª–µ–¥—É—é—â–∏–º –∫—Ä–∏—Ç–µ—Ä–∏—è–º (0-25 –±–∞–ª–ª–æ–≤ –∫–∞–∂–¥—ã–π):
1. –ì—Ä–∞–º–º–∞—Ç–∏—á–µ—Å–∫–∞—è –ø—Ä–∞–≤–∏–ª—å–Ω–æ—Å—Ç—å
2. –õ–µ–∫—Å–∏—á–µ—Å–∫–æ–µ —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–∏–µ –∏ —Ç–æ—á–Ω–æ—Å—Ç—å
3. –°–æ–¥–µ—Ä–∂–∞–Ω–∏–µ –∏ –ø–æ–ª–Ω–æ—Ç–∞ –æ—Ç–≤–µ—Ç–∞
4. –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –∏ —Å–≤—è–∑–Ω–æ—Å—Ç—å —Ç–µ–∫—Å—Ç–∞

–í–µ—Ä–Ω–∏ –æ—Ç–≤–µ—Ç –≤ —Ñ–æ—Ä–º–∞—Ç–µ JSON:
{{
  "score": 85,
  "detailed_scores": {{
    "grammar": 20,
    "vocabulary": 22,
    "content": 21,
    "structure": 22
  }},
  "feedback": "–û–±—â–∞—è –æ—Ü–µ–Ω–∫–∞ –∏ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏",
  "suggestions": ["–ö–æ–Ω–∫—Ä–µ—Ç–Ω–æ–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ 1", "–ü—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ 2"]
}}"""
            
            response = await asyncio.to_thread(
                self.client.chat.completions.create,
                model="deepseek-chat",
                messages=[{"role": "user", "content": prompt}],
                temperature=0.3,
                max_tokens=1000
            )
            
            content = response.choices[0].message.content
            json_match = re.search(r'\{.*\}', content, re.DOTALL)
            if json_match:
                return json.loads(json_match.group())
                
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –æ—Ü–µ–Ω–∫–∏ –ø–∏—Å—å–º–∞ AI: {e}")
        
        return self.evaluate_writing_offline(text, task_data)
    
def evaluate_writing_offline(self, text: str, task_data: Dict) -> Dict:
    """–û—Ü–µ–Ω–∫–∞ –ø–∏—Å—å–º–µ–Ω–Ω–æ–π —Ä–∞–±–æ—Ç—ã –ù–ê –û–°–ù–û–í–ï –†–ï–ê–õ–¨–ù–´–• –ö–†–ò–¢–ï–†–ò–ï–í"""
    
    # 1. –ê–Ω–∞–ª–∏–∑ –¥–ª–∏–Ω—ã —Ç–µ–∫—Å—Ç–∞
    char_count = len(text)
    word_req = task_data.get('requirements', '10Â≠ó')
    req_match = re.search(r'(\d+)', word_req)
    req_count = int(req_match.group(1)) if req_match else 20
    
    # 2. –ü—Ä–æ–≤–µ—Ä–∫–∞ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è —Ç—Ä–µ–±–æ–≤–∞–Ω–∏–π
    requirements_met = 0
    if "‰ΩøÁî®‰ª•‰∏ãËØçËØ≠" in task_data.get('requirements', ''):
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ —Ç—Ä–µ–±—É–µ–º—ã—Ö —Å–ª–æ–≤
        required_words = re.findall(r'[\u4e00-\u9fff]+', task_data['requirements'])
        used_words = sum(1 for word in required_words if word in text)
        requirements_met = min(1.0, used_words / len(required_words)) if required_words else 1.0
    
    # 3. –ü—Ä–æ–≤–µ—Ä–∫–∞ –≥—Ä–∞–º–º–∞—Ç–∏–∫–∏ (–ø—Ä–æ—Å—Ç–∞—è)
    grammar_indicators = ['„ÄÇ', 'Ôºå', '‰∫Ü', 'ÁöÑ', 'ÊòØ', 'Âú®']
    grammar_score = sum(1 for marker in grammar_indicators if marker in text) / len(grammar_indicators)
    
    # 4. –î–ª–∏–Ω–∞ —Ç–µ–∫—Å—Ç–∞
    length_score = min(1.0, char_count / max(req_count, 1))
    
    # 5. –ë–∞–∑–æ–≤–∞—è –æ—Ü–µ–Ω–∫–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ –∫—Ä–∏—Ç–µ—Ä–∏–µ–≤ (–º–∞–∫—Å–∏–º—É–º 25 –∑–∞ –∫–∞–∂–¥—ã–π –∫—Ä–∏—Ç–µ—Ä–∏–π)
    scores = {
        "grammar": min(25, grammar_score * 25),
        "vocabulary": min(25, requirements_met * 25),
        "content": min(25, length_score * 25),
        "structure": min(25, 20)  # –ë–∞–∑–æ–≤–∞—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∞
    }
    
    # 6. –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –±–æ–Ω—É—Å—ã/—à—Ç—Ä–∞—Ñ—ã
    if char_count >= req_count:
        scores["content"] = min(25, scores["content"] + 5)
    
    # –ë–æ–Ω—É—Å –∑–∞ —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–∏–µ
    unique_chars = len(set(text))
    if unique_chars > 10:
        scores["vocabulary"] = min(25, scores["vocabulary"] + 3)
    
    # –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º –æ–±—â–∏–π –±–∞–ª–ª (0-100)
    total_score = min(100, sum(scores.values()))
    
    # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ñ–∏–¥–±–µ–∫–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ –æ—Ü–µ–Ω–∫–∏
    if total_score >= 90:
        feedback = "–û—Ç–ª–∏—á–Ω–∞—è —Ä–∞–±–æ—Ç–∞! –ì—Ä–∞–º–º–∞—Ç–∏–∫–∞ –∏ —Å–ª–æ–≤–∞—Ä–Ω—ã–π –∑–∞–ø–∞—Å –Ω–∞ –≤—ã—Å–æ–∫–æ–º —É—Ä–æ–≤–Ω–µ."
    elif total_score >= 80:
        feedback = "–û—á–µ–Ω—å —Ö–æ—Ä–æ—à–æ. –ù–µ–±–æ–ª—å—à–∏–µ –æ—à–∏–±–∫–∏, –Ω–æ –≤ —Ü–µ–ª–æ–º –æ—Ç–ª–∏—á–Ω–∞—è —Ä–∞–±–æ—Ç–∞."
    elif total_score >= 70:
        feedback = "–•–æ—Ä–æ—à–∞—è —Ä–∞–±–æ—Ç–∞. –ï—Å—Ç—å –æ—à–∏–±–∫–∏, –Ω–æ —Å—Ç—Ä—É–∫—Ç—É—Ä–∞ –∏ —Å–æ–¥–µ—Ä–∂–∞–Ω–∏–µ —Ö–æ—Ä–æ—à–∏–µ."
    elif total_score >= 60:
        feedback = "–£–¥–æ–≤–ª–µ—Ç–≤–æ—Ä–∏—Ç–µ–ª—å–Ω–æ. –ù—É–∂–Ω–æ –±–æ–ª—å—à–µ –ø—Ä–∞–∫—Ç–∏–∫–∏ —Å –≥—Ä–∞–º–º–∞—Ç–∏–∫–æ–π."
    elif total_score >= 50:
        feedback = "–¢—Ä–µ–±—É–µ—Ç—Å—è —É–ª—É—á—à–µ–Ω–∏–µ. –û–±—Ä–∞—Ç–∏—Ç–µ –≤–Ω–∏–º–∞–Ω–∏–µ –Ω–∞ –≥—Ä–∞–º–º–∞—Ç–∏–∫—É –∏ —Å–ª–æ–≤–∞—Ä–Ω—ã–π –∑–∞–ø–∞—Å."
    else:
        feedback = "–ù–µ—É–¥–æ–≤–ª–µ—Ç–≤–æ—Ä–∏—Ç–µ–ª—å–Ω–æ. –¢—Ä–µ–±—É–µ—Ç—Å—è –∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω–∞—è –ø—Ä–∞–∫—Ç–∏–∫–∞."
    
    return {
        "score": int(total_score),
        "detailed_scores": scores,
        "feedback": feedback,
        "suggestions": [
            f"–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–æ {char_count} –∏–µ—Ä–æ–≥–ª–∏—Ñ–æ–≤ –∏–∑ {req_count} —Ç—Ä–µ–±—É–µ–º—ã—Ö",
            f"–£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –∏–µ—Ä–æ–≥–ª–∏—Ñ–æ–≤: {unique_chars}",
            "–†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è: –±–æ–ª—å—à–µ –ø—Ä–∞–∫—Ç–∏–∫–∏ —Å –≥—Ä–∞–º–º–∞—Ç–∏—á–µ—Å–∫–∏–º–∏ –∫–æ–Ω—Å—Ç—Ä—É–∫—Ü–∏—è–º–∏"
        ]
    }

# –ì–ª–æ–±–∞–ª—å–Ω—ã–π —ç–∫–∑–µ–º–ø–ª—è—Ä
test_generator = HSKTestGenerator()

# ========== API —Ñ—É–Ω–∫—Ü–∏–∏ ==========

async def generate_hsk_test_api(level: int, test_type: str = "adaptive") -> Dict:
    """API: –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ç–µ—Å—Ç–∞ HSK"""
    return await test_generator.generate_full_test(level, test_type)

async def evaluate_writing_api(text: str, task_data: Dict) -> Dict:
    """API: –û—Ü–µ–Ω–∫–∞ –ø–∏—Å—å–º–µ–Ω–Ω–æ–π —Ä–∞–±–æ—Ç—ã"""
    return await test_generator.evaluate_writing(text, task_data)

async def evaluate_speaking_api(audio_text: str, task_data: Dict) -> Dict:
    """API: –û—Ü–µ–Ω–∫–∞ —É—Å—Ç–Ω–æ–π —Ä–µ—á–∏ (—É–ø—Ä–æ—â–µ–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è)"""
    # –ë–æ–ª–µ–µ —Ä–µ–∞–ª–∏—Å—Ç–∏—á–Ω–∞—è –æ—Ü–µ–Ω–∫–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ç–µ–∫—Å—Ç–∞
    # –ü—Ä–æ—Å—Ç–∞—è –ª–æ–≥–∏–∫–∞: –ø—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤ –∏ –¥–ª–∏–Ω—É –æ—Ç–≤–µ—Ç–∞
    
    text_length = len(audio_text)
    keywords = task_data.get('keywords', '').split(',') if task_data.get('keywords') else []
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤
    keyword_score = 0
    if keywords:
        found_keywords = sum(1 for kw in keywords if kw.strip() in audio_text)
        keyword_score = (found_keywords / len(keywords)) * 30  # 30 –±–∞–ª–ª–æ–≤ –∑–∞ –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞
    
    # –û—Ü–µ–Ω–∫–∞ –∑–∞ –¥–ª–∏–Ω—É (–º–∞–∫—Å–∏–º—É–º 30 –±–∞–ª–ª–æ–≤)
    length_score = min(30, (text_length / 50) * 30)
    
    # –ë–∞–∑–æ–≤–∞—è –æ—Ü–µ–Ω–∫–∞ –∑–∞ —Å—Ç—Ä—É–∫—Ç—É—Ä—É (–º–∞–∫—Å–∏–º—É–º 40 –±–∞–ª–ª–æ–≤)
    structure_score = 40 if any(marker in audio_text for marker in ['„ÄÇ', 'Ôºå', 'Âõ†‰∏∫', 'ÊâÄ‰ª•']) else 20
    
    total_score = min(100, int(keyword_score + length_score + structure_score))
    
    return {
        "score": total_score,
        "pronunciation": random.randint(total_score - 10, total_score + 10),
        "fluency": random.randint(total_score - 10, total_score + 10),
        "accuracy": total_score,
        "feedback": f"–û—Ü–µ–Ω–∫–∞ –æ—Å–Ω–æ–≤–∞–Ω–∞ –Ω–∞ –∞–Ω–∞–ª–∏–∑–µ —Ç–µ–∫—Å—Ç–∞. –î–ª–∏–Ω–∞: {text_length} –∏–µ—Ä–æ–≥–ª–∏—Ñ–æ–≤.",
        "details": {
            "keyword_score": int(keyword_score),
            "length_score": int(length_score),
            "structure_score": structure_score
        }
    }

async def generate_certificate_api(test_results: Dict, user_data: Dict) -> Dict:
    """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Å–µ—Ä—Ç–∏—Ñ–∏–∫–∞—Ç–∞"""
    total_score = test_results.get("total_score", 0)
    level = test_results.get("level", 1)
    
    return {
        "certificate_id": f"CERT_{datetime.now().strftime('%Y%m%d')}_{user_data.get('user_id', '000')}",
        "user_name": user_data.get("name", "–°—Ç—É–¥–µ–Ω—Ç"),
        "level": level,
        "total_score": total_score,
        "date": datetime.now().strftime("%YÂπ¥%mÊúà%dÊó•"),
        "result": "ÂêàÊ†º" if total_score >= (180 if level >= 3 else 120) else "‰∏çÂêàÊ†º",
        "ai_generated": test_results.get("ai_generated", False)
    }

async def generate_progress_report_api(test_results: Dict, user_data: Dict) -> Dict:
    """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç—á–µ—Ç–∞ –æ –ø—Ä–æ–≥—Ä–µ—Å—Å–µ"""
    scores = {
        "listening": test_results.get("listening_score", 0),
        "reading": test_results.get("reading_score", 0),
        "writing": test_results.get("writing_score", 0),
        "total": test_results.get("total_score", 0)
    }
    
    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Å–∏–ª—å–Ω—ã–µ –∏ —Å–ª–∞–±—ã–µ —Å—Ç–æ—Ä–æ–Ω—ã
    strengths = []
    weaknesses = []
    
    if scores["listening"] > 80:
        strengths.append("–ê—É–¥–∏—Ä–æ–≤–∞–Ω–∏–µ")
    elif scores["listening"] < 60:
        weaknesses.append("–ê—É–¥–∏—Ä–æ–≤–∞–Ω–∏–µ")
    
    if scores["reading"] > 80:
        strengths.append("–ß—Ç–µ–Ω–∏–µ")
    elif scores["reading"] < 60:
        weaknesses.append("–ß—Ç–µ–Ω–∏–µ")
    
    if scores["writing"] > 70:
        strengths.append("–ü–∏—Å—å–º–æ")
    elif scores["writing"] < 50:
        weaknesses.append("–ü–∏—Å—å–º–æ")
    
    return {
        "report_id": f"REPORT_{datetime.now().strftime('%Y%m%d_%H%M%S')}",
        "user_name": user_data.get("name", "–°—Ç—É–¥–µ–Ω—Ç"),
        "test_date": datetime.now().strftime("%Y-%m-%d"),
        "level": test_results.get("level", 1),
        "scores": scores,
        "strengths": strengths if strengths else ["–£—Å–µ—Ä–¥–∏–µ", "–ú–æ—Ç–∏–≤–∞—Ü–∏—è"],
        "weaknesses": weaknesses if weaknesses else ["–ù—É–∂–Ω–∞ –ø—Ä–∞–∫—Ç–∏–∫–∞"],
        "recommendations": [
            "–†–µ–≥—É–ª—è—Ä–Ω–æ —Å–ª—É—à–∞–π—Ç–µ –∫–∏—Ç–∞–π—Å–∫—É—é —Ä–µ—á—å",
            "–ß–∏—Ç–∞–π—Ç–µ –∫–æ—Ä–æ—Ç–∫–∏–µ —Ç–µ–∫—Å—Ç—ã –∫–∞–∂–¥—ã–π –¥–µ–Ω—å",
            "–ü–∏—à–∏—Ç–µ —Ö–æ—Ç—è –±—ã 2-3 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –≤ –¥–µ–Ω—å"
        ]
    }