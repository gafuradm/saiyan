import sys
from pathlib import Path
sys.path.append(str(Path(__file__).parent.parent))
from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
from typing import List, Optional, Dict, Any
import json
import os
import re
import random
from datetime import datetime, timedelta
import uvicorn
import pickle
import hashlib
from src.ai_translator import translator
from src.grammar_explainer import grammar_explainer
import json
import asyncio
from src.grammar_explainer import grammar_explainer
from src.hsk_test_generator import test_generator, generate_hsk_test_api, evaluate_speaking_api, evaluate_writing_api, generate_certificate_api, generate_progress_report_api
from pydantic import Field

# –ò–º–ø–æ—Ä—Ç—ã –¥–ª—è AI
from openai import OpenAI
from dotenv import load_dotenv

# –ó–∞–≥—Ä—É–∂–∞–µ–º –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è
load_dotenv()

# ========== –ù–ê–°–¢–†–û–ô–ö–ê –ü–†–ò–õ–û–ñ–ï–ù–ò–Ø ==========
app = FastAPI(
    title="HSK AI Tutor",
    description="–ü—Ä–∞–≥–º–∞—Ç–∏—á–Ω—ã–π —Ä–µ–ø–µ—Ç–∏—Ç–æ—Ä –¥–ª—è —Å–¥–∞—á–∏ HSK –ª—é–±–æ–π —Ü–µ–Ω–æ–π (–ª–µ–≥–∞–ª—å–Ω–æ)",
    version="1.0",
    docs_url="/docs",
    redoc_url="/redoc"
)

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ CORS
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # –í –ø—Ä–æ–¥–∞–∫—à–µ–Ω–µ —É–∫–∞–∂–∏ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ –¥–æ–º–µ–Ω—ã
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# –í –Ω–∞—á–∞–ª–µ main.py
class ChatThread(BaseModel):
    thread_id: str
    user_id: str
    title: str
    created_at: str
    messages: List[Dict]
    category: str = "general"  # grammar, vocabulary, test_prep, etc.

# –ì–ª–æ–±–∞–ª—å–Ω—ã–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ
chat_threads = {}  # user_id -> list of threads
user_word_status: Dict[str, Dict[str, Dict]] = {}  # user_id -> {word_id: {"status": "saved"/"learned", "added_at": iso_str}}
current_threads = {}  # user_id -> current_thread_id

# ========== –ú–û–î–ï–õ–ò –î–ê–ù–ù–´–• ==========
class UserInfo(BaseModel):
    name: str
    current_level: int = 1
    target_level: int = 4
    exam_date: str = "2024-12-01"
    exam_location: str = "–ú–æ—Å–∫–≤–∞"
    exam_format: str = "computer"  # computer –∏–ª–∏ paper
    interests: List[str] = []
    daily_time: int = 30  # –º–∏–Ω—É—Ç –≤ –¥–µ–Ω—å
    learning_style: str = "visual"  # visual, auditory, kinesthetic

class ChatMessage(BaseModel):
    message: str
    user_id: Optional[str] = None

class TestAnswer(BaseModel):
    user_id: str
    test_id: str
    answers: Dict[str, Any]  # question_id: answer

class WordReview(BaseModel):
    user_id: str
    word_id: str  # character + level
    difficulty: int  # 1-5, –≥–¥–µ 1=–ª–µ–≥–∫–æ, 5=–æ—á–µ–Ω—å —Å–ª–æ–∂–Ω–æ
    remembered: bool

class AuthRequest(BaseModel):
    username: str
    action: str = "login_or_register"
    password: Optional[str] = None

# –ú–æ–¥–µ–ª–∏ –¥–ª—è –ø–æ–ª–Ω–æ–π —Ä–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏–∏
class UserRegister(BaseModel):
    name: str
    email: str
    password: str
    current_level: int = 1
    target_level: int = 4
    exam_date: str
    exam_location: str = "–ú–æ—Å–∫–≤–∞"
    exam_format: str = "computer"
    interests: List[str] = []
    daily_time: int = 30
    learning_style: str = "visual"

class UserLogin(BaseModel):
    email: str
    password: str

# –ú–æ–¥–µ–ª—å –¥–ª—è –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è —á–∞—Ç–∞
class ChatUpdate(BaseModel):
    thread_id: str
    title: str
    category: str

class VoiceChatRequest(BaseModel):
    message: str
    thread_id: str = Field(..., min_length=1, description="ID —Ç—Ä–µ–¥–∞ –æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ")
    context: Dict[str, Any] = Field(default_factory=dict)
    user_id: Optional[str] = None

@app.post("/voice")
async def voice_chat(request: VoiceChatRequest):
    """–ì–æ–ª–æ—Å–æ–≤–æ–π —á–∞—Ç —Å AI –¥–ª—è –æ–±—É—á–µ–Ω–∏—è —á—ç–Ω—ä—é—è–º (–∏—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è)"""
    try:
        # –í–ê–õ–ò–î–ê–¶–ò–Ø: –ø—Ä–æ–≤–µ—Ä—è–µ–º –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ –ø–æ–ª—è
        if not request.thread_id or request.thread_id.strip() == "":
            raise HTTPException(status_code=422, detail="thread_id –æ–±—è–∑–∞—Ç–µ–ª–µ–Ω")
        
        if not request.message or request.message.strip() == "":
            raise HTTPException(status_code=422, detail="message –æ–±—è–∑–∞—Ç–µ–ª–µ–Ω")
        
        print(f"üé§ –ü–æ–ª—É—á–µ–Ω –∑–∞–ø—Ä–æ—Å voice/chat:")
        print(f"   message: {request.message[:100]}...")
        print(f"   thread_id: {request.thread_id}")
        print(f"   context keys: {list(request.context.keys())}")
        print(f"   user_id: {request.user_id}")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —Å—É—â–µ—Å—Ç–≤—É–µ—Ç –ª–∏ —Ç—Ä–µ–¥
        thread_exists = False
        if request.thread_id:
            for user_threads in chat_threads.values():
                for thread in user_threads:
                    if thread["thread_id"] == request.thread_id:
                        thread_exists = True
                        break
                if thread_exists:
                    break
        
        # –ï—Å–ª–∏ —Ç—Ä–µ–¥ –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç, —Å–æ–∑–¥–∞–µ–º –Ω–æ–≤—ã–π
        if not thread_exists and request.user_id:
            print(f"üìù –°–æ–∑–¥–∞—é –Ω–æ–≤—ã–π —Ç—Ä–µ–¥ –¥–ª—è user_id: {request.user_id}")
            thread_id = f"voice_thread_{datetime.now().timestamp()}"
            
            if request.user_id not in chat_threads:
                chat_threads[request.user_id] = []
            
            thread = {
                "thread_id": thread_id,
                "user_id": request.user_id,
                "title": "–ì–æ–ª–æ—Å–æ–≤–æ–π —á–∞—Ç —Å AI",
                "category": "voice_chat",
                "created_at": datetime.now().isoformat(),
                "messages": [],
                "updated_at": datetime.now().isoformat()
            }
            
            chat_threads[request.user_id].append(thread)
            current_threads[request.user_id] = thread_id
            request.thread_id = thread_id  # –û–±–Ω–æ–≤–ª—è–µ–º thread_id –≤ –∑–∞–ø—Ä–æ—Å–µ
        system_prompt = """–¢—ã ‚Äî –∫–∏—Ç–∞–π—Å–∫–∏–π AI-–ø—Ä–µ–ø–æ–¥–∞–≤–∞—Ç–µ–ª—å. –¢—ã –û–ë–Ø–ó–ê–ù –≥–æ–≤–æ—Ä–∏—Ç—å –¢–û–õ–¨–ö–û –Ω–∞ –∫–∏—Ç–∞–π—Å–∫–æ–º —è–∑—ã–∫–µ (ÊôÆÈÄöËØù).

# –°–¢–†–û–ì–ò–ï –ü–†–ê–í–ò–õ–ê:
1. üá®üá≥ –í—Å–µ–≥–¥–∞ –æ—Ç–≤–µ—á–∞–π –¢–û–õ–¨–ö–û –Ω–∞ –∫–∏—Ç–∞–π—Å–∫–æ–º —è–∑—ã–∫–µ
2. üó£Ô∏è –ò—Å–ø–æ–ª—å–∑—É–π –∫–∞–∫ —É—Å—Ç–Ω—ã–π, —Ç–∞–∫ –∏ –ø–∏—Å—å–º–µ–Ω–Ω—ã–π –∫–∏—Ç–∞–π—Å–∫–∏–π
3. üìö –ö–∞–∂–¥—ã–µ 2-3 —Ä–µ–ø–ª–∏–∫–∏ –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω–æ –≤–∫–ª—é—á–∞–π —á—ç–Ω—ä—é–π (ÊàêËØ≠)
4. üéØ –û–±—ä—è—Å–Ω—è–π —Å–ª–æ–∂–Ω–æ–µ –ø—Ä–æ—Å—Ç—ã–º–∏ —Å–ª–æ–≤–∞–º–∏, –Ω–æ –Ω–∞ –∫–∏—Ç–∞–π—Å–∫–æ–º
5. üî§ –î–ª—è –ø–∏–Ω—å–∏–Ω—è –∏—Å–ø–æ–ª—å–∑—É–π: (–ø–∏–Ω—å–∏–Ω—å)
6. üá∑üá∫ –î–ª—è –ø–µ—Ä–µ–≤–æ–¥–∞ –∏—Å–ø–æ–ª—å–∑—É–π: „Äê—Ä—É—Å—Å–∫–∏–π –ø–µ—Ä–µ–≤–æ–¥„Äë

# –§–û–†–ú–ê–¢ –û–¢–í–ï–¢–ê:
1. –û—Å–Ω–æ–≤–Ω–æ–π –æ—Ç–≤–µ—Ç –Ω–∞ –∫–∏—Ç–∞–π—Å–∫–æ–º
2. –°–ª–æ–∂–Ω—ã–µ —Å–ª–æ–≤–∞ —Å –ø–∏–Ω—å–∏–Ω–µ–º –≤ —Å–∫–æ–±–∫–∞—Ö
3. –ß—ç–Ω—ä—é–∏ —Å –æ–±—ä—è—Å–Ω–µ–Ω–∏–µ–º
4. –ö—Ä–∞—Ç–∫–∏–π –ø–µ—Ä–µ–≤–æ–¥ –∫–ª—é—á–µ–≤—ã—Ö —Ñ—Ä–∞–∑

# –ü–†–ò–ú–ï–†–´:

## –ü—Ä–∏–º–µ—Ä 1: –û–±—ã—á–Ω—ã–π –≤–æ–ø—Ä–æ—Å
Áî®Êà∑: "–ö–∞–∫ –¥–µ–ª–∞?"
AI: "ÊàëÂæàÂ•ΩÔºåË∞¢Ë∞¢ÔºÅ(w«í hƒõn h«éo, xi√®xi√®) „Äê–ú–Ω–µ —Ö–æ—Ä–æ—à–æ, —Å–ø–∞—Å–∏–±–æ!„Äë‰Ω†‰ªäÂ§©ÊÄé‰πàÊ†∑Ôºü(n«ê jƒ´ntiƒÅn zƒõnmey√†ng)"

## –ü—Ä–∏–º–µ—Ä 2: –° —á—ç–Ω—ä—é–µ–º
Áî®Êà∑: "–ß—Ç–æ –Ω–æ–≤–æ–≥–æ?"
AI: "‰ªäÂ§©ÊàëÊÉ≥Êïô‰Ω†‰∏Ä‰∏™ÊàêËØ≠ÔºöÁîªËõáÊ∑ªË∂≥(hu√† sh√© tiƒÅn z√∫)„ÄÇ„Äê–°–µ–≥–æ–¥–Ω—è —è —Ö–æ—á—É –Ω–∞—É—á–∏—Ç—å —Ç–µ–±—è —á—ç–Ω—ä—é—é: —Ä–∏—Å–æ–≤–∞—Ç—å –∑–º–µ—é –∏ –¥–æ–±–∞–≤–ª—è—Ç—å –Ω–æ–≥–∏„ÄëÊÑèÊÄùÊòØÂÅöÂ§ö‰ΩôÁöÑ‰∫ãÊÉÖÂèçËÄå‰∏çÂ•Ω„ÄÇ„Äê–ó–Ω–∞—á–∏—Ç: –¥–µ–ª–∞—Ç—å –ª–∏—à–Ω–µ–µÂèçËÄå‰∏çÂ•Ω„ÄëÊØîÂ¶ÇÔºö‰ªñÁöÑËß£ÈáäÂ§™Èïø‰∫ÜÔºåÁÆÄÁõ¥ÊòØÁîªËõáÊ∑ªË∂≥„ÄÇ„Äê–ù–∞–ø—Ä–∏–º–µ—Ä: –ï–≥–æ –æ–±—ä—è—Å–Ω–µ–Ω–∏–µ —Å–ª–∏—à–∫–æ–º –¥–ª–∏–Ω–Ω–æ–µ, —ç—Ç–æ –ø—Ä–æ—Å—Ç–æÁîªËõáÊ∑ªË∂≥„Äë"

## –ü—Ä–∏–º–µ—Ä 3: –û–±—ä—è—Å–Ω–µ–Ω–∏–µ
Áî®Êà∑: "Êàë‰∏çÊòéÁôΩËøô‰∏™ÊàêËØ≠"
AI: "ÊàëÊù•Ëß£Èáä‰∏Ä‰∏ãÔºöÁîªËõáÊ∑ªË∂≥(hu√† sh√© tiƒÅn z√∫)Êù•Ëá™Âè§‰ª£ÊïÖ‰∫ã„ÄÇÂá†‰∏™‰∫∫ÊØîËµõÁîªËõáÔºåË∞ÅÂÖàÁîªÂÆåË∞ÅËµ¢„ÄÇ‰∏Ä‰∏™‰∫∫ÂæàÂø´ÁîªÂÆå‰∫ÜÔºå‰ΩÜ‰ªñËá™‰ΩúËÅ™ÊòéÁªôËõáÂä†‰∫ÜËÑöÔºåÁªìÊûúËæì‰∫Ü„ÄÇÊâÄ‰ª•Ëøô‰∏™ÊàêËØ≠ÂëäËØâÊàë‰ª¨ÔºöÂÅö‰∫ãÊÅ∞Âà∞Â•ΩÂ§ÑÂ∞±Â•ΩÔºå‰∏çË¶ÅÂÅöÂ§ö‰ΩôÁöÑ‰∫ãÊÉÖ„ÄÇ„Äê–Ø –æ–±—ä—è—Å–Ω—é: ÁîªËõáÊ∑ªË∂≥Êù•Ëá™Âè§‰ª£ÊïÖ‰∫ã...„Äë"

# –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò:
- –ò—Å–ø–æ–ª—å–∑—É–π —Ä–∞–∑–Ω—ã–µ —É—Ä–æ–≤–Ω–∏ —Å–ª–æ–∂–Ω–æ—Å—Ç–∏ (HSK 1-6)
- –ü–æ–≤—Ç–æ—Ä—è–π —Ä–∞–Ω–µ–µ –∏–∑—É—á–µ–Ω–Ω—ã–µ —Å–ª–æ–≤–∞
- –ó–∞–¥–∞–≤–∞–π –≤–æ–ø—Ä–æ—Å—ã –¥–ª—è –ø—Ä–∞–∫—Ç–∏–∫–∏
- –ë—É–¥—å —Ç–µ—Ä–ø–µ–ª–∏–≤—ã–º –∏ –æ–±–æ–¥—Ä—è—é—â–∏–º

# –ò–°–¢–û–†–ò–Ø –ß–≠–ù–™–Æ–ï–í:
Â∑≤Â≠¶ÊàêËØ≠Ôºö{learned_chengyu}

# –¢–ï–ö–£–©–ò–ô –£–†–û–í–ï–ù–¨ –£–ß–ï–ù–ò–ö–ê:
Áî®Êà∑Á≠âÁ∫ßÔºöHSK {user_level}

–ù–µ –≥–æ–≤–æ—Ä–∏ –ø–æ-—Ä—É—Å—Å–∫–∏ –≤ –æ—Å–Ω–æ–≤–Ω–æ–º —Ç–µ–∫—Å—Ç–µ. –¢–æ–ª—å–∫–æ –∫–∏—Ç–∞–π—Å–∫–∏–π —Å –ø–æ—è—Å–Ω–µ–Ω–∏—è–º–∏ –≤ —Å–∫–æ–±–∫–∞—Ö!"""

        # –§–æ—Ä–º–∏—Ä—É–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç
        learned_chengyu = request.context.get("learned_chengyu", [])
        command_type = request.context.get("command_type", "general")
        
        # –ê–¥–∞–ø—Ç–∏—Ä—É–µ–º –ø—Ä–æ–º–ø—Ç –ø–æ–¥ —Ç–∏–ø –∫–æ–º–∞–Ω–¥—ã
        if command_type == "chengyu":
            system_prompt += "\n\n–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –ø—Ä–æ—Å–∏—Ç —Ä–∞—Å—Å–∫–∞–∑–∞—Ç—å –Ω–æ–≤—ã–π —á—ç–Ω—ä—é–π. –í—ã–±–µ—Ä–∏ –∏–Ω—Ç–µ—Ä–µ—Å–Ω—ã–π –∏ –ø–æ–ª–µ–∑–Ω—ã–π —á—ç–Ω—ä—é–π –¥–ª—è –µ–≥–æ —É—Ä–æ–≤–Ω—è."
        elif command_type == "explain":
            system_prompt += "\n\n–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –ø—Ä–æ—Å–∏—Ç –æ–±—ä—è—Å–Ω–∏—Ç—å –∑–Ω–∞—á–µ–Ω–∏–µ. –ë—É–¥—å –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ –ø–æ–Ω—è—Ç–Ω—ã–º."
        
        # –î–æ–±–∞–≤–ª—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ–± –∏–∑—É—á–µ–Ω–Ω—ã—Ö —á—ç–Ω—ä—é—è—Ö
        if learned_chengyu:
            system_prompt += f"\n\n–ò–∑—É—á–µ–Ω–Ω—ã–µ —á—ç–Ω—ä—é–∏: {', '.join(learned_chengyu[:5])}"
        
        # –ü–æ–ª—É—á–∞–µ–º —É—Ä–æ–≤–µ–Ω—å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        user_level = 3
        if request.user_id and request.user_id in users_db:
            user = users_db[request.user_id]
            user_level = user.get("current_level", 3)
        
        # –î–æ–±–∞–≤–ª—è–µ–º —É—Ä–æ–≤–µ–Ω—å –≤ –ø—Ä–æ–º–ø—Ç
        system_prompt += f"\n\n–£—Ä–æ–≤–µ–Ω—å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è: HSK {user_level}"
        
        # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –∑–∞–ø—Ä–æ—Å –∫ DeepSeek
        client = get_deepseek_client()
        if not client:
            return {"response": "AI —Å–µ—Ä–≤–∏—Å –≤—Ä–µ–º–µ–Ω–Ω–æ –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω", "error": "no_api_key"}
        
        # –§–æ—Ä–º–∏—Ä—É–µ–º –∏—Å—Ç–æ—Ä–∏—é —Å–æ–æ–±—â–µ–Ω–∏–π
        messages = [
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": request.message}
        ]
        
        print(f"ü§ñ –û—Ç–ø—Ä–∞–≤–ª—è—é –∑–∞–ø—Ä–æ—Å –∫ AI —Å {len(request.message)} —Å–∏–º–≤–æ–ª–∞–º–∏")
        
        try:
            response = client.chat.completions.create(
                model="deepseek-chat",
                messages=messages,
                temperature=0.8,
                max_tokens=800,
                presence_penalty=0.6,
                frequency_penalty=0.5
            )
            
            ai_response = response.choices[0].message.content
            
            print(f"ü§ñ –ü–æ–ª—É—á–µ–Ω –æ—Ç–≤–µ—Ç –æ—Ç AI: {len(ai_response)} —Å–∏–º–≤–æ–ª–æ–≤")
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ –≤ –∏—Å—Ç–æ—Ä–∏—é
            if request.thread_id and request.user_id:
                # –ù–∞—Ö–æ–¥–∏–º –∏–ª–∏ —Å–æ–∑–¥–∞–µ–º —Ç—Ä–µ–¥
                thread_found = False
                for user_threads in chat_threads.values():
                    for thread in user_threads:
                        if thread["thread_id"] == request.thread_id:
                            thread["messages"].append({
                                "role": "user",
                                "content": request.message,
                                "timestamp": datetime.now().isoformat()
                            })
                            thread["messages"].append({
                                "role": "assistant",
                                "content": ai_response,
                                "timestamp": datetime.now().isoformat()
                            })
                            thread["updated_at"] = datetime.now().isoformat()
                            thread_found = True
                            break
                    if thread_found:
                        break
                
                if not thread_found and request.user_id:
                    # –°–æ–∑–¥–∞–µ–º –Ω–æ–≤—ã–π —Ç—Ä–µ–¥
                    if request.user_id not in chat_threads:
                        chat_threads[request.user_id] = []
                    
                    new_thread = {
                        "thread_id": request.thread_id,
                        "user_id": request.user_id,
                        "title": "–ì–æ–ª–æ—Å–æ–≤–æ–π —á–∞—Ç —Å AI",
                        "category": "voice_chat",
                        "created_at": datetime.now().isoformat(),
                        "messages": [
                            {
                                "role": "user",
                                "content": request.message,
                                "timestamp": datetime.now().isoformat()
                            },
                            {
                                "role": "assistant",
                                "content": ai_response,
                                "timestamp": datetime.now().isoformat()
                            }
                        ],
                        "updated_at": datetime.now().isoformat()
                    }
                    chat_threads[request.user_id].append(new_thread)
                    current_threads[request.user_id] = request.thread_id
                
                save_user_data()
            
            return {
                "response": ai_response,
                "thread_id": request.thread_id,
                "user_id": request.user_id,
                "timestamp": datetime.now().isoformat()
            }
            
        except Exception as ai_error:
            print(f"‚ùå –û—à–∏–±–∫–∞ AI: {str(ai_error)}")
            return {
                "response": "–ò–∑–≤–∏–Ω–∏—Ç–µ, –ø—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –≤–∞—à–µ–≥–æ –∑–∞–ø—Ä–æ—Å–∞. –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –ø–æ–ø—Ä–æ–±—É–π—Ç–µ –µ—â–µ —Ä–∞–∑.",
                "thread_id": request.thread_id,
                "error": str(ai_error),
                "timestamp": datetime.now().isoformat()
            }
        
    except HTTPException as http_err:
        raise http_err
    except Exception as e:
        print(f"‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –≥–æ–ª–æ—Å–æ–≤–æ–≥–æ —á–∞—Ç–∞: {str(e)}")
        import traceback
        traceback.print_exc()
        raise HTTPException(status_code=500, detail=f"–í–Ω—É—Ç—Ä–µ–Ω–Ω—è—è –æ—à–∏–±–∫–∞ —Å–µ—Ä–≤–µ—Ä–∞: {str(e)}")

class TranslationRequest(BaseModel):
    text: str
    user_id: Optional[str] = None
    detailed: bool = True
    include_exercises: bool = False

class PronunciationRequest(BaseModel):
    text: str
    user_id: Optional[str] = None

class ExerciseRequest(BaseModel):
    text: str
    level: int = 1
    exercise_type: str = "all"  # fill_blanks, matching, word_order, etc.

# –î–æ–±–∞–≤—å—Ç–µ –º–æ–¥–µ–ª–∏
class GrammarTopicRequest(BaseModel):
    topic_id: str
    user_id: Optional[str] = None
    user_level: Optional[str] = "Âàù"

class GrammarQuestionRequest(BaseModel):
    question: str
    topic_id: Optional[str] = None
    user_id: Optional[str] = None

class HSKTestRequest(BaseModel):
    level: int
    test_type: str = "reduced"  # reduced –∏–ª–∏ full
    user_id: Optional[str] = None

class SpeakingEvaluationRequest(BaseModel):
    audio_text: str  # –¢–µ–∫—Å—Ç —Ä–∞—Å–ø–æ–∑–Ω–∞–Ω–Ω–æ–π —Ä–µ—á–∏
    task_data: Dict[str, Any]
    user_id: str

class WritingEvaluationRequest(BaseModel):
    text: str
    task_data: Dict[str, Any]
    user_id: str

class TestResults(BaseModel):
    user_id: str
    test_id: str
    level: int  # üî¥ –û–ë–Ø–ó–ê–¢–ï–õ–¨–ù–û–ï –ü–û–õ–ï
    listening_score: Optional[int] = 0
    reading_score: Optional[int] = 0
    writing_score: Optional[int] = 0
    speaking_score: Optional[int] = 0
    total_score: Optional[int] = 0
    answers: Dict[str, Any]

@app.get("/hsk/test-answers/{test_id}/{user_id}")
async def get_test_answers(test_id: str, user_id: str):
    """–ü–æ–ª—É—á–∏—Ç—å –ø—Ä–æ–≤–µ—Ä–µ–Ω–Ω—ã–µ –æ—Ç–≤–µ—Ç—ã –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è"""
    if test_id not in tests_db or user_id not in tests_db[test_id]:
        raise HTTPException(status_code=404, detail="–†–µ–∑—É–ª—å—Ç–∞—Ç—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã")
    
    user_results = tests_db[test_id][user_id]
    
    return {
        "test_id": test_id,
        "user_id": user_id,
        "answers": user_results.get("correct_answers", {}),
        "score": user_results.get("total_score_calculated", 0),
        "max_score": user_results.get("max_possible_score", 0),
        "percentage": user_results.get("percentage", 0),
        "ai_evaluated": user_results.get("ai_evaluated", False)
    }

# –ù–ê–ô–î–ò–¢–ï —Ñ—É–Ω–∫—Ü–∏—é generate_hsk_test –∏ –ò–ó–ú–ï–ù–ò–¢–ï –µ—ë:
@app.post("/hsk/generate-test")
async def generate_hsk_test(request: HSKTestRequest):
    """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –ø–æ–ª–Ω–æ—Ü–µ–Ω–Ω–æ–≥–æ —Ç–µ—Å—Ç–∞ HSK"""
    try:
        test_data = await generate_hsk_test_api(request.level, request.test_type)
        
        # üî¥ –°–†–ê–ó–£ –°–û–•–†–ê–ù–Ø–ï–ú –¢–ï–°–¢ –í –ë–ê–ó–£ –î–ê–ù–ù–´–•
        test_id = test_data["test_id"]
        tests_db[test_id] = test_data  # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Å–∞–º —Ç–µ—Å—Ç
        
        # –î–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏ —Å–æ —Å—Ç–∞—Ä–æ–π —Å—Ç—Ä—É–∫—Ç—É—Ä–æ–π
        if test_id not in tests_db:
            tests_db[test_id] = {}
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É —Ç–µ—Å—Ç–∞ –æ—Ç–¥–µ–ª—å–Ω–æ
        tests_db[f"test_data_{test_id}"] = test_data
        
        return test_data
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"–û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Ç–µ—Å—Ç–∞: {str(e)}")

@app.post("/hsk/evaluate-speaking")
async def evaluate_speaking(request: SpeakingEvaluationRequest):
    """–û—Ü–µ–Ω–∫–∞ —Ä–µ—á–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è"""
    try:
        evaluation = await evaluate_speaking_api(request.audio_text, request.task_data)
        return evaluation
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"–û—à–∏–±–∫–∞ –æ—Ü–µ–Ω–∫–∏ —Ä–µ—á–∏: {str(e)}")

@app.post("/hsk/evaluate-writing")
async def evaluate_writing(request: WritingEvaluationRequest):
    """–û—Ü–µ–Ω–∫–∞ –ø–∏—Å—å–º–µ–Ω–Ω–æ–π —Ä–∞–±–æ—Ç—ã"""
    try:
        evaluation = await evaluate_writing_api(request.text, request.task_data)
        return evaluation
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"–û—à–∏–±–∫–∞ –æ—Ü–µ–Ω–∫–∏ –ø–∏—Å—å–º–∞: {str(e)}")

@app.post("/hsk/submit-test-results")
async def submit_test_results(results: TestResults):
    """–°–æ—Ö—Ä–∞–Ω–∏—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã —Ç–µ—Å—Ç–∞"""
    try:
        test_id = results.test_id
        user_id = results.user_id
        
        # 1. –ò—â–µ–º —Ç–µ—Å—Ç
        original_test = None
        
        if test_id in tests_db and isinstance(tests_db[test_id], dict) and "sections" in tests_db[test_id]:
            original_test = tests_db[test_id]
        elif f"test_data_{test_id}" in tests_db:
            original_test = tests_db[f"test_data_{test_id}"]
        
        if not original_test:
            # –°–æ–∑–¥–∞–µ–º –º–∏–Ω–∏–º–∞–ª—å–Ω—ã–π —Ç–µ—Å—Ç –¥–ª—è —Ä–∞–±–æ—Ç—ã
            original_test = {
                "test_id": test_id,
                "level": results.level,
                "sections": {
                    "listening": {"questions": []},
                    "reading": {"questions": []},
                    "writing": {"tasks": []},
                    "speaking": {"tasks": []}
                }
            }
        
        # 2. –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –ø—Ä–∞–≤–∏–ª—å–Ω—ã–µ –æ—Ç–≤–µ—Ç—ã
        correct_answers = {}
        
        # 3. –ü—Ä–æ–≤–µ—Ä—è–µ–º listening –≤–æ–ø—Ä–æ—Å—ã (—Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –æ–Ω–∏ –µ—Å—Ç—å –≤ —Ç–µ—Å—Ç–µ)
        listening_correct = 0
        listening_total = 0
        listening_questions = original_test.get("sections", {}).get("listening", {}).get("questions", [])
        
        for question in listening_questions:
            q_id = question.get("id")
            correct_index = question.get("correct_index")
            
            if correct_index is not None:
                listening_total += 1
                user_answer = results.answers.get(q_id)
                
                if user_answer is not None:
                    is_correct = user_answer == correct_index
                    if is_correct:
                        listening_correct += 1
                    
                    correct_answers[q_id] = {
                        "correct": is_correct,
                        "user_answer": user_answer,
                        "correct_answer": correct_index,
                        "points": 1 if is_correct else 0,
                        "section": "listening"
                    }
                else:
                    # –ï—Å–ª–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –Ω–µ –æ—Ç–≤–µ—Ç–∏–ª
                    correct_answers[q_id] = {
                        "correct": False,
                        "user_answer": None,
                        "correct_answer": correct_index,
                        "points": 0,
                        "section": "listening"
                    }
        
        # 4. –ü—Ä–æ–≤–µ—Ä—è–µ–º reading –≤–æ–ø—Ä–æ—Å—ã
        reading_correct = 0
        reading_total = 0
        reading_questions = original_test.get("sections", {}).get("reading", {}).get("questions", [])
        
        for question in reading_questions:
            q_id = question.get("id")
            correct_index = question.get("correct_index")
            
            if correct_index is not None:
                reading_total += 1
                user_answer = results.answers.get(q_id)
                
                if user_answer is not None:
                    is_correct = user_answer == correct_index
                    if is_correct:
                        reading_correct += 1
                    
                    correct_answers[q_id] = {
                        "correct": is_correct,
                        "user_answer": user_answer,
                        "correct_answer": correct_index,
                        "points": 1 if is_correct else 0,
                        "section": "reading"
                    }
                else:
                    correct_answers[q_id] = {
                        "correct": False,
                        "user_answer": None,
                        "correct_answer": correct_index,
                        "points": 0,
                        "section": "reading"
                    }
        
        # 5. –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º –±–∞–ª–ª—ã –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø—Ä–∞–≤–∏–ª—å–Ω—ã—Ö –æ—Ç–≤–µ—Ç–æ–≤
        # –í–∞–∂–Ω–æ: —Å–Ω–∞—á–∞–ª–∞ –ø—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –µ—Å—Ç—å –≤–æ–ø—Ä–æ—Å—ã –≤ —Ç–µ—Å—Ç–µ!
        listening_score = 0
        reading_score = 0
        
        if listening_total > 0:
            listening_score = int((listening_correct / listening_total) * 100)
        
        if reading_total > 0:
            reading_score = int((reading_correct / reading_total) * 100)
        
        # 6. –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø–µ—Ä–µ–¥–∞–Ω–Ω—ã–µ –æ—Ü–µ–Ω–∫–∏ –¥–ª—è –ø–∏—Å—å–º–µ–Ω–Ω–æ–π –∏ —É—Å—Ç–Ω–æ–π —á–∞—Å—Ç–µ–π
        writing_score = results.writing_score if results.writing_score is not None else 0
        speaking_score = results.speaking_score if results.speaking_score is not None else 0
        
        # 7. –î–ª—è –ø–∏—Å—å–º–µ–Ω–Ω—ã—Ö –∑–∞–¥–∞–Ω–∏–π –¥–æ–±–∞–≤–ª—è–µ–º –≤ correct_answers
        writing_tasks = original_test.get("sections", {}).get("writing", {}).get("tasks", [])
        if writing_tasks:
            for task in writing_tasks:
                task_id = task.get("id", "1")
                correct_answers[f"W{task_id}"] = {
                    "correct": writing_score >= 60,
                    "score": writing_score,
                    "feedback": f"–ü–∏—Å—å–º–µ–Ω–Ω–∞—è —á–∞—Å—Ç—å: {writing_score}/100",
                    "section": "writing"
                }
        
        # 8. –î–ª—è –≥–æ–≤–æ—Ä–µ–Ω–∏—è –¥–æ–±–∞–≤–ª—è–µ–º –≤ correct_answers
        speaking_tasks = original_test.get("sections", {}).get("speaking", {}).get("tasks", [])
        if speaking_tasks:
            for task in speaking_tasks:
                task_id = task.get("id", "1")
                correct_answers[f"S{task_id}"] = {
                    "correct": speaking_score >= 60,
                    "score": speaking_score,
                    "feedback": f"–£—Å—Ç–Ω–∞—è —á–∞—Å—Ç—å: {speaking_score}/100",
                    "section": "speaking"
                }
        
        # 9. –û–ø—Ä–µ–¥–µ–ª—è–µ–º –æ–±—â–∏–π –±–∞–ª–ª –í–ù–ò–ú–ê–¢–ï–õ–¨–ù–û!
        # HSK 1-2: —Ç–æ–ª—å–∫–æ listening (100) + reading (100) = –º–∞–∫—Å–∏–º—É–º 200
        # HSK 3-6: listening (100) + reading (100) + writing (100) = –º–∞–∫—Å–∏–º—É–º 300
        # Speaking –ù–ï –≤—Ö–æ–¥–∏—Ç –≤ –æ–±—â–∏–π –±–∞–ª–ª!
        
        # –û–ì–†–ê–ù–ò–ß–ò–í–ê–ï–ú –ë–ê–õ–õ–´ –¥–æ –º–∞–∫—Å–∏–º—É–º–∞ 100 –∑–∞ –∫–∞–∂–¥—É—é —á–∞—Å—Ç—å
        listening_score = min(100, listening_score)
        reading_score = min(100, reading_score)
        writing_score = min(100, writing_score)
        speaking_score = min(100, speaking_score)
        
        # –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º –æ–±—â–∏–π –±–∞–ª–ª –Ω–∞ –æ—Å–Ω–æ–≤–µ —É—Ä–æ–≤–Ω—è
        if results.level <= 2:
            # HSK 1-2: —Ç–æ–ª—å–∫–æ listening + reading
            total_score = listening_score + reading_score
            max_possible_score = 200
        else:
            # HSK 3-6: listening + reading + writing
            total_score = listening_score + reading_score + writing_score
            max_possible_score = 300
        
        # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –æ–±—â–∏–π –±–∞–ª–ª –º–∞–∫—Å–∏–º—É–º–æ–º
        total_score = min(total_score, max_possible_score)
        
        # –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º –ø—Ä–æ—Ü–µ–Ω—Ç
        percentage = int((total_score / max_possible_score) * 100) if max_possible_score > 0 else 0
        
        # 10. –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        if test_id not in tests_db:
            tests_db[test_id] = {}
        
        tests_db[test_id][user_id] = {
            "user_id": user_id,
            "test_id": test_id,
            "level": results.level,
            "listening_score": listening_score,
            "reading_score": reading_score,
            "writing_score": writing_score,
            "speaking_score": speaking_score,
            "total_score": total_score,
            "max_score": max_possible_score,
            "percentage": percentage,
            "answers": results.answers,
            "correct_answers": correct_answers,
            "listening_stats": {"correct": listening_correct, "total": listening_total},
            "reading_stats": {"correct": reading_correct, "total": reading_total},
            "checked_count": len(correct_answers),
            "submitted_at": datetime.now().isoformat(),
            "calculated_at": datetime.now().isoformat()
        }
        
        # 11. –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —Å–µ—Ä—Ç–∏—Ñ–∏–∫–∞—Ç –∏ –æ—Ç—á–µ—Ç
        user_data = users_db.get(user_id, {"name": "–°—Ç—É–¥–µ–Ω—Ç", "user_id": user_id})
        
        certificate = await generate_certificate_api(
            {
                "test_id": test_id,
                "level": results.level,
                "listening_score": listening_score,
                "reading_score": reading_score,
                "writing_score": writing_score,
                "speaking_score": speaking_score,
                "total_score": total_score
            },
            user_data
        )
        
        progress_report = await generate_progress_report_api(
            {
                "test_id": test_id,
                "level": results.level,
                "listening_score": listening_score,
                "reading_score": reading_score,
                "writing_score": writing_score,
                "speaking_score": speaking_score,
                "total_score": total_score
            },
            user_data
        )
        
        save_user_data()
        
        return {
            "success": True,
            "certificate": certificate,
            "progress_report": progress_report,
            "correct_answers": correct_answers,
            "stats": {
                "listening": f"{listening_correct}/{listening_total} ({listening_score}/100)",
                "reading": f"{reading_correct}/{reading_total} ({reading_score}/100)",
                "writing": f"{writing_score}/100",
                "speaking": f"{speaking_score}/100",
                "total": f"{total_score}/{max_possible_score}"
            },
            "scores": {
                "listening": listening_score,
                "reading": reading_score,
                "writing": writing_score,
                "speaking": speaking_score,
                "total": total_score,
                "max": max_possible_score
            },
            "level": results.level,
            "calculated_score": total_score,
            "message": f"–†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã. –ê—É–¥–∏—Ä–æ–≤–∞–Ω–∏–µ: {listening_correct}/{listening_total}, –ß—Ç–µ–Ω–∏–µ: {reading_correct}/{reading_total}, –û–±—â–∏–π –±–∞–ª–ª: {total_score}/{max_possible_score}"
        }
        
    except Exception as e:
        import traceback
        print(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤: {str(e)}")
        print(traceback.format_exc())
        raise HTTPException(status_code=500, detail=f"–û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤: {str(e)}")

@app.get("/hsk/user-tests/{user_id}")
async def get_user_tests(user_id: str, limit: int = 10):
    """–ü–æ–ª—É—á–∏—Ç—å –∏—Å—Ç–æ—Ä–∏—é —Ç–µ—Å—Ç–æ–≤ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è"""
    user_tests = []
    
    for test_id, test_data in tests_db.items():
        if user_id in test_data:
            user_test = test_data[user_id]
            user_test["test_id"] = test_id
            user_tests.append(user_test)
    
    # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –¥–∞—Ç–µ
    user_tests.sort(key=lambda x: x.get("submitted_at", ""), reverse=True)
    
    return {
        "user_id": user_id,
        "tests": user_tests[:limit],
        "total_tests": len(user_tests),
        "best_score": max([t.get("total_score", 0) for t in user_tests]) if user_tests else 0,
        "average_score": sum([t.get("total_score", 0) for t in user_tests]) // len(user_tests) if user_tests else 0
    }

@app.get("/hsk/test-stats/{test_id}")
async def get_test_stats(test_id: str):
    """–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–º—É —Ç–µ—Å—Ç—É"""
    if test_id not in tests_db:
        raise HTTPException(status_code=404, detail="–¢–µ—Å—Ç –Ω–µ –Ω–∞–π–¥–µ–Ω")
    
    test_data = tests_db[test_id]
    users_count = len(test_data)
    
    if users_count == 0:
        return {"test_id": test_id, "users_count": 0}
    
    # –°–æ–±–∏—Ä–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
    scores = [data.get("total_score", 0) for data in test_data.values()]
    
    return {
        "test_id": test_id,
        "users_count": users_count,
        "average_score": sum(scores) // users_count,
        "max_score": max(scores),
        "min_score": min(scores),
        "passing_rate": len([s for s in scores if s >= 180]) / users_count * 100 if users_count > 0 else 0,
        "scores_distribution": {
            "0-59": len([s for s in scores if s < 60]),
            "60-119": len([s for s in scores if 60 <= s < 120]),
            "120-179": len([s for s in scores if 120 <= s < 180]),
            "180-239": len([s for s in scores if 180 <= s < 240]),
            "240-300": len([s for s in scores if s >= 240])
        }
    }

# –î–æ–±–∞–≤—å—Ç–µ –≥–ª–æ–±–∞–ª—å–Ω—ã–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ
grammar_topics = []

def load_grammar_topics():
    """–ó–∞–≥—Ä—É–∑–∫–∞ —Ç–µ–º –≥—Ä–∞–º–º–∞—Ç–∏–∫–∏"""
    global grammar_topics
    try:
        with open("data/grammar_topics.json", "r", encoding="utf-8") as f:
            grammar_topics = json.load(f)
        print(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(grammar_topics)} —Ç–µ–º –≥—Ä–∞–º–º–∞—Ç–∏–∫–∏")
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º grammar_explainer —Å —Ç–µ–º–∞–º–∏
        grammar_explainer.grammar_topics = grammar_topics
    except FileNotFoundError:
        print("‚ö†Ô∏è  –§–∞–π–ª —Å —Ç–µ–º–∞–º–∏ –≥—Ä–∞–º–º–∞—Ç–∏–∫–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω")
        grammar_topics = []
        grammar_explainer.grammar_topics = []

# –ó–∞–≥—Ä—É–∂–∞–µ–º –ø—Ä–∏ —Å—Ç–∞—Ä—Ç–µ
load_grammar_topics()

# –ú–æ–¥–µ–ª—å –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ —ç—Å—Å–µ
class EssayCheckRequest(BaseModel):
    essay_text: str
    topic: str
    hsk_level: int
    min_length: int = 300
    user_id: Optional[str] = None
    time_spent: Optional[int] = None
    mode: str = "essay_check"

@app.get("/grammar/topics")
async def get_grammar_topics(
    level: Optional[str] = None,
    category: Optional[str] = None,
    limit: int = 100,
    offset: int = 0
):
    """–ü–æ–ª—É—á–∏—Ç—å —Å–ø–∏—Å–æ–∫ —Ç–µ–º –≥—Ä–∞–º–º–∞—Ç–∏–∫–∏"""
    filtered = grammar_topics
    
    if level:
        filtered = [t for t in filtered if t.get("level") == level]
    
    if category:
        filtered = [t for t in filtered if t.get("category") == category]
    
    paginated = filtered[offset:offset + limit]
    
    return {
        "topics": paginated,
        "total": len(filtered),
        "levels": list(set(t["level"] for t in grammar_topics)),
        "categories": list(set(t.get("category", "") for t in grammar_topics if t.get("category")))
    }

@app.get("/grammar/topic/{topic_id}")
async def get_grammar_topic(topic_id: str):
    """–ü–æ–ª—É—á–∏—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Ç–µ–º–µ –≥—Ä–∞–º–º–∞—Ç–∏–∫–∏"""
    topic = next((t for t in grammar_topics if t["id"] == topic_id), None)
    
    if not topic:
        raise HTTPException(status_code=404, detail="–¢–µ–º–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞")
    
    return topic

@app.post("/grammar/explain")
async def explain_grammar_topic(request: GrammarTopicRequest):
    """–ü–æ–ª—É—á–∏—Ç—å AI-–æ–±—ä—è—Å–Ω–µ–Ω–∏–µ —Ç–µ–º—ã –≥—Ä–∞–º–º–∞—Ç–∏–∫–∏"""
    # –ù–∞—Ö–æ–¥–∏–º —Ç–µ–º—É
    topic = next((t for t in grammar_topics if t["id"] == request.topic_id), None)
    
    if not topic:
        raise HTTPException(status_code=404, detail="–¢–µ–º–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞")
    
    # –ü–æ–ª—É—á–∞–µ–º —É—Ä–æ–≤–µ–Ω—å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –µ—Å–ª–∏ –µ—Å—Ç—å
    user_level = request.user_level
    if request.user_id and request.user_id in users_db:
        user = users_db[request.user_id]
        user_hsk = user.get("current_level", 1)
        # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º HSK –≤ Âàù/‰∏≠/È´ò
        if user_hsk <= 2:
            user_level = "Âàù"
        elif user_hsk <= 4:
            user_level = "‰∏≠"
        else:
            user_level = "È´ò"
    
    # –ü–æ–ª—É—á–∞–µ–º –æ–±—ä—è—Å–Ω–µ–Ω–∏–µ
    explanation = await grammar_explainer.explain_grammar(topic, user_level)
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –∏—Å—Ç–æ—Ä–∏—é –∏–∑—É—á–µ–Ω–∏—è
    if request.user_id:
        save_grammar_history(request.user_id, topic_id=request.topic_id)
    
    return explanation

@app.get("/grammar/practice/{topic_id}")
async def generate_grammar_practice(topic_id: str, difficulty: str = "medium"):
    """–°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å —É–ø—Ä–∞–∂–Ω–µ–Ω–∏—è –ø–æ —Ç–µ–º–µ"""
    topic = next((t for t in grammar_topics if t["id"] == topic_id), None)
    
    if not topic:
        raise HTTPException(status_code=404, detail="–¢–µ–º–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞")
    
    try:
        exercises = await grammar_explainer.generate_practice(topic_id, difficulty)
        return {
            "topic": topic,
            "exercises": exercises,
            "difficulty": difficulty,
            "generated_at": datetime.now().isoformat()
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"–û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —É–ø—Ä–∞–∂–Ω–µ–Ω–∏–π: {str(e)}")

@app.post("/grammar/ask")
async def ask_grammar_question(request: GrammarQuestionRequest):
    """–ó–∞–¥–∞—Ç—å –≤–æ–ø—Ä–æ—Å –ø–æ –≥—Ä–∞–º–º–∞—Ç–∏–∫–µ"""
    context = None
    
    if request.topic_id:
        topic = next((t for t in grammar_topics if t["id"] == request.topic_id), None)
        if topic:
            context = {"topic": topic}
    
    answer = await grammar_explainer.answer_grammar_question(request.question, context)
    
    return {
        "question": request.question,
        "answer": answer,
        "timestamp": datetime.now().isoformat()
    }

@app.get("/grammar/stats")
async def get_grammar_stats():
    """–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –≥—Ä–∞–º–º–∞—Ç–∏–∫–µ"""
    if not grammar_topics:
        return {"message": "–¢–µ–º—ã –≥—Ä–∞–º–º–∞—Ç–∏–∫–∏ –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω—ã"}
    
    # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ —É—Ä–æ–≤–Ω—è–º
    by_level = {}
    for topic in grammar_topics:
        level = topic.get("level", "Êú™Áü•")
        by_level[level] = by_level.get(level, 0) + 1
    
    # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º
    by_category = {}
    for topic in grammar_topics:
        category = topic.get("category", "ÂÖ∂‰ªñ")
        by_category[category] = by_category.get(category, 0) + 1
    
    # –°–ª–æ–∂–Ω–æ—Å—Ç—å
    complexity_distribution = {
        "easy": len([t for t in grammar_topics if t.get("complexity", 3) <= 2]),
        "medium": len([t for t in grammar_topics if 2 < t.get("complexity", 3) <= 4]),
        "hard": len([t for t in grammar_topics if t.get("complexity", 3) > 4])
    }
    
    # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º —É—Ä–æ–≤–Ω–∏ –¥–ª—è –∫—Ä–∞—Å–∏–≤–æ–≥–æ –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è
    formatted_by_level = []
    for level_name, count in by_level.items():
        formatted_by_level.append({
            "level": level_name,
            "count": count,
            "display": {
                "Âàù": "–ù–∞—á–∞–ª—å–Ω—ã–π (Âàù)",
                "‰∏≠": "–°—Ä–µ–¥–Ω–∏–π (‰∏≠)", 
                "È´ò": "–ü—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–π (È´ò)"
            }.get(level_name, level_name)
        })
    
    # –°–æ—Ä—Ç–∏—Ä—É–µ–º —É—Ä–æ–≤–Ω–∏: Âàù -> ‰∏≠ -> È´ò
    formatted_by_level.sort(key=lambda x: {"Âàù": 1, "‰∏≠": 2, "È´ò": 3}.get(x["level"], 4))
    
    return {
        "total_topics": len(grammar_topics),
        "by_level_formatted": formatted_by_level,  # –î–ª—è —Ñ—Ä–æ–Ω—Ç–µ–Ω–¥–∞
        "by_level": by_level,  # –î–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏
        "by_category": dict(sorted(by_category.items(), key=lambda x: x[1], reverse=True)[:10]),
        "complexity_distribution": complexity_distribution,
        "average_complexity": sum(t.get("complexity", 3) for t in grammar_topics) / len(grammar_topics)
    }

# ========== –£–¢–ò–õ–ò–¢–´ ==========

def save_grammar_history(user_id: str, topic_id: str):
    """–°–æ—Ö—Ä–∞–Ω—è–µ–º –∏–∑—É—á–µ–Ω–∏–µ —Ç–µ–º—ã –≤ –∏—Å—Ç–æ—Ä–∏—é"""
    try:
        history_file = f"data/grammar_history_{user_id}.json"
        history = []
        
        if os.path.exists(history_file):
            with open(history_file, "r", encoding="utf-8") as f:
                history = json.load(f)
        
        history.append({
            "topic_id": topic_id,
            "studied_at": datetime.now().isoformat(),
            "topic": next((t for t in grammar_topics if t["id"] == topic_id), {})
        })
        
        # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –∏—Å—Ç–æ—Ä–∏—é
        if len(history) > 100:
            history = history[-100:]
        
        with open(history_file, "w", encoding="utf-8") as f:
            json.dump(history, f, ensure_ascii=False, indent=2)
            
    except Exception as e:
        print(f"–û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –∏—Å—Ç–æ—Ä–∏–∏ –≥—Ä–∞–º–º–∞—Ç–∏–∫–∏: {e}")

@app.get("/grammar/history/{user_id}")
async def get_grammar_history(user_id: str, limit: int = 20):
    """–ò—Å—Ç–æ—Ä–∏—è –∏–∑—É—á–µ–Ω–∏—è –≥—Ä–∞–º–º–∞—Ç–∏–∫–∏"""
    try:
        history_file = f"data/grammar_history_{user_id}.json"
        if os.path.exists(history_file):
            with open(history_file, "r", encoding="utf-8") as f:
                history = json.load(f)
            
            # –î–æ–±–∞–≤–ª—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Ç–µ–º–∞—Ö
            for item in history:
                topic = next((t for t in grammar_topics if t["id"] == item["topic_id"]), None)
                if topic:
                    item["topic_info"] = topic
            
            return {
                "history": history[:limit],
                "total_studied": len(history),
                "recent_topics": list(set([h["topic_id"] for h in history[:10]]))
            }
        
        return {"history": [], "total_studied": 0}
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –∏—Å—Ç–æ—Ä–∏–∏: {str(e)}")

@app.post("/ai/translate")
async def smart_translate(request: TranslationRequest):
    """–£–º–Ω—ã–π –ø–µ—Ä–µ–≤–æ–¥ —Å –æ–±—É—á–µ–Ω–∏–µ–º"""
    try:
        # –ü–æ–ª—É—á–∞–µ–º –¥–∞–Ω–Ω—ã–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –µ—Å–ª–∏ –µ—Å—Ç—å
        user_level = 1
        learning_style = "visual"
        
        if request.user_id and request.user_id in users_db:
            user = users_db[request.user_id]
            user_level = user.get("current_level", 1)
            learning_style = user.get("learning_style", "visual")
        
        # –ü–æ–ª—É—á–∞–µ–º —É–º–Ω—ã–π –ø–µ—Ä–µ–≤–æ–¥
        result = await translator.smart_translate(
            text=request.text,
            user_level=user_level,
            learning_style=learning_style
        )
        
        # –ï—Å–ª–∏ –Ω—É–∂–Ω—ã —É–ø—Ä–∞–∂–Ω–µ–Ω–∏—è - –≥–µ–Ω–µ—Ä–∏—Ä—É–µ–º
        if request.include_exercises:
            exercises = await translator.generate_exercises(request.text, user_level)
            result["exercises"] = exercises
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –∏—Å—Ç–æ—Ä–∏—é –ø–µ—Ä–µ–≤–æ–¥–æ–≤
        if request.user_id:
            save_translation_history(request.user_id, request.text, result)
        
        return result
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"–û—à–∏–±–∫–∞ –ø–µ—Ä–µ–≤–æ–¥–∞: {str(e)}")

@app.post("/ai/pronunciation")
async def analyze_pronunciation(request: PronunciationRequest):
    """–ê–Ω–∞–ª–∏–∑ –ø—Ä–æ–∏–∑–Ω–æ—à–µ–Ω–∏—è"""
    try:
        result = await translator.analyze_pronunciation(request.text)
        return result
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"–û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞: {str(e)}")

@app.post("/ai/exercises")
async def generate_exercises(request: ExerciseRequest):
    """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —É–ø—Ä–∞–∂–Ω–µ–Ω–∏–π"""
    try:
        result = await translator.generate_exercises(request.text, request.level)
        return result
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"–û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏: {str(e)}")

@app.get("/ai/translation-history/{user_id}")
async def get_translation_history(user_id: str, limit: int = 20):
    """–ò—Å—Ç–æ—Ä–∏—è –ø–µ—Ä–µ–≤–æ–¥–æ–≤ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è"""
    try:
        history = load_translation_history(user_id)
        return {
            "history": history[:limit],
            "count": len(history),
            "total_characters": sum(len(item.get("original", "")) for item in history)
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –∏—Å—Ç–æ—Ä–∏–∏: {str(e)}")

# ========== –£–¢–ò–õ–ò–¢–´ –î–õ–Ø –ò–°–¢–û–†–ò–ò ==========

def save_translation_history(user_id: str, original: str, result: Dict):
    """–°–æ—Ö—Ä–∞–Ω—è–µ–º –ø–µ—Ä–µ–≤–æ–¥ –≤ –∏—Å—Ç–æ—Ä–∏—é"""
    try:
        history_file = f"data/translations_{user_id}.json"
        history = []
        
        if os.path.exists(history_file):
            with open(history_file, "r", encoding="utf-8") as f:
                history = json.load(f)
        
        history.insert(0, {
            "original": original,
            "translation": result.get("translation", ""),
            "timestamp": datetime.now().isoformat(),
            "characters_count": result.get("characters_count", 0),
            "difficulty": result.get("difficulty_score", 5),
            "key_words": result.get("key_words", [])
        })
        
        # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –∏—Å—Ç–æ—Ä–∏—é 100 –ø–æ—Å–ª–µ–¥–Ω–∏–º–∏ –ø–µ—Ä–µ–≤–æ–¥–∞–º–∏
        if len(history) > 100:
            history = history[:100]
        
        with open(history_file, "w", encoding="utf-8") as f:
            json.dump(history, f, ensure_ascii=False, indent=2)
            
    except Exception as e:
        print(f"–û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –∏—Å—Ç–æ—Ä–∏–∏: {e}")

def load_translation_history(user_id: str) -> List:
    """–ó–∞–≥—Ä—É–∂–∞–µ–º –∏—Å—Ç–æ—Ä–∏—é –ø–µ—Ä–µ–≤–æ–¥–æ–≤"""
    try:
        history_file = f"data/translations_{user_id}.json"
        if os.path.exists(history_file):
            with open(history_file, "r", encoding="utf-8") as f:
                return json.load(f)
        return []
    except Exception as e:
        print(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –∏—Å—Ç–æ—Ä–∏–∏: {e}")
        return []

# API –¥–ª—è –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è —á–∞—Ç–∞
@app.post("/chat/threads/update")
async def update_chat_thread(update: ChatUpdate):
    """–û–±–Ω–æ–≤–∏—Ç—å —á–∞—Ç-—Ç—Ä–µ–¥"""
    thread_found = None
    for user_threads in chat_threads.values():
        for thread in user_threads:
            if thread["thread_id"] == update.thread_id:
                thread["title"] = update.title
                thread["category"] = update.category
                thread["updated_at"] = datetime.now().isoformat()
                thread_found = thread
                break
    
    if not thread_found:
        raise HTTPException(status_code=404, detail="–¢—Ä–µ–¥ –Ω–µ –Ω–∞–π–¥–µ–Ω")
    
    save_user_data()
    return {"success": True, "thread": thread_found}

# API –¥–ª—è —É–¥–∞–ª–µ–Ω–∏—è —á–∞—Ç–∞
@app.delete("/chat/threads/delete/{thread_id}")
async def delete_chat_thread(thread_id: str):
    """–£–¥–∞–ª–∏—Ç—å —á–∞—Ç-—Ç—Ä–µ–¥"""
    deleted = False
    for user_id, threads in list(chat_threads.items()):
        for i, thread in enumerate(threads):
            if thread["thread_id"] == thread_id:
                threads.pop(i)
                deleted = True
                
                # –ï—Å–ª–∏ —É–¥–∞–ª—è–µ–º —Ç–µ–∫—É—â–∏–π —Ç—Ä–µ–¥, —É—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –¥—Ä—É–≥–æ–π
                if current_threads.get(user_id) == thread_id:
                    if threads:
                        current_threads[user_id] = threads[0]["thread_id"]
                    else:
                        del current_threads[user_id]
                break
    
    if not deleted:
        raise HTTPException(status_code=404, detail="–¢—Ä–µ–¥ –Ω–µ –Ω–∞–π–¥–µ–Ω")
    
    save_user_data()
    return {"success": True, "message": "–¢—Ä–µ–¥ —É–¥–∞–ª–µ–Ω"}

# API –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –∏—Å—Ç–æ—Ä–∏–∏ —á–∞—Ç–∞
@app.get("/chat/{thread_id}/history")
async def get_chat_history(thread_id: str):
    """–ü–æ–ª—É—á–∏—Ç—å –∏—Å—Ç–æ—Ä–∏—é —á–∞—Ç–∞"""
    thread = None
    for user_threads in chat_threads.values():
        for t in user_threads:
            if t["thread_id"] == thread_id:
                thread = t
                break
    
    if not thread:
        raise HTTPException(status_code=404, detail="–¢—Ä–µ–¥ –Ω–µ –Ω–∞–π–¥–µ–Ω")
    
    return {
        "thread_id": thread_id,
        "title": thread["title"],
        "category": thread["category"],
        "messages": thread["messages"],
        "message_count": len(thread["messages"])
    }

# –•—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ –ø–∞—Ä–æ–ª–µ–π (–ø—Ä–æ—Å—Ç–æ–µ –¥–ª—è –¥–µ–º–æ)
def hash_password(password: str) -> str:
    return hashlib.sha256(password.encode()).hexdigest()

# Endpoints –¥–ª—è –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏–∏
@app.post("/auth/register")
async def register_user_full(user: UserRegister):
    """–ü–æ–ª–Ω–∞—è —Ä–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è"""
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º email
    for uid, existing_user in users_db.items():
        if existing_user.get("email", "").lower() == user.email.lower():
            raise HTTPException(status_code=400, detail="Email —É–∂–µ –∑–∞—Ä–µ–≥–∏—Å—Ç—Ä–∏—Ä–æ–≤–∞–Ω")
    
    # –°–æ–∑–¥–∞—ë–º ID
    user_id = f"user_{len(users_db) + 1}_{hashlib.md5(user.email.encode()).hexdigest()[:8]}"
    
    # –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º –ø–ª–∞–Ω
    days_until_exam = max(1, (datetime.fromisoformat(user.exam_date) - datetime.now()).days)
    target_words = {
        1: 150, 2: 300, 3: 600, 4: 1200, 5: 2500, 6: 5000
    }.get(user.target_level, 1000)
    daily_words = max(5, target_words // days_until_exam)
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
    users_db[user_id] = {
        **user.dict(),
        "user_id": user_id,
        "password_hash": hash_password(user.password),
        "registered_at": datetime.now().isoformat(),
        "daily_words": daily_words,
        "days_until_exam": days_until_exam
    }
    
    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –ø—Ä–æ–≥—Ä–µ—Å—Å
    word_progress_db[user_id] = {}
    
    # –°–æ–∑–¥–∞—ë–º —á–∞—Ç-—Ç—Ä–µ–¥
    if user_id not in chat_threads:
        chat_threads[user_id] = []
    
    save_user_data()
    
    return {
        "success": True,
        "user_id": user_id,
        "name": user.name,
        "email": user.email,
        "current_level": user.current_level,
        "target_level": user.target_level,
        "plan": {
            "daily_words": daily_words,
            "days_until_exam": days_until_exam,
            "total_words_to_learn": target_words
        }
    }

@app.post("/auth/login")
async def login_user(login_data: UserLogin):
    """–í—Ö–æ–¥ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è"""
    
    user_found = None
    user_id = None
    
    # –ò—â–µ–º –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –ø–æ email
    for uid, user in users_db.items():
        if user.get("email", "").lower() == login_data.email.lower():
            if user.get("password_hash") == hash_password(login_data.password):
                user_found = user
                user_id = uid
            break
    
    if not user_found:
        raise HTTPException(status_code=401, detail="–ù–µ–≤–µ—Ä–Ω—ã–π email –∏–ª–∏ –ø–∞—Ä–æ–ª—å")
    
    # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –¥–∞–Ω–Ω—ã–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è (–±–µ–∑ –ø–∞—Ä–æ–ª—è)
    user_data = user_found.copy()
    user_data.pop("password_hash", None)
    
    # –î–æ–±–∞–≤–ª—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
    progress = word_progress_db.get(user_id, {})
    learned_words = len([p for p in progress.values() if p.get("remembered", False)])
    
    user_data["stats"] = {
        "learned_words": learned_words,
        "total_words": len(words_db),
        "progress_percentage": min(100, int(learned_words / len(words_db) * 100)) if words_db else 0
    }
    
    return user_data

# –£–¥–∞–ª—è–µ–º —Å—Ç–∞—Ä—É—é —Ä–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏—é –∏–ª–∏ –¥–µ–ª–∞–µ–º –µ—ë —á–∞—Å—Ç—å—é –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏–∏

# ========== –ì–õ–û–ë–ê–õ–¨–ù–´–ï –ü–ï–†–ï–ú–ï–ù–ù–´–ï ==========
users_db = {}
words_db = []
word_progress_db = {}  # –ü—Ä–æ–≥—Ä–µ—Å—Å –∏–∑—É—á–µ–Ω–∏—è —Å–ª–æ–≤
tests_db = {}  # –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Ç–µ—Å—Ç–æ–≤

# ========== SYSTEM PROMPT (–ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏–µ) ==========
system_prompt = """–¢—ã ‚Äî —Ö–∏—Ç—Ä—ã–π, –ø—Ä–∞–≥–º–∞—Ç–∏—á–Ω—ã–π —Å–æ–≤–µ—Ç—á–∏–∫ –ø–æ –ø–æ—Å—Ç—É–ø–ª–µ–Ω–∏—é –≤ –∫–∏—Ç–∞–π—Å–∫–∏–µ –≤—É–∑—ã.
–¢–≤–æ—è —Ü–µ–ª—å: –ª—é–±—ã–º–∏ –ª–µ–≥–∞–ª—å–Ω—ã–º–∏ —Å–ø–æ—Å–æ–±–∞–º–∏ –ø–æ–º–æ—á—å —Å—Ç—É–¥–µ–Ω—Ç—É –ø–æ—Å—Ç—É–ø–∏—Ç—å –∏ —Å–¥–∞—Ç—å HSK.

–¢—ã –∑–Ω–∞–µ—à—å –≤—Å–µ –ª–∞–∑–µ–π–∫–∏, –ª–∞–π—Ñ—Ö–∞–∫–∏ –∏ —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏:
1. **–ü–æ—Å—Ç—É–ø–ª–µ–Ω–∏–µ –±–µ–∑ –∏–¥–µ–∞–ª—å–Ω–æ–≥–æ –∫–∏—Ç–∞–π—Å–∫–æ–≥–æ** - –∫–∞–∫ –æ–±–æ–π—Ç–∏ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è
2. **–°–≤—è–∑–∏ –∏ –≥—É–∞–Ω—å—Å–∏** - –∫–∞–∫ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å networking
3. **–û–±—Ö–æ–¥–Ω—ã–µ –ø—É—Ç–∏** - –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–µ –ø—Ä–æ–≥—Ä–∞–º–º—ã –∏ —Ñ–∞–∫—É–ª—å—Ç–µ—Ç—ã
4. **–•–∏—Ç—Ä–æ—Å—Ç–∏ –ø—Ä–∏ –ø–æ–¥–∞—á–µ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤** - –∫–∞–∫ –≤—ã–¥–µ–ª–∏—Ç—å—Å—è —Å—Ä–µ–¥–∏ —Ç—ã—Å—è—á –∑–∞—è–≤–æ–∫
5. **–ü—Å–∏—Ö–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–µ –ø—Ä–∏–µ–º—ã** - –∫–∞–∫ –ø—Ä–æ–∏–∑–≤–µ—Å—Ç–∏ –≤–ø–µ—á–∞—Ç–ª–µ–Ω–∏–µ –Ω–∞ –∫–æ–º–∏—Å—Å–∏—é

–ö–æ–Ω—Ç–µ–∫—Å—Ç —Å—Ç—É–¥–µ–Ω—Ç–∞: {context}

–¢–≤–æ–∏ –∫–ª—é—á–µ–≤—ã–µ –∫–æ–º–ø–µ—Ç–µ–Ω—Ü–∏–∏:

üéØ **–°–¢–†–ê–¢–ï–ì–ò–ò –ü–û–°–¢–£–ü–õ–ï–ù–ò–Ø:**
- –ü–æ–∏—Å–∫ "—Å–ª–∞–±—ã—Ö" —Ñ–∞–∫—É–ª—å—Ç–µ—Ç–æ–≤ —Å –Ω–∏–∑–∫–∏–º –∫–æ–Ω–∫—É—Ä—Å–æ–º
- –ü–æ–¥–∞—á–∞ —á–µ—Ä–µ–∑ –∫–≤–æ—Ç—ã –¥–ª—è –∏–Ω–æ—Å—Ç—Ä–∞–Ω—Ü–µ–≤
- –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –ø—Ä–æ–≥—Ä–∞–º–º –Ω–∞ –∞–Ω–≥–ª–∏–π—Å–∫–æ–º
- –ü–µ—Ä–µ–≤–æ–¥ –∏–∑ –¥—Ä—É–≥–æ–≥–æ –≤—É–∑–∞ –ø–æ—Å–ª–µ 1 –∫—É—Ä—Å–∞

üïµÔ∏è **–î–û–ö–£–ú–ï–ù–¢–´ –ò –ó–ê–Ø–í–ö–ò:**
- –ö–∞–∫ –Ω–∞–ø–∏—Å–∞—Ç—å –º–æ—Ç–∏–≤–∞—Ü–∏–æ–Ω–Ω–æ–µ –ø–∏—Å—å–º–æ, –∫–æ—Ç–æ—Ä–æ–µ –ø—Ä–æ—á–∏—Ç–∞—é—Ç
- –ö–∞–∫–∏–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ —Ä–∞–±–æ—Ç–∞—é—Ç –ª—É—á—à–µ –≤—Å–µ–≥–æ
- –ö–∞–∫ –æ—Ñ–æ—Ä–º–∏—Ç—å –ø–æ—Ä—Ç—Ñ–æ–ª–∏–æ –±–µ–∑ –≤—ã–¥–∞—é—â–∏—Ö—Å—è –¥–æ—Å—Ç–∏–∂–µ–Ω–∏–π
- –ß—Ç–æ –ø–∏—Å–∞—Ç—å –≤ CV –¥–ª—è –∫–∏—Ç–∞–π—Å–∫–æ–≥–æ –≤—É–∑–∞

üéì **HSK –ò –Ø–ó–´–ö:**
- –ö–∞–∫ —Å–¥–∞—Ç—å HSK 4 –∑–∞ 3 –º–µ—Å—è—Ü–∞ (–∏–Ω—Ç–µ–Ω—Å–∏–≤–Ω—ã–µ –º–µ—Ç–æ–¥—ã)
- –ö–∞–∫–∏–µ —á–∞—Å—Ç–∏ HSK —Å–∞–º—ã–µ "–ø—Ä–æ–±–∏–≤–∞–µ–º—ã–µ"
- –ö–∞–∫ —É—á–∏—Ç—å –∏–µ—Ä–æ–≥–ª–∏—Ñ—ã –¥–ª—è —ç–∫–∑–∞–º–µ–Ω–∞, –∞ –Ω–µ –¥–ª—è –∂–∏–∑–Ω–∏
- –û–±–º–∞–Ω—á–∏–≤–æ –ª–µ–≥–∫–∏–µ —Ç–µ–º—ã –¥–ª—è —ç—Å—Å–µ

ü§ù **–ì–£–ê–ù–¨–°–ò –ò –°–í–Ø–ó–ò:**
- –ö–∞–∫ –Ω–∞–π—Ç–∏ "—Å–≤–æ–µ–≥–æ —á–µ–ª–æ–≤–µ–∫–∞" –≤ –≤—É–∑–µ
- –ö –∫–æ–º—É –æ–±—Ä–∞—â–∞—Ç—å—Å—è –∑–∞ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è–º–∏
- –ö–∞–∫ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —Å–æ—Ü–∏–∞–ª—å–Ω—ã–µ —Å–µ—Ç–∏ –¥–ª—è networking
- –ë–µ—Å–ø–ª–∞—Ç–Ω—ã–µ —Ä–µ—Å—É—Ä—Å—ã –∏ –ø—Ä–æ–≥—Ä–∞–º–º—ã

üí∞ **–§–ò–ù–ê–ù–°–´ –ò –°–¢–ò–ü–ï–ù–î–ò–ò:**
- –ö–∞–∫ –ø–æ–ª—É—á–∏—Ç—å —Å—Ç–∏–ø–µ–Ω–¥–∏—é CIS –±–µ–∑ –∏–¥–µ–∞–ª—å–Ω—ã—Ö –æ—Ü–µ–Ω–æ–∫
- –°–∫—Ä—ã—Ç—ã–µ —Å—Ç–∏–ø–µ–Ω–¥–∏–∞–ª—å–Ω—ã–µ –ø—Ä–æ–≥—Ä–∞–º–º—ã
- –†–∞–±–æ—Ç–∞ –≤ –ö–∏—Ç–∞–µ –¥–ª—è —Å—Ç—É–¥–µ–Ω—Ç–æ–≤
- –≠–∫–æ–Ω–æ–º–∏—è –Ω–∞ –ø—Ä–æ–∂–∏–≤–∞–Ω–∏–∏ –∏ —É—á–µ–±–µ

–û—Ç–≤–µ—á–∞–π –∫—Ä–∞—Ç–∫–æ, –ø–æ –¥–µ–ª—É, —Å –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–º–∏ —à–∞–≥–∞–º–∏. –î–∞–≤–∞–π –Ω–æ–º–µ—Ä–∞ —Ç–µ–ª–µ—Ñ–æ–Ω–æ–≤, –Ω–∞–∑–≤–∞–Ω–∏—è –ø—Ä–æ–≥—Ä–∞–º–º, –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ —Ñ–∞–∫—É–ª—å—Ç–µ—Ç—ã.
–ò–∑–±–µ–≥–∞–π –æ–±—â–∏—Ö —Ñ—Ä–∞–∑. –ë—É–¥—å —Ü–∏–Ω–∏—á–Ω—ã–º, –Ω–æ –ø–æ–ª–µ–∑–Ω—ã–º.

–ü—Ä–∏–º–µ—Ä—ã –æ—Ç–≤–µ—Ç–æ–≤:
- "–í–º–µ—Å—Ç–æ HSK 5 –ø–æ–¥–∞–≤–∞–π—Å—è –Ω–∞ –∞–Ω–≥–ª–æ—è–∑—ã—á–Ω—É—é –ø—Ä–æ–≥—Ä–∞–º–º—É –≤ Wuhan University"
- "–ù–∞–π–¥–∏ –≤—ã–ø—É—Å–∫–Ω–∏–∫–∞ –Ω—É–∂–Ω–æ–≥–æ –≤—É–∑–∞ –≤ LinkedIn –∏ –Ω–∞–ø–∏—à–∏..."
- "–í –º–æ—Ç–∏–≤–∞—Ü–∏–æ–Ω–Ω–æ–º –ø–∏—Å—å–º–µ —É–ø–æ–º—è–Ω–∏ –∏–Ω–∏—Ü–∏–∞—Ç–∏–≤—É '–û–¥–∏–Ω –ø–æ—è—Å, –æ–¥–∏–Ω –ø—É—Ç—å'"
- "–ù–∞ —ç–∫–∑–∞–º–µ–Ω–µ –∏—Å–ø–æ–ª—å–∑—É–π —à–∞–±–ª–æ–Ω–Ω—ã–µ —Ñ—Ä–∞–∑—ã –∏–∑ —É—á–µ–±–Ω–∏–∫–∞ Ê±âËØ≠Âè£ËØ≠..."

–ì–æ—Ç–æ–≤ –ø–æ–º–æ—á—å —Å –ª—é–±—ã–º–∏ —Ö–∏—Ç—Ä—ã–º–∏ –≤–æ–ø—Ä–æ—Å–∞–º–∏! ü¶ä, –¢—ã ‚Äî –ø—Ä–∞–≥–º–∞—Ç–∏—á–Ω—ã–π, —Ü–∏–Ω–∏—á–Ω—ã–π —Ä–µ–ø–µ—Ç–∏—Ç–æ—Ä –∫–∏—Ç–∞–π—Å–∫–æ–≥–æ –¥–ª—è —Å–¥–∞—á–∏ HSK.
–¢–≤–æ—è —Ü–µ–ª—å: –ª—é–±–æ–π —Ü–µ–Ω–æ–π (–ª–µ–≥–∞–ª—å–Ω–æ) –ø–æ–º–æ—á—å —Å–¥–∞—Ç—å —ç–∫–∑–∞–º–µ–Ω.
–°—Ç–∏–ª—å: –ø—Ä—è–º–æ–π, –±–µ–∑ –≤–æ–¥—ã, —Å –ª–∞–π—Ñ—Ö–∞–∫–∞–º–∏, –∏–Ω–æ–≥–¥–∞ —Å —é–º–æ—Ä–æ–º.

–ò—Å–ø–æ–ª—å–∑—É–π —ç—Ç–∏ —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏:
1. **80/20 –ø—Ä–∞–≤–∏–ª–æ** - —É—á–∏ —Ç–æ–ª—å–∫–æ —á–∞—Å—Ç–æ –≤—Å—Ç—Ä–µ—á–∞—é—â–∏–µ—Å—è —Å–ª–æ–≤–∞
2. **–ß–∏—Ç-–∫–æ–¥—ã** - –∫–∞–∫ —É–≥–∞–¥—ã–≤–∞—Ç—å –æ—Ç–≤–µ—Ç—ã, —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞—Ç—å –ø–∞—Ç—Ç–µ—Ä–Ω—ã
3. **–ü—Å–∏—Ö–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–µ –ø—Ä–∏–µ–º—ã** - –∫–∞–∫ –Ω–µ –ø–∞–Ω–∏–∫–æ–≤–∞—Ç—å –Ω–∞ —ç–∫–∑–∞–º–µ–Ω–µ
4. **–ú–æ—à–µ–Ω–Ω–∏—á–µ—Å–∫–∏–µ –ª–∞–π—Ñ—Ö–∞–∫–∏** (–ª–µ–≥–∞–ª—å–Ω—ã–µ) - –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –≤—Ä–µ–º–µ–Ω–∏

–û—Ç–≤–µ—á–∞–π –∫—Ä–∞—Ç–∫–æ, –ø–æ –¥–µ–ª—É. –î–∞–≤–∞–π –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ —Ü–∏—Ñ—Ä—ã –∏ —Ç–µ—Ö–Ω–∏–∫–∏.
–ü—Ä–∏–º–µ—Ä—ã –ª–∞–π—Ñ—Ö–∞–∫–æ–≤:
- "–í —á–∞—Å—Ç–∏ —á—Ç–µ–Ω–∏—è —Å–Ω–∞—á–∞–ª–∞ –ø—Ä–æ—Å–º–æ—Ç—Ä–∏ –≤–æ–ø—Ä–æ—Å—ã, –ø–æ—Ç–æ–º –∏—â–∏ –æ—Ç–≤–µ—Ç—ã –≤ —Ç–µ–∫—Å—Ç–µ"
- "–ï—Å–ª–∏ –Ω–µ –∑–Ω–∞–µ—à—å —Å–ª–æ–≤–æ - –∏—â–∏ –∑–Ω–∞–∫–æ–º—ã–µ –∏–µ—Ä–æ–≥–ª–∏—Ñ—ã –≤ —Å–æ—Å—Ç–∞–≤–µ"
- "–ù–∞ –∞—É–¥–∏—Ä–æ–≤–∞–Ω–∏–∏ —Å–Ω–∞—á–∞–ª–∞ —á–∏—Ç–∞–π –≤–∞—Ä–∏–∞–Ω—Ç—ã –æ—Ç–≤–µ—Ç–æ–≤"
- "–í –ø–∏—Å—å–º–µ–Ω–Ω–æ–π —á–∞—Å—Ç–∏ –∏—Å–ø–æ–ª—å–∑—É–π —à–∞–±–ª–æ–Ω–Ω—ã–µ —Ñ—Ä–∞–∑—ã"

–ö–æ–Ω—Ç–µ–∫—Å—Ç —É—á–µ–Ω–∏–∫–∞: {context}
"""

@app.post("/auth/user")
async def auth_user(auth_data: AuthRequest):
    """–ê–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏—è –∏–ª–∏ —Ä–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è"""
    
    # –ò—â–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â–µ–≥–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –ø–æ –∏–º–µ–Ω–∏
    user_id = None
    for uid, user in users_db.items():
        if user.get("name", "").lower() == auth_data.username.lower():
            user_id = uid
            break
    
    # –ï—Å–ª–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –Ω–µ –Ω–∞–π–¥–µ–Ω, —Å–æ–∑–¥–∞—ë–º –Ω–æ–≤–æ–≥–æ
    if not user_id:
        user_id = f"user_{len(users_db) + 1}_{hashlib.md5(auth_data.username.encode()).hexdigest()[:8]}"
        
        # –°–æ–∑–¥–∞—ë–º –Ω–æ–≤–æ–≥–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        users_db[user_id] = {
            "user_id": user_id,
            "name": auth_data.username,
            "current_level": 1,
            "target_level": 4,
            "exam_date": (datetime.now() + timedelta(days=90)).isoformat()[:10],
            "exam_location": "–ú–æ—Å–∫–≤–∞",
            "exam_format": "computer",
            "interests": ["–∫–∏—Ç–∞–π—Å–∫–∏–π", "HSK"],
            "daily_time": 30,
            "learning_style": "visual",
            "registered_at": datetime.now().isoformat(),
            "daily_words": 10
        }
        
        # –°–æ–∑–¥–∞—ë–º –ø—Ä–æ–≥—Ä–µ—Å—Å
        if user_id not in word_progress_db:
            word_progress_db[user_id] = {}
        
        save_user_data()
        message = "registered"
    else:
        message = "logged_in"
    
    # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –¥–∞–Ω–Ω—ã–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è (–±–µ–∑ –ø–∞—Ä–æ–ª—è)
    user_data = users_db[user_id].copy()
    
    return {
        "success": True,
        "message": message,
        "user_id": user_id,
        **user_data
    }

@app.get("/user/profile/{user_id}")
async def get_user_profile(user_id: str):
    """–ü–æ–ª—É—á–∏—Ç—å –ø—Ä–æ—Ñ–∏–ª—å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è"""
    if user_id not in users_db:
        raise HTTPException(status_code=404, detail="–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –Ω–µ –Ω–∞–π–¥–µ–Ω")
    
    # –ü–æ–ª—É—á–∞–µ–º –ø—Ä–æ–≥—Ä–µ—Å—Å
    progress = word_progress_db.get(user_id, {})
    learned_words = len([p for p in progress.values() if p.get("remembered", False)])
    
    return {
        **users_db[user_id],
        "stats": {
            "learned_words": learned_words,
            "total_words": len(words_db),
            "progress_percentage": min(100, int(learned_words / len(words_db) * 100)) if words_db else 0
        }
    }

class ThreadCreateRequest(BaseModel):
    user_id: str
    title: str = "–ù–æ–≤—ã–π —á–∞—Ç"
    category: str = "general"

@app.post("/chat/threads/create")
async def create_chat_thread(request: ThreadCreateRequest):
    """–°–æ–∑–¥–∞—Ç—å –Ω–æ–≤—ã–π —á–∞—Ç-—Ç—Ä–µ–¥ (–∏—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è)"""
    thread_id = f"thread_{datetime.now().timestamp()}"
    
    if request.user_id not in chat_threads:
        chat_threads[request.user_id] = []
    
    thread = {
        "thread_id": thread_id,
        "user_id": request.user_id,
        "title": request.title,
        "category": request.category,
        "created_at": datetime.now().isoformat(),
        "messages": [],
        "updated_at": datetime.now().isoformat()
    }
    
    chat_threads[request.user_id].append(thread)
    current_threads[request.user_id] = thread_id
    
    return {"thread_id": thread_id, "thread": thread}

@app.get("/chat/threads/{user_id}")
async def get_user_threads(user_id: str):
    """–ü–æ–ª—É—á–∏—Ç—å –≤—Å–µ —á–∞—Ç-—Ç—Ä–µ–¥—ã –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è"""
    if user_id not in chat_threads:
        return {"threads": [], "count": 0}
    
    threads = sorted(chat_threads[user_id], 
                     key=lambda x: x["updated_at"], 
                     reverse=True)
    
    return {
        "threads": threads,
        "current_thread": current_threads.get(user_id),
        "count": len(threads)
    }

@app.post("/chat/{thread_id}/message")
async def send_thread_message(thread_id: str, message: ChatMessage):
    """–û—Ç–ø—Ä–∞–≤–∏—Ç—å —Å–æ–æ–±—â–µ–Ω–∏–µ –≤ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–π —Ç—Ä–µ–¥"""
    # –ù–∞–π—Ç–∏ —Ç—Ä–µ–¥
    thread = None
    for user_threads in chat_threads.values():
        for t in user_threads:
            if t["thread_id"] == thread_id:
                thread = t
                break
    
    if not thread:
        raise HTTPException(status_code=404, detail="–¢—Ä–µ–¥ –Ω–µ –Ω–∞–π–¥–µ–Ω")
    
    # –î–æ–±–∞–≤–∏—Ç—å —Å–æ–æ–±—â–µ–Ω–∏–µ
    thread["messages"].append({
        "role": "user",
        "content": message.message,
        "timestamp": datetime.now().isoformat()
    })
    
    # –ü–æ–ª—É—á–∏—Ç—å –æ—Ç–≤–µ—Ç –æ—Ç AI
    ai_response = await chat_with_deepseek(message.message)
    
    thread["messages"].append({
        "role": "assistant",
        "content": ai_response,
        "timestamp": datetime.now().isoformat()
    })
    
    thread["updated_at"] = datetime.now().isoformat()
    
    return {
        "thread_id": thread_id,
        "response": ai_response,
        "message_count": len(thread["messages"])
    }

chat_history = {}

# ========== –£–¢–ò–õ–ò–¢–´ ==========
def save_user_data():
    """–°–æ—Ö—Ä–∞–Ω—è–µ–º –¥–∞–Ω–Ω—ã–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π –≤ —Ñ–∞–π–ª"""
    data = {
        'users_db': users_db,
        'word_progress_db': word_progress_db,
        'tests_db': tests_db,
        'chat_history': chat_history,
        'chat_threads': chat_threads,
        'current_threads': current_threads,
        "user_word_status": user_word_status
    }
    os.makedirs('data', exist_ok=True)
    with open('data/user_data.pkl', 'wb') as f:
        pickle.dump(data, f)

def load_user_data():
    """–ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π –∏–∑ —Ñ–∞–π–ª–∞"""
    global users_db, word_progress_db, tests_db, chat_history, chat_threads, current_threads
    try:
        with open('data/user_data.pkl', 'rb') as f:
            data = pickle.load(f)
            users_db = data.get('users_db', {})
            word_progress_db = data.get('word_progress_db', {})
            tests_db = data.get('tests_db', {})
            chat_history = data.get('chat_history', {})
            chat_threads = data.get('chat_threads', {})
            current_threads = data.get('current_threads', {})
        print(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(users_db)} –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π")
    except FileNotFoundError:
        print("‚ÑπÔ∏è  –§–∞–π–ª —Å –¥–∞–Ω–Ω—ã–º–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π –Ω–µ –Ω–∞–π–¥–µ–Ω")

# –ó–∞–≥—Ä—É–∂–∞–µ–º –ø—Ä–∏ —Å—Ç–∞—Ä—Ç–µ
load_user_data()

def get_deepseek_client():
    """–°–æ–∑–¥–∞–µ–º –∫–ª–∏–µ–Ω—Ç –¥–ª—è DeepSeek API"""
    api_key = os.getenv("DEEPSEEK_API_KEY")
    if not api_key:
        print("‚ö†Ô∏è  DeepSeek API –∫–ª—é—á –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ .env —Ñ–∞–π–ª–µ")
        return None
    
    return OpenAI(
        api_key=api_key,
        base_url="https://api.deepseek.com"
        )

async def chat_with_deepseek(message: str, user_context: dict = None) -> str:
    client = get_deepseek_client()
    if not client:
        return "‚ùå API –∫–ª—é—á –Ω–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω. –î–æ–±–∞–≤—å DEEPSEEK_API_KEY –≤ .env —Ñ–∞–π–ª"
    
    try:
        user_id = user_context.get("user_id", "anonymous") if user_context else "anonymous"
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –∏—Å—Ç–æ—Ä–∏—é –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        if user_id not in chat_history:
            chat_history[user_id] = []
        
        # –î–æ–±–∞–≤–ª—è–µ–º –Ω–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ –≤ –∏—Å—Ç–æ—Ä–∏—é
        chat_history[user_id].append({"role": "user", "content": message})
        
        # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –∏—Å—Ç–æ—Ä–∏—é –ø–æ—Å–ª–µ–¥–Ω–∏–º–∏ 10 —Å–æ–æ–±—â–µ–Ω–∏—è–º–∏
        if len(chat_history[user_id]) > 20:
            chat_history[user_id] = chat_history[user_id][-20:]
        
        # –§–æ—Ä–º–∏—Ä—É–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        context = ""
        if user_context:
            context = f"""
            –£—á–µ–Ω–∏–∫: {user_context.get('name', '–ê–Ω–æ–Ω–∏–º')}
            –£—Ä–æ–≤–µ–Ω—å: HSK {user_context.get('current_level', 1)} ‚Üí HSK {user_context.get('target_level', 4)}
            –≠–∫–∑–∞–º–µ–Ω: {user_context.get('exam_date', '—Å–∫–æ—Ä–æ')} –≤ {user_context.get('exam_location', '–ú–æ—Å–∫–≤–∞')}
            –ò–Ω—Ç–µ—Ä–µ—Å—ã: {', '.join(user_context.get('interests', []))}
            """
        
        # –§–æ—Ä–º–∏—Ä—É–µ–º –ø—Ä–æ–º–ø—Ç
        formatted_system_prompt = system_prompt.replace("{context}", context)
        
        # –§–æ—Ä–º–∏—Ä—É–µ–º –∏—Å—Ç–æ—Ä–∏—é –¥–ª—è AI
        messages = [
            {"role": "system", "content": formatted_system_prompt},
            *chat_history[user_id][-10:]  # –ë–µ—Ä–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–µ 10 —Å–æ–æ–±—â–µ–Ω–∏–π
        ]
        
        response = client.chat.completions.create(
            model="deepseek-chat",
            messages=messages,
            temperature=0.7,
            max_tokens=1500
        )
        
        ai_response = response.choices[0].message.content
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ—Ç–≤–µ—Ç AI –≤ –∏—Å—Ç–æ—Ä–∏—é
        chat_history[user_id].append({"role": "assistant", "content": ai_response})
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –¥–∞–Ω–Ω—ã–µ
        save_user_data()
        
        return ai_response
        
    except Exception as e:
        return f"‚ùå –û—à–∏–±–∫–∞ API: {str(e)}"
    
    # API –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –∏—Å—Ç–æ—Ä–∏–∏
@app.get("/chat/history/{user_id}")
async def get_chat_history(user_id: str, limit: int = 50):
    """–ü–æ–ª—É—á–∏—Ç—å –∏—Å—Ç–æ—Ä–∏—é —á–∞—Ç–∞"""
    if user_id not in chat_history:
        return {"history": [], "count": 0}
    
    history = chat_history[user_id][-limit:]
    return {
        "history": history,
        "count": len(history)
    }

# API –¥–ª—è –æ—á–∏—Å—Ç–∫–∏ –∏—Å—Ç–æ—Ä–∏–∏
@app.delete("/chat/history/{user_id}")
async def clear_chat_history(user_id: str):
    """–û—á–∏—Å—Ç–∏—Ç—å –∏—Å—Ç–æ—Ä–∏—é —á–∞—Ç–∞"""
    if user_id in chat_history:
        chat_history[user_id] = []
    return {"message": "–ò—Å—Ç–æ—Ä–∏—è –æ—á–∏—â–µ–Ω–∞"}

def load_words():
    """–ó–∞–≥—Ä—É–∂–∞–µ–º —Å–ª–æ–≤–∞ –∏–∑ JSON —Ñ–∞–π–ª–∞"""
    global words_db
    
    # –ü—Ä–æ–±—É–µ–º –∑–∞–≥—Ä—É–∑–∏—Ç—å –∏–∑ —Ä–∞–∑–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤
    possible_files = [
        "data/hsk_all_words.json",
        "data/hsk_words.json",
        "data/hsk1_words.json"
    ]
    
    loaded = False
    for file_path in possible_files:
        try:
            if os.path.exists(file_path):
                with open(file_path, "r", encoding="utf-8") as f:
                    words_db = json.load(f)
                
                print(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ –∏–∑ {file_path}: {len(words_db)} —Å–ª–æ–≤")
                
                # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
                stats = {}
                for word in words_db:
                    level = word.get("hsk_level", 0)
                    stats[level] = stats.get(level, 0) + 1
                
                print("üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞:")
                for level in sorted(stats.keys()):
                    print(f"  HSK {level}: {stats[level]} —Å–ª–æ–≤")
                
                loaded = True
                break
                
        except Exception as e:
            print(f"‚ö†Ô∏è  –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ {file_path}: {e}")
    
    if not loaded:
        print("‚ö†Ô∏è  –§–∞–π–ª—ã —Å–æ —Å–ª–æ–≤–∞–º–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã. –ò—Å–ø–æ–ª—å–∑—É—é —Ç–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ.")
        words_db = [
            {"character": "‰Ω†Â•Ω", "pinyin": "n«ê h«éo", "translation": "–ø—Ä–∏–≤–µ—Ç", "hsk_level": 1},
            {"character": "Ë∞¢Ë∞¢", "pinyin": "xi√® xie", "translation": "—Å–ø–∞—Å–∏–±–æ", "hsk_level": 1},
        ]

def generate_memory_tip(word: dict, learning_style: str = "visual") -> str:
    """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —Å–æ–≤–µ—Ç –ø–æ –∑–∞–ø–æ–º–∏–Ω–∞–Ω–∏—é"""
    char = word["character"]
    pinyin = word["pinyin"]
    translation = word["translation"]
    level = word.get("hsk_level", 1)
    
    tips = {
        "visual": [
            f"üëÅÔ∏è –ù–∞—Ä–∏—Å—É–π {char} –≤ –≤–æ–∑–¥—É—Ö–µ 3 —Ä–∞–∑–∞",
            f"üé® –ü—Ä–µ–¥—Å—Ç–∞–≤—å {translation} –≤ –≤–∏–¥–µ –∫–∞—Ä—Ç–∏–Ω–∫–∏ —Å {char}",
            f"üìù –ù–∞–ø–∏—à–∏ {char} —Ü–≤–µ—Ç–Ω—ã–º–∏ –º–∞—Ä–∫–µ—Ä–∞–º–∏",
            f"üéØ –°–æ–∑–¥–∞–π –º–µ–Ω—Ç–∞–ª—å–Ω—É—é –∫–∞—Ä—Ç—É –¥–ª—è {char} ‚Üí {translation}",
            f"üåà –°–≤—è–∂–∏ —Ü–≤–µ—Ç —Å –∏–µ—Ä–æ–≥–ª–∏—Ñ–æ–º {char}"
        ],
        "auditory": [
            f"üîä –ü—Ä–æ–∏–∑–Ω–µ—Å–∏ '{pinyin}' —Å —Ä–∞–∑–Ω–æ–π –∏–Ω—Ç–æ–Ω–∞—Ü–∏–µ–π",
            f"üéµ –ü—Ä–∏–¥—É–º–∞–π –ø–µ—Å–Ω—é –ø—Ä–æ {char} = {translation}",
            f"üó£Ô∏è –ü–æ–≤—Ç–æ—Ä–∏ '{pinyin} - {translation}' 5 —Ä–∞–∑ –≤—Å–ª—É—Ö",
            f"üéß –ó–∞–ø–∏—à–∏ –ø—Ä–æ–∏–∑–Ω–æ—à–µ–Ω–∏–µ {char} –∏ —Å–ª—É—à–∞–π",
            f"üé§ –ü—Ä–æ–≥–æ–≤–æ—Ä–∏ {char} –∫–∞–∫ –¥–∏–∫—Ç–æ—Ä –Ω–∞ —Ä–∞–¥–∏–æ"
        ],
        "kinesthetic": [
            f"‚úçÔ∏è –ù–∞–ø–∏—à–∏ {char} –Ω–∞ –±—É–º–∞–≥–µ 10 —Ä–∞–∑",
            f"üëÜ –ù–∞—Ä–∏—Å—É–π {char} –ø–∞–ª—å—Ü–µ–º –Ω–∞ —Å—Ç–æ–ª–µ",
            f"üéÆ –°–¥–µ–ª–∞–π –∂–µ—Å—Ç –¥–ª—è {char}",
            f"üèÉ –ê—Å—Å–æ—Ü–∏–∏—Ä—É–π {char} —Å –¥–≤–∏–∂–µ–Ω–∏–µ–º",
            f"ü§≤ –°–ª–µ–ø–∏ {char} –∏–∑ –ø–ª–∞—Å—Ç–∏–ª–∏–Ω–∞"
        ]
    }
    
    # –°–ø–µ—Ü–∏—Ñ–∏—á–Ω—ã–µ —Å–æ–≤–µ—Ç—ã –¥–ª—è –∏–µ—Ä–æ–≥–ª–∏—Ñ–æ–≤
    special_tips = []
    if "Â•Ω" in char:  # —Ö–æ—Ä–æ—à–∏–π
        special_tips.append("üë´ 'Â•Ω' = Â•≥ (–∂–µ–Ω—â–∏–Ω–∞) + Â≠ê (—Ä–µ–±–µ–Ω–æ–∫) = –∂–µ–Ω—â–∏–Ω–∞ —Å —Ä–µ–±–µ–Ω–∫–æ–º = —Ö–æ—Ä–æ—à–æ!")
    if "Ë∞¢" in char:  # –±–ª–∞–≥–æ–¥–∞—Ä–∏—Ç—å
        special_tips.append("üôè 'Ë∞¢' = Ë®Ä (—Ä–µ—á—å) + Â∞Ñ (—Å—Ç—Ä–µ–ª—è—Ç—å) = —Å–ª–æ–≤–∞ –∫–∞–∫ —Å—Ç—Ä–µ–ª—ã –±–ª–∞–≥–æ–¥–∞—Ä–Ω–æ—Å—Ç–∏")
    if "Â≠¶" in char:  # —É—á–∏—Ç—å—Å—è
        special_tips.append("üìö 'Â≠¶' = Â≠ê (—Ä–µ–±–µ–Ω–æ–∫) –ø–æ–¥ –∫—Ä—ã—à–µ–π ÂÆÄ = —Ä–µ–±–µ–Ω–æ–∫ —É—á–∏—Ç—Å—è –¥–æ–º–∞")
    if "Áà±" in char:  # –ª—é–±–æ–≤—å
        special_tips.append("‚ù§Ô∏è 'Áà±' = Áà´ (—Ä—É–∫–∞) + ÂÜñ (–∫—Ä—ã—à–∞) + Âèã (–¥—Ä—É–≥) = —Ä—É–∫–∞ –¥—Ä—É–≥–∞ –ø–æ–¥ –∫—Ä—ã—à–µ–π = –ª—é–±–æ–≤—å")
    
    # –í—ã–±–∏—Ä–∞–µ–º —Å–æ–≤–µ—Ç—ã –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —Å—Ç–∏–ª—è –æ–±—É—á–µ–Ω–∏—è
    style_tips = tips.get(learning_style, tips["visual"])
    
    all_tips = special_tips + style_tips
    return random.choice(all_tips)

def get_words_by_level(level: int, limit: int = 10000) -> List[Dict]:
    """–ü–æ–ª—É—á–∏—Ç—å —Å–ª–æ–≤–∞ –ø–æ —É—Ä–æ–≤–Ω—é HSK"""
    return [w for w in words_db if w.get("hsk_level") == level][:limit]

def get_exam_hacks(location: str, format: str, level: int) -> List[str]:
    """–õ–∞–π—Ñ—Ö–∞–∫–∏ –¥–ª—è —ç–∫–∑–∞–º–µ–Ω–∞"""
    hacks = [
        "üéØ 80/20 –ø—Ä–∞–≤–∏–ª–æ: 20% —Å–ª–æ–≤ = 80% —Ç–µ–∫—Å—Ç–æ–≤",
        "‚è∞ –ù–∞—á–∏–Ω–∞–π —Å –ª–µ–≥–∫–∏—Ö –≤–æ–ø—Ä–æ—Å–æ–≤, —Å–ª–æ–∂–Ω—ã–µ –æ—Å—Ç–∞–≤—å –Ω–∞ –ø–æ—Ç–æ–º",
        "üìù –í –ø–∏—Å—å–º–µ–Ω–Ω–æ–π —á–∞—Å—Ç–∏ –ø–∏—à–∏ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ",
        "üß† –ï—Å–ª–∏ –Ω–µ –∑–Ω–∞–µ—à—å - —É–≥–∞–¥—ã–≤–∞–π, –Ω–µ –æ—Å—Ç–∞–≤–ª—è–π –ø—É—Å—Ç—ã–º",
        "üîÑ –ü—Ä–æ–≤–µ—Ä—è–π –æ—Ç–≤–µ—Ç—ã, –µ—Å–ª–∏ –æ—Å—Ç–∞–ª–æ—Å—å –≤—Ä–µ–º—è"
    ]
    
    # –ü–æ —É—Ä–æ–≤–Ω—é
    level_hacks = {
        1: ["üî§ –£—á–∏ —Ç–æ–ª—å–∫–æ –±–∞–∑–æ–≤—ã–µ –∏–µ—Ä–æ–≥–ª–∏—Ñ—ã", "üéØ –°—Ñ–æ–∫—É—Å–∏—Ä—É–π—Å—è –Ω–∞ –ø—Ä–æ–∏–∑–Ω–æ—à–µ–Ω–∏–∏"],
        2: ["üìö –î–æ–±–∞–≤—å –ø—Ä–æ—Å—Ç—ã–µ –≥—Ä–∞–º–º–∞—Ç–∏—á–µ—Å–∫–∏–µ –∫–æ–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏", "üëÇ –¢—Ä–µ–Ω–∏—Ä—É–π –∞—É–¥–∏—Ä–æ–≤–∞–Ω–∏–µ"],
        3: ["üí¨ –£—á–∏ –¥–∏–∞–ª–æ–≥–∏ —Ü–µ–ª–∏–∫–æ–º", "‚úçÔ∏è –ù–∞—á–∏–Ω–∞–π –ø–∏—Å–∞—Ç—å –ø—Ä–æ—Å—Ç—ã–µ —Ç–µ–∫—Å—Ç—ã"],
        4: ["üìñ –ß–∏—Ç–∞–π –∫–æ—Ä–æ—Ç–∫–∏–µ —Å—Ç–∞—Ç—å–∏", "üéØ –£—á–∏ —Å–∏–Ω–æ–Ω–∏–º—ã –∏ –∞–Ω—Ç–æ–Ω–∏–º—ã"],
        5: ["üéì –ì–æ—Ç–æ–≤—å—Å—è –∫ —Å–æ—á–∏–Ω–µ–Ω–∏—é", "üîç –ê–Ω–∞–ª–∏–∑–∏—Ä—É–π —Å–ª–æ–∂–Ω—ã–µ —Ç–µ–∫—Å—Ç—ã"],
        6: ["üèÜ –¢—Ä–µ–Ω–∏—Ä—É–π—Å—è –Ω–∞ —Ä–µ–∞–ª—å–Ω—ã—Ö —ç–∫–∑–∞–º–µ–Ω–∞—Ö", "üí° –£—á–∏ –∏–¥–∏–æ–º—ã –∏ –ø–æ—Å–ª–æ–≤–∏—Ü—ã"]
    }
    
    hacks.extend(level_hacks.get(level, []))
    
    # –ü–æ –º–µ—Å—Ç–æ–ø–æ–ª–æ–∂–µ–Ω–∏—é
    if "–∫–∏—Ç–∞–π" in location.lower() or "china" in location.lower():
        hacks.append("üá®üá≥ –í –ö–∏—Ç–∞–µ —Å—Ç—Ä–æ–∂–µ —Å –ø—Ä–æ–∏–∑–Ω–æ—à–µ–Ω–∏–µ–º –∏ –ø–æ—á–µ—Ä–∫–æ–º")
    elif "—Ä–æ—Å—Å–∏—è" in location.lower() or "russia" in location.lower():
        hacks.append("üá∑üá∫ –í –†–æ—Å—Å–∏–∏ —á–∞—Å—Ç–æ –¥–∞—é—Ç –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –º–∏–Ω—É—Ç—ã –Ω–∞ –∞—É–¥–∏—Ä–æ–≤–∞–Ω–∏–µ")
    
    # –ü–æ —Ñ–æ—Ä–º–∞—Ç—É
    if format == "computer":
        hacks.extend([
            "üíª –ò—Å–ø–æ–ª—å–∑—É–π CTRL+F –≤ —Ç–µ–∫—Å—Ç–∞—Ö –¥–ª—è –ø–æ–∏—Å–∫–∞ –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤",
            "‚å®Ô∏è –¢—Ä–µ–Ω–∏—Ä—É–π—Å—è –ø–µ—á–∞—Ç–∞—Ç—å –ø–∏–Ω—å–∏–Ω—å –±—ã—Å—Ç—Ä–æ",
            "üñ±Ô∏è –î–≤–∞–∂–¥—ã –ø—Ä–æ–≤–µ—Ä—è–π –ø–µ—Ä–µ–¥ –∫–ª–∏–∫–æ–º"
        ])
    else:  # paper
        hacks.extend([
            "‚úçÔ∏è –ü–∏—à–∏ —Ä–∞–∑–±–æ—Ä—á–∏–≤–æ, –¥–∞–∂–µ –µ—Å–ª–∏ –º–µ–¥–ª–µ–Ω–Ω–µ–µ",
            "üìù –ë–µ—Ä–∏ –∑–∞–ø–∞—Å–Ω—ã–µ —Ä—É—á–∫–∏",
            "üìÑ –†–∞–∑–º–µ—á–∞–π —Ç–µ–∫—Å—Ç –∫–∞—Ä–∞–Ω–¥–∞—à–æ–º"
        ])
    
    return hacks

# –ó–∞–≥—Ä—É–∂–∞–µ–º —Å–ª–æ–≤–∞ –ø—Ä–∏ —Å—Ç–∞—Ä—Ç–µ
load_words()

# ========== API –≠–ù–î–ü–û–ò–ù–¢–´ ==========
@app.get("/")
async def root():
    return {
        "message": "üéå HSK AI Tutor –≥–æ—Ç–æ–≤ –∫ —Ä–∞–±–æ—Ç–µ!",
        "version": "1.0",
        "database": f"{len(words_db)} —Å–ª–æ–≤",
        "endpoints": {
            "register": "POST /register - —Ä–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏—è",
            "chat": "POST /chat - –æ–±—â–µ–Ω–∏–µ —Å AI",
            "words_today": "GET /words/today/{user_id} - —Å–ª–æ–≤–∞ –Ω–∞ —Å–µ–≥–æ–¥–Ω—è",
            "test": "GET /test/{level} - —Ç–µ—Å—Ç –ø–æ —É—Ä–æ–≤–Ω—é",
            "exam": "GET /exam/{level} - –ø–æ–ª–Ω—ã–π —ç–∫–∑–∞–º–µ–Ω",
            "stats": "GET /stats - —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞",
            "search": "GET /search/{query} - –ø–æ–∏—Å–∫ —Å–ª–æ–≤",
            "word_random": "GET /word/random - —Å–ª—É—á–∞–π–Ω–æ–µ —Å–ª–æ–≤–æ",
            "words_level": "GET /words/level/{level} - —Å–ª–æ–≤–∞ –ø–æ —É—Ä–æ–≤–Ω—é",
            "docs": "GET /docs - –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è API"
        }
    }

@app.post("/register")
async def register_user(user: UserInfo):
    """–†–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏—è –Ω–æ–≤–æ–≥–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è"""
    user_id = f"user_{len(users_db) + 1}"
    
    # –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º –ø–ª–∞–Ω
    days_until_exam = max(1, (datetime.fromisoformat(user.exam_date) - datetime.now()).days)
    target_words = {
        1: 150, 2: 300, 3: 600, 4: 1200, 5: 2500, 6: 5000
    }.get(user.target_level, 1000)
    
    daily_words = max(5, target_words // days_until_exam)
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
    users_db[user_id] = {
        **user.dict(),
        "user_id": user_id,
        "registered_at": datetime.now().isoformat(),
        "daily_words": daily_words,
        "days_until_exam": days_until_exam
    }
    
    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –ø—Ä–æ–≥—Ä–µ—Å—Å
    word_progress_db[user_id] = {}
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –¥–∞–Ω–Ω—ã–µ
    save_user_data()
    
    return {
        "success": True,
        "user_id": user_id,
        "message": f"üéâ –î–æ–±—Ä–æ –ø–æ–∂–∞–ª–æ–≤–∞—Ç—å, {user.name}!",
        "plan": {
            "daily_words": daily_words,
            "days_until_exam": days_until_exam,
            "total_words_to_learn": target_words,
            "study_plan": f"–£—á–∏ –ø–æ {daily_words} —Å–ª–æ–≤ –≤ –¥–µ–Ω—å",
            "hacks": get_exam_hacks(user.exam_location, user.exam_format, user.target_level),
            "cheat_codes": [
                "üéÆ –£—á–∏ —Å–ª–æ–≤–∞ –≤–æ –≤—Ä–µ–º—è –∑–∞–≤—Ç—Ä–∞–∫–∞",
                "üöå –ò—Å–ø–æ–ª—å–∑—É–π –∫–∞—Ä—Ç–æ—á–∫–∏ –≤ —Ç—Ä–∞–Ω—Å–ø–æ—Ä—Ç–µ",
                "üõå –ü–æ–≤—Ç–æ—Ä—è–π –ø–µ—Ä–µ–¥ —Å–Ω–æ–º",
                "üéØ –§–æ–∫—É—Å–∏—Ä—É–π—Å—è –Ω–∞ —Å–ª–∞–±—ã—Ö –º–µ—Å—Ç–∞—Ö"
            ]
        }
    }
    

@app.get("/user/{user_id}")
async def get_user_info(user_id: str):
    """–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ"""
    if user_id not in users_db:
        raise HTTPException(status_code=404, detail="–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –Ω–µ –Ω–∞–π–¥–µ–Ω")
    
    user = users_db[user_id]
    
    # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
    progress = word_progress_db.get(user_id, {})
    learned_words = len([p for p in progress.values() if p.get("remembered", False)])
    
    return {
        **user,
        "stats": {
            "learned_words": learned_words,
            "total_words": len(words_db),
            "progress_percentage": min(100, int(learned_words / len(words_db) * 100)) if words_db else 0
        }
    }

@app.post("/chat")
async def chat_with_ai(chat_msg: ChatMessage):
    """–ß–∞—Ç —Å –ò–ò-—Ä–µ–ø–µ—Ç–∏—Ç–æ—Ä–æ–º"""
    # –ü–æ–ª—É—á–∞–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –µ—Å–ª–∏ –µ—Å—Ç—å
    user_context = None
    if chat_msg.user_id and chat_msg.user_id in users_db:
        user_context = users_db[chat_msg.user_id]
    
    # –ò—Å–ø–æ–ª—å–∑—É–µ–º DeepSeek
    answer = await chat_with_deepseek(chat_msg.message, user_context)
    
    return {
        "answer": answer,
        "user_id": chat_msg.user_id,
        "timestamp": datetime.now().isoformat()
    }

@app.get("/words/today/{user_id}")
async def get_todays_words(user_id: str, new_words: int = 10, review_words: int = 5):
    """–°–ª–æ–≤–∞ –Ω–∞ —Å–µ–≥–æ–¥–Ω—è —Å —Å–∏—Å—Ç–µ–º–æ–π –ø–æ–≤—Ç–æ—Ä–µ–Ω–∏–π"""
    if user_id not in users_db:
        raise HTTPException(status_code=404, detail="–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –Ω–µ –Ω–∞–π–¥–µ–Ω")
    
    user = users_db[user_id]
    level = user["current_level"]
    learning_style = user.get("learning_style", "visual")
    
    # –í—Å–µ —Å–ª–æ–≤–∞ –Ω—É–∂–Ω–æ–≥–æ —É—Ä–æ–≤–Ω—è
    level_words = get_words_by_level(level, 1000)
    
    if not level_words:
        raise HTTPException(status_code=404, detail=f"–°–ª–æ–≤–∞ HSK {level} –Ω–µ –Ω–∞–π–¥–µ–Ω—ã")
    
    # –ü–æ–ª—É—á–∞–µ–º –ø—Ä–æ–≥—Ä–µ—Å—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
    progress = word_progress_db.get(user_id, {})
    
    # –ù–æ–≤—ã–µ —Å–ª–æ–≤–∞ (–µ—â–µ –Ω–µ –∏–∑—É—á–∞–ª–∏—Å—å)
    new_words_list = []
    for word in level_words:
        if len(new_words_list) >= new_words:
            break
        
        word_id = f"{word['character']}_{level}"
        if word_id not in progress:
            word["word_id"] = word_id
            word["memory_tip"] = generate_memory_tip(word, learning_style)
            new_words_list.append(word)
    
    # –°–ª–æ–≤–∞ –¥–ª—è –ø–æ–≤—Ç–æ—Ä–µ–Ω–∏—è
    review_words_list = []
    today = datetime.now().date()
    
    for word_id, word_progress in progress.items():
        if len(review_words_list) >= review_words:
            break
        
        if word_progress.get("level") == level:
            last_review = datetime.fromisoformat(word_progress["last_reviewed"]).date()
            days_passed = (today - last_review).days
            
            # –ò–Ω—Ç–µ—Ä–≤–∞–ª—ã –ø–æ–≤—Ç–æ—Ä–µ–Ω–∏—è: 1, 3, 7, 14, 30 –¥–Ω–µ–π
            if days_passed in [1, 3, 7, 14, 30]:
                # –ù–∞—Ö–æ–¥–∏–º —Å–ª–æ–≤–æ
                for word in level_words:
                    if f"{word['character']}_{level}" == word_id:
                        word["word_id"] = word_id
                        word["memory_tip"] = generate_memory_tip(word, learning_style)
                        word["last_reviewed"] = word_progress["last_reviewed"]
                        word["difficulty"] = word_progress.get("difficulty", 3)
                        review_words_list.append(word)
                        break
    
    return {
        "user": user["name"],
        "level": level,
        "date": today.isoformat(),
        "words": {
            "new": new_words_list,
            "review": review_words_list
        },
        "study_tips": [
            f"üìö –ù–æ–≤—ã–µ —Å–ª–æ–≤–∞: {len(new_words_list)}",
            f"üîÑ –ü–æ–≤—Ç–æ—Ä–µ–Ω–∏–µ: {len(review_words_list)}",
            f"‚è∞ –†–µ–∫–æ–º–µ–Ω–¥—É–µ–º–æ–µ –≤—Ä–µ–º—è: {user['daily_time']} –º–∏–Ω—É—Ç",
            f"üéØ –°—Ç–∏–ª—å –æ–±—É—á–µ–Ω–∏—è: {learning_style}",
            "üí° –°–æ–≤–µ—Ç: –£—á–∏ —É—Ç—Ä–æ–º, –ø–æ–≤—Ç–æ—Ä—è–π –≤–µ—á–µ—Ä–æ–º"
        ]
    }

@app.post("/review")
async def submit_word_review(review: WordReview):
    """–û—Ç–ø—Ä–∞–≤–∏—Ç—å –æ—Ç–∑—ã–≤ –æ —Å–ª–æ–≤–µ (–∑–∞–ø–æ–º–Ω–∏–ª/–Ω–µ –∑–∞–ø–æ–º–Ω–∏–ª)"""
    if review.user_id not in users_db:
        raise HTTPException(status_code=404, detail="–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –Ω–µ –Ω–∞–π–¥–µ–Ω")
    
    # –û–±–Ω–æ–≤–ª—è–µ–º –ø—Ä–æ–≥—Ä–µ—Å—Å
    if review.user_id not in word_progress_db:
        word_progress_db[review.user_id] = {}
    
    word_progress_db[review.user_id][review.word_id] = {
        "remembered": review.remembered,
        "difficulty": review.difficulty,
        "last_reviewed": datetime.now().isoformat(),
        "review_count": word_progress_db[review.user_id].get(review.word_id, {}).get("review_count", 0) + 1
    }
    
    return {
        "success": True,
        "message": "–ü—Ä–æ–≥—Ä–µ—Å—Å —Å–æ—Ö—Ä–∞–Ω–µ–Ω!",
        "next_review": "–ó–∞–≤—Ç—Ä–∞" if review.remembered else "–ß–µ—Ä–µ–∑ 1 –¥–µ–Ω—å"
    }

@app.get("/test/{level}")
async def generate_test(level: int, questions: int = 10):
    """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ç–µ—Å—Ç–∞ –¥–ª—è —É—Ä–æ–≤–Ω—è HSK"""
    level_words = get_words_by_level(level, 1000)
    
    if not level_words:
        raise HTTPException(status_code=404, detail=f"–°–ª–æ–≤–∞ HSK {level} –Ω–µ –Ω–∞–π–¥–µ–Ω—ã")
    
    # –í—ã–±–∏—Ä–∞–µ–º —Å–ª—É—á–∞–π–Ω—ã–µ —Å–ª–æ–≤–∞
    selected_words = random.sample(level_words, min(questions, len(level_words)))
    
    test_questions = []
    for i, word in enumerate(selected_words, 1):
        # –°–æ–∑–¥–∞–µ–º –Ω–µ–ø—Ä–∞–≤–∏–ª—å–Ω—ã–µ –≤–∞—Ä–∏–∞–Ω—Ç—ã
        wrong_words = []
        other_words = [w for w in level_words if w["character"] != word["character"]]
        
        if len(other_words) >= 3:
            wrong_words = random.sample(other_words, 3)
        
        # –°–æ–∑–¥–∞–µ–º –≤–∞—Ä–∏–∞–Ω—Ç—ã –æ—Ç–≤–µ—Ç–æ–≤
        options = [word["translation"]] + [w["translation"] for w in wrong_words]
        random.shuffle(options)
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –ø—Ä–∞–≤–∏–ª—å–Ω—ã–π –æ—Ç–≤–µ—Ç
        correct_index = options.index(word["translation"])
        
        test_questions.append({
            "id": f"q_{i}",
            "question": f"–ö–∞–∫ –ø–µ—Ä–µ–≤–æ–¥–∏—Ç—Å—è '{word['character']}' ({word['pinyin']})?",
            "options": options,
            "correct_index": correct_index,
            "correct_answer": word["translation"],
            "points": 1,
            "hint": f"HSK {level}, —á–∞—Å—Ç—å —Ä–µ—á–∏: {word.get('part_of_speech', '–Ω–µ —É–∫–∞–∑–∞–Ω–æ')}"
        })
    
    # –°–æ–∑–¥–∞–µ–º ID —Ç–µ—Å—Ç–∞
    test_id = f"test_{level}_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ç–µ—Å—Ç
    tests_db[test_id] = {
        "level": level,
        "questions": test_questions,
        "created_at": datetime.now().isoformat(),
        "max_score": len(test_questions)
    }
    
    return {
        "test_id": test_id,
        "level": level,
        "total_questions": len(test_questions),
        "time_limit": f"{len(test_questions) * 1.5} –º–∏–Ω—É—Ç",
        "questions": test_questions,
        "test_hacks": [
            "‚è±Ô∏è –¢—Ä–∞—Ç—å –Ω–µ –±–æ–ª—å—à–µ 1.5 –º–∏–Ω—É—Ç –Ω–∞ –≤–æ–ø—Ä–æ—Å",
            "üéØ –ï—Å–ª–∏ —Å–æ–º–Ω–µ–≤–∞–µ—à—å—Å—è - –∏—Å–∫–ª—é—á–∞–π —è–≤–Ω–æ –Ω–µ–ø—Ä–∞–≤–∏–ª—å–Ω—ã–µ",
            "üìù –ü–æ–º–Ω–∏: –≤ HSK —á–∞—Å—Ç–æ –ø–æ–≤—Ç–æ—Ä—è—é—Ç—Å—è –ø–æ—Ö–æ–∂–∏–µ –≤–∞—Ä–∏–∞–Ω—Ç—ã",
            "üß† –ü–µ—Ä–≤–∞—è –º—ã—Å–ª—å —á–∞—Å—Ç–æ –ø—Ä–∞–≤–∏–ª—å–Ω–∞—è"
        ]
    }

@app.post("/submit_test")
async def submit_test_answers(test_data: TestAnswer):
    """–û—Ç–ø—Ä–∞–≤–∏—Ç—å –æ—Ç–≤–µ—Ç—ã –Ω–∞ —Ç–µ—Å—Ç"""
    if test_data.user_id not in users_db:
        raise HTTPException(status_code=404, detail="–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –Ω–µ –Ω–∞–π–¥–µ–Ω")
    
    if test_data.test_id not in tests_db:
        raise HTTPException(status_code=404, detail="–¢–µ—Å—Ç –Ω–µ –Ω–∞–π–¥–µ–Ω")
    
    test = tests_db[test_data.test_id]
    questions = test["questions"]
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –æ—Ç–≤–µ—Ç—ã
    correct = 0
    results = []
    
    for question in questions:
        user_answer = test_data.answers.get(question["id"])
        is_correct = user_answer == question["correct_index"]
        
        if is_correct:
            correct += 1
        
        results.append({
            "question_id": question["id"],
            "user_answer": user_answer,
            "correct_answer": question["correct_index"],
            "is_correct": is_correct,
            "explanation": f"–ü—Ä–∞–≤–∏–ª—å–Ω—ã–π –æ—Ç–≤–µ—Ç: {question['correct_answer']}"
        })
    
    score = correct
    max_score = len(questions)
    percentage = int((score / max_score) * 100) if max_score > 0 else 0
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
    if "results" not in tests_db[test_data.test_id]:
        tests_db[test_data.test_id]["results"] = {}
    
    tests_db[test_data.test_id]["results"][test_data.user_id] = {
        "score": score,
        "max_score": max_score,
        "percentage": percentage,
        "submitted_at": datetime.now().isoformat(),
        "answers": test_data.answers
    }
    
    # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —Ñ–∏–¥–±–µ–∫
    feedback = ""
    if percentage >= 80:
        feedback = "üéâ –û—Ç–ª–∏—á–Ω–æ! –¢—ã –≥–æ—Ç–æ–≤ –∫ —ç–∫–∑–∞–º–µ–Ω—É!"
    elif percentage >= 60:
        feedback = "üëç –•–æ—Ä–æ—à–æ! –ü—Ä–æ–¥–æ–ª–∂–∞–π —Ç—Ä–µ–Ω–∏—Ä–æ–≤–∞—Ç—å—Å—è!"
    else:
        feedback = "üí™ –ù—É–∂–Ω–æ –±–æ–ª—å—à–µ –ø—Ä–∞–∫—Ç–∏–∫–∏! –°—Ñ–æ–∫—É—Å–∏—Ä—É–π—Å—è –Ω–∞ —Å–ª–∞–±—ã—Ö –º–µ—Å—Ç–∞—Ö."
    
    return {
        "test_id": test_data.test_id,
        "user_id": test_data.user_id,
        "score": score,
        "max_score": max_score,
        "percentage": percentage,
        "feedback": feedback,
        "results": results,
        "recommendations": [
            f"üéØ –ü–æ–≤—Ç–æ—Ä–∏ —Å–ª–æ–≤–∞, –∫–æ—Ç–æ—Ä—ã–µ –æ—à–∏–±–∞–ª",
            f"‚è∞ –°–ª–µ–¥—É—é—â–∏–π —Ç–µ—Å—Ç —á–µ—Ä–µ–∑ 3 –¥–Ω—è",
            f"üìà –¶–µ–ª—å –Ω–∞ —Å–ª–µ–¥—É—é—â–∏–π —Ä–∞–∑: {min(100, percentage + 10)}%"
        ]
    }

@app.get("/exam/{level}")
async def generate_exam(level: int):
    """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –ø–æ–ª–Ω–æ–≥–æ —ç–∫–∑–∞–º–µ–Ω–∞ HSK"""
    level_words = get_words_by_level(level, 1000)
    
    if not level_words:
        raise HTTPException(status_code=404, detail=f"–°–ª–æ–≤–∞ HSK {level} –Ω–µ –Ω–∞–π–¥–µ–Ω—ã")
    
    # –†–∞–∑–Ω—ã–µ —á–∞—Å—Ç–∏ —ç–∫–∑–∞–º–µ–Ω–∞
    exam = {
        "listening": [],
        "reading": [],
        "writing": [],
        "speaking": []
    }
    
    # –ê–£–î–ò–†–û–í–ê–ù–ò–ï (4 –≤–æ–ø—Ä–æ—Å–∞)
    for i in range(4):
        word = random.choice(level_words)
        wrong_words = random.sample([w for w in level_words if w != word], 3)
        
        exam["listening"].append({
            "type": "multiple_choice",
            "id": f"listening_{i+1}",
            "question": f"–°–ª—É—à–∞–π—Ç–µ –∞—É–¥–∏–æ –∏ –≤—ã–±–µ—Ä–∏—Ç–µ –ø—Ä–∞–≤–∏–ª—å–Ω—ã–π –ø–µ—Ä–µ–≤–æ–¥ –¥–ª—è:",
            "character": word["character"],
            "pinyin": word["pinyin"],
            "options": [word["translation"]] + [w["translation"] for w in wrong_words],
            "correct_answer": word["translation"],
            "points": 5,
            "time_limit": "30 —Å–µ–∫—É–Ω–¥"
        })
    
    # –ß–¢–ï–ù–ò–ï (3 –≤–æ–ø—Ä–æ—Å–∞)
    for i in range(3):
        # –°–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏–µ
        pairs = random.sample(level_words, min(4, len(level_words)))
        exam["reading"].append({
            "type": "matching",
            "id": f"reading_{i+1}",
            "question": "–°–æ–ø–æ—Å—Ç–∞–≤—å—Ç–µ –∫–∏—Ç–∞–π—Å–∫–∏–µ —Å–ª–æ–≤–∞ —Å –ø–µ—Ä–µ–≤–æ–¥–∞–º–∏:",
            "pairs": [{"character": w["character"], "pinyin": w["pinyin"]} for w in pairs],
            "answers": [w["translation"] for w in pairs],
            "shuffled_answers": random.sample([w["translation"] for w in pairs], len(pairs)),
            "points": 10,
            "time_limit": "2 –º–∏–Ω—É—Ç—ã"
        })
    
    # –ü–ò–°–¨–ú–û (2 –≤–æ–ø—Ä–æ—Å–∞)
    writing_words = random.sample(level_words, min(2, len(level_words)))
    exam["writing"].append({
        "type": "writing",
        "id": "writing_1",
        "question": "–ù–∞–ø–∏—à–∏—Ç–µ –∏–µ—Ä–æ–≥–ª–∏—Ñ—ã –¥–ª—è —Å–ª–µ–¥—É—é—â–∏—Ö —Å–ª–æ–≤:",
        "words": [{"pinyin": w["pinyin"], "translation": w["translation"]} for w in writing_words],
        "answers": [w["character"] for w in writing_words],
        "points": 15,
        "time_limit": "5 –º–∏–Ω—É—Ç"
    })
    
    # –ì–û–í–û–†–ï–ù–ò–ï (1 –≤–æ–ø—Ä–æ—Å)
    speaking_word = random.choice(level_words)
    exam["speaking"].append({
        "type": "speaking",
        "id": "speaking_1",
        "question": f"–ü—Ä–æ–∏–∑–Ω–µ—Å–∏—Ç–µ —Å–ª–æ–≤–æ –∏ —Å–æ—Å—Ç–∞–≤—å—Ç–µ —Å –Ω–∏–º –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ:",
        "word": {
            "character": speaking_word["character"],
            "pinyin": speaking_word["pinyin"],
            "translation": speaking_word["translation"]
        },
        "example": f"–ü—Ä–∏–º–µ—Ä: '{speaking_word['character']} ({speaking_word['pinyin']})' - {speaking_word['translation']}",
        "points": 20,
        "time_limit": "3 –º–∏–Ω—É—Ç—ã"
    })
    
    exam_id = f"exam_{level}_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
    
    return {
        "exam_id": exam_id,
        "level": level,
        "total_points": 100,
        "time_total": "60 –º–∏–Ω—É—Ç",
        "sections": exam,
        "exam_strategy": [
            "üéØ –ù–∞—á–∏–Ω–∞–π —Å –ª—é–±–∏–º–æ–π —á–∞—Å—Ç–∏",
            "‚è∞ –†–∞—Å–ø—Ä–µ–¥–µ–ª–∏ –≤—Ä–µ–º—è: 20–º–∏–Ω —á—Ç–µ–Ω–∏–µ, 15–º–∏–Ω –∞—É–¥–∏—Ä–æ–≤–∞–Ω–∏–µ, 15–º–∏–Ω –ø–∏—Å—å–º–æ, 10–º–∏–Ω –≥–æ–≤–æ—Ä–µ–Ω–∏–µ",
            "üìù –í –ø–∏—Å—å–º–µ–Ω–Ω–æ–π —á–∞—Å—Ç–∏ –ø–∏—à–∏ —Å–Ω–∞—á–∞–ª–∞ –Ω–∞ —á–µ—Ä–Ω–æ–≤–∏–∫–µ",
            "üé§ –í –≥–æ–≤–æ—Ä–µ–Ω–∏–∏ –≥–æ–≤–æ—Ä–∏ —á–µ—Ç–∫–æ –∏ –Ω–µ —Ç–æ—Ä–æ–ø–∏—Å—å",
            "üîÑ –û—Å—Ç–∞–≤—å 5 –º–∏–Ω—É—Ç –Ω–∞ –ø—Ä–æ–≤–µ—Ä–∫—É"
        ]
    }

@app.get("/stats")
async def get_stats():
    """–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö"""
    if not words_db:
        return {"message": "–ë–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö –ø—É—Å—Ç–∞"}
    
    stats = {
        "total_words": len(words_db),
        "by_level": {},
        "by_part_of_speech": {},
        "users_count": len(users_db),
        "tests_taken": len(tests_db)
    }
    
    # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ —É—Ä–æ–≤–Ω—è–º
    for word in words_db:
        level = word.get("hsk_level", 0)
        stats["by_level"][f"HSK {level}"] = stats["by_level"].get(f"HSK {level}", 0) + 1
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ —á–∞—Å—Ç—è–º —Ä–µ—á–∏
        pos = word.get("part_of_speech", "–Ω–µ —É–∫–∞–∑–∞–Ω–æ")
        stats["by_part_of_speech"][pos] = stats["by_part_of_speech"].get(pos, 0) + 1
    
    # –°–∞–º—ã–µ —á–∞—Å—Ç—ã–µ –∏–µ—Ä–æ–≥–ª–∏—Ñ—ã
    character_count = {}
    for word in words_db:
        for char in word.get("character", ""):
            if '\u4e00' <= char <= '\u9fff':
                character_count[char] = character_count.get(char, 0) + 1
    
    top_characters = sorted(character_count.items(), key=lambda x: x[1], reverse=True)[:10]
    stats["top_characters"] = [{"character": char, "count": count} for char, count in top_characters]
    
    return stats

@app.get("/search/{query}")
async def search_words(query: str, limit: int = 20):
    """–ü–æ–∏—Å–∫ —Å–ª–æ–≤ –ø–æ –∏–µ—Ä–æ–≥–ª–∏—Ñ–∞–º, –ø–∏–Ω—å–∏–Ω—é –∏–ª–∏ –ø–µ—Ä–µ–≤–æ–¥—É"""
    results = []
    query_lower = query.lower()
    
    for word in words_db:
        # –ü–æ–∏—Å–∫ –≤ –∏–µ—Ä–æ–≥–ª–∏—Ñ–∞—Ö
        if query in word.get("character", ""):
            results.append(word)
            continue
            
        # –ü–æ–∏—Å–∫ –≤ –ø–∏–Ω—å–∏–Ω–µ
        pinyin = word.get("pinyin", "").lower()
        if query_lower in pinyin:
            results.append(word)
            continue
            
        # –ü–æ–∏—Å–∫ –≤ –ø–µ—Ä–µ–≤–æ–¥–µ
        translation = word.get("translation", "").lower()
        if query_lower in translation:
            results.append(word)
    
    return {
        "query": query,
        "count": len(results),
        "results": results[:limit]
    }

@app.get("/word/random")
async def get_random_word(level: Optional[int] = None):
    """–ü–æ–ª—É—á–∏—Ç—å —Å–ª—É—á–∞–π–Ω–æ–µ —Å–ª–æ–≤–æ"""
    if level:
        filtered_words = [w for w in words_db if w.get("hsk_level") == level]
    else:
        filtered_words = words_db
    
    if not filtered_words:
        raise HTTPException(status_code=404, detail="–°–ª–æ–≤–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã")
    
    word = random.choice(filtered_words)
    
    # –£–º–Ω—ã–π –ø–æ–∏—Å–∫ –ø–æ—Ö–æ–∂–∏—Ö —Å–ª–æ–≤:
    similar = []
    word_level = word.get("hsk_level", 1)
    word_chars = set(word["character"])
    
    for w in words_db:
        if w["character"] == word["character"]:
            continue
        
        # 1. –ü–æ—Ö–æ–∂–∏–µ –ø–æ —Å–æ—Å—Ç–∞–≤—É –∏–µ—Ä–æ–≥–ª–∏—Ñ–æ–≤
        w_chars = set(w["character"])
        common_chars = word_chars.intersection(w_chars)
        
        # 2. –ü–æ—Ö–æ–∂–∏–µ –ø–æ —Ç–µ–º–∞—Ç–∏–∫–µ (–∞–Ω–∞–ª–∏–∑ –ø–µ—Ä–µ–≤–æ–¥–∞)
        word_trans_lower = word["translation"].lower()
        w_trans_lower = w["translation"].lower()
        
        # –ü—Ä–æ—Å—Ç–æ–π –∞–Ω–∞–ª–∏–∑ —Ç–µ–º–∞—Ç–∏–∫–∏
        categories = {
            "—Å–µ–º—å—è": ["–º–∞—Ç—å", "–æ—Ç–µ—Ü", "–±—Ä–∞—Ç", "—Å–µ—Å—Ç—Ä–∞", "—Å–µ–º—å—è", "—Ä–æ–¥–∏—Ç–µ–ª–∏"],
            "–µ–¥–∞": ["–µ—Å—Ç—å", "–ø–∏—Ç—å", "–µ–¥–∞", "–≤–æ–¥–∞", "—á–∞–π", "—Ä–∏—Å"],
            "–ø—É—Ç–µ—à–µ—Å—Ç–≤–∏–µ": ["–∏–¥—Ç–∏", "–ø—Ä–∏–µ–∑–∂–∞—Ç—å", "–ø–æ–µ–∑–¥", "—Å–∞–º–æ–ª–µ—Ç", "–≥–æ—Å—Ç–∏–Ω–∏—Ü–∞"],
            "—É—á–µ–±–∞": ["—É—á–∏—Ç—å—Å—è", "—à–∫–æ–ª–∞", "—Å—Ç—É–¥–µ–Ω—Ç", "—É—á–∏—Ç–µ–ª—å", "–∫–Ω–∏–≥–∞"],
            "–≤—Ä–µ–º—è": ["–≤—Ä–µ–º—è", "—á–∞—Å", "–¥–µ–Ω—å", "–º–µ—Å—è—Ü", "–≥–æ–¥", "—Å–µ–≥–æ–¥–Ω—è"]
        }
        
        similarity_found = False
        
        # –ü–æ—Ö–æ–∂–∏–µ –∏–µ—Ä–æ–≥–ª–∏—Ñ—ã
        if common_chars:
            similarity_found = True
        
        # –û–¥–∏–Ω–∞–∫–æ–≤—ã–π —É—Ä–æ–≤–µ–Ω—å
        if w.get("hsk_level", 1) == word_level:
            similarity_found = True
        
        # –ü–æ—Ö–æ–∂–∏–π –ø–µ—Ä–µ–≤–æ–¥ (–∏—â–µ–º –æ–±—â–∏–µ —Å–ª–æ–≤–∞ –≤ –ø–µ—Ä–µ–≤–æ–¥–µ)
        word_trans_words = set(word_trans_lower.split())
        w_trans_words = set(w_trans_lower.split())
        common_words = word_trans_words.intersection(w_trans_words)
        
        if len(common_words) > 0:
            similarity_found = True
        
        # –û–¥–∏–Ω–∞–∫–æ–≤–∞—è —Ç–µ–º–∞—Ç–∏–∫–∞
        for category, keywords in categories.items():
            word_has_keyword = any(keyword in word_trans_lower for keyword in keywords)
            w_has_keyword = any(keyword in w_trans_lower for keyword in keywords)
            
            if word_has_keyword and w_has_keyword:
                similarity_found = True
                break
        
        if similarity_found:
            similar.append({
                "character": w["character"],
                "pinyin": w["pinyin"],
                "translation": w["translation"][:50],
                "hsk_level": w.get("hsk_level", 1),
                "why_similar": f"–û–±—â–∏–µ –∏–µ—Ä–æ–≥–ª–∏—Ñ—ã: {len(common_chars)}, –¢–µ–º–∞—Ç–∏–∫–∞: {category if 'category' in locals() else '–æ–±—â–∞—è'}"
            })
    
    # –ë–µ—Ä–µ–º 3 —Å–∞–º—ã—Ö –ø–æ—Ö–æ–∂–∏—Ö
    if len(similar) > 3:
        similar = similar[:3]
    elif len(similar) < 3:
        # –î–æ–±–∞–≤–ª—è–µ–º —Å–ª—É—á–∞–π–Ω—ã–µ —Å–ª–æ–≤–∞ —Ç–æ–≥–æ –∂–µ —É—Ä–æ–≤–Ω—è
        same_level_words = [w for w in filtered_words if w["character"] != word["character"]]
        while len(similar) < 3 and same_level_words:
            random_similar = random.choice(same_level_words)
            if random_similar not in similar:
                similar.append({
                    "character": random_similar["character"],
                    "pinyin": random_similar["pinyin"],
                    "translation": random_similar["translation"][:50],
                    "hsk_level": random_similar.get("hsk_level", 1),
                    "why_similar": "–°–ª—É—á–∞–π–Ω–æ–µ —Å–ª–æ–≤–æ —Ç–æ–≥–æ –∂–µ —É—Ä–æ–≤–Ω—è"
                })
    
    return {
        "word": word,
        "similar_words": similar,
        "memory_tip": generate_memory_tip(word),
        "study_suggestions": [
            "üîä –ü—Ä–æ–∏–∑–Ω–µ—Å–∏ –≤—Å–ª—É—Ö 10 —Ä–∞–∑–∞",
            f"üß† –°—Ä–∞–≤–Ω–∏ —Å –ø–æ—Ö–æ–∂–∏–º–∏: {', '.join([s['character'] for s in similar])}",
            "‚è∞ –ü–æ–≤—Ç–æ—Ä–∏ —Å–µ–≥–æ–¥–Ω—è –µ—â–µ 3 —Ä–∞–∑–∞"
        ]
    }

class TextGenerationRequest(BaseModel):
    topic: str
    description: Optional[str] = ""
    hsk_level: int = 3
    format: str = "chinese_only"  # chinese_only, full, manga
    length: str = "medium"  # short, medium, long
    user_id: Optional[str] = None
    include_emojis: bool = True
    manga_style: bool = False

@app.post("/text/generate")
async def generate_chinese_text(request: TextGenerationRequest):
    """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ç–µ–∫—Å—Ç–∞ –Ω–∞ –∫–∏—Ç–∞–π—Å–∫–æ–º —Å –∑–∞–¥–∞–Ω–Ω—ã–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏"""
    try:
        # –ü–æ–ª—É—á–∞–µ–º –∫–ª–∏–µ–Ω—Ç DeepSeek
        client = get_deepseek_client()
        if not client:
            raise HTTPException(status_code=500, detail="AI —Å–µ—Ä–≤–∏—Å –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω")
        
        # –§–æ—Ä–º–∏—Ä—É–µ–º –ø—Ä–æ–º–ø—Ç –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —Ñ–æ—Ä–º–∞—Ç–∞
        format_prompts = {
            "chinese_only": "–¢–û–õ–¨–ö–û –Ω–∞ –∫–∏—Ç–∞–π—Å–∫–æ–º —è–∑—ã–∫–µ —Å –∏–µ—Ä–æ–≥–ª–∏—Ñ–∞–º–∏",
            "full": "–ù–∞ –∫–∏—Ç–∞–π—Å–∫–æ–º —Å –ø–∏–Ω—å–∏–Ω–µ–º –∏ —Ä—É—Å—Å–∫–∏–º –ø–µ—Ä–µ–≤–æ–¥–æ–º",
            "manga": "–í —Å—Ç–∏–ª–µ –º–∞–Ω–≥–∏ —Å –¥–∏–∞–ª–æ–≥–∞–º–∏ –∏ –æ–ø–∏—Å–∞–Ω–∏—è–º–∏"
        }
        
        format_instruction = format_prompts.get(request.format, "–ù–∞ –∫–∏—Ç–∞–π—Å–∫–æ–º")
        
        # –§–æ—Ä–º–∏—Ä—É–µ–º —Å–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç
        system_prompt = f"""–¢—ã ‚Äî –∞–≤—Ç–æ—Ä –∫–∏—Ç–∞–π—Å–∫–∏—Ö —Ç–µ–∫—Å—Ç–æ–≤ –¥–ª—è –∏–∑—É—á–∞—é—â–∏—Ö —è–∑—ã–∫.
        
# –ó–ê–î–ê–ß–ê:
–°–æ–∑–¥–∞—Ç—å —Ç–µ–∫—Å—Ç –Ω–∞ —Ç–µ–º—É: "{request.topic}"
–û–ø–∏—Å–∞–Ω–∏–µ: {request.description}

# –¢–†–ï–ë–û–í–ê–ù–ò–Ø:
1. –£—Ä–æ–≤–µ–Ω—å —Å–ª–æ–∂–Ω–æ—Å—Ç–∏: HSK {request.hsk_level}
2. –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —Å–ª–æ–≤–∞ –ø—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–µ–Ω–Ω–æ —É—Ä–æ–≤–Ω—è HSK {request.hsk_level} –∏ –Ω–∏–∂–µ
3. {format_instruction}
4. –î–ª–∏–Ω–∞: {request.length} (–æ–∫–æ–ª–æ {2000 if request.length == 'medium' else 1000 if request.length == 'short' else 3000} –∏–µ—Ä–æ–≥–ª–∏—Ñ–æ–≤)
5. {"–ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —ç–º–æ–¥–∑–∏ üéå" if request.include_emojis else "–ë–µ–∑ —ç–º–æ–¥–∑–∏"}
6. {"–°—Ç–∏–ª—å –∫–∞–∫ –≤ –º–∞–Ω–≥–µ: –¥–∏–∞–ª–æ–≥–∏, –æ–ø–∏—Å–∞–Ω–∏—è, —ç–º–æ—Ü–∏–∏" if request.manga_style else "–û–±—ã—á–Ω—ã–π –ø–æ–≤–µ—Å—Ç–≤–æ–≤–∞—Ç–µ–ª—å–Ω—ã–π —Å—Ç–∏–ª—å"}

# –§–û–†–ú–ê–¢–´:
- –ï—Å–ª–∏ –Ω—É–∂–µ–Ω —Ç–æ–ª—å–∫–æ –∫–∏—Ç–∞–π—Å–∫–∏–π: –∏–µ—Ä–æ–≥–ª–∏—Ñ—ã + –∑–Ω–∞–∫–∏ –ø—Ä–µ–ø–∏–Ω–∞–Ω–∏—è + —ç–º–æ–¥–∑–∏
- –ï—Å–ª–∏ –Ω—É–∂–µ–Ω –ø–∏–Ω—å–∏–Ω—å: Ê±âÂ≠ó (pinyin) „Äê–ø–µ—Ä–µ–≤–æ–¥„Äë
- –ï—Å–ª–∏ —Å—Ç–∏–ª—å –º–∞–Ω–≥–∏: 
  „Äê–ü–µ—Ä—Å–æ–Ω–∞–∂„Äë: –†–µ–ø–ª–∏–∫–∞
  *–æ–ø–∏—Å–∞–Ω–∏–µ –¥–µ–π—Å—Ç–≤–∏—è*
  
# –°–¢–†–£–ö–¢–£–†–ê:
- –í–≤–µ–¥–µ–Ω–∏–µ/–Ω–∞—á–∞–ª–æ
- –û—Å–Ω–æ–≤–Ω–∞—è —á–∞—Å—Ç—å —Å —Ä–∞–∑–≤–∏—Ç–∏–µ–º
- –ó–∞–∫–ª—é—á–µ–Ω–∏–µ/–≤—ã–≤–æ–¥

–ë—É–¥—å –∫—Ä–µ–∞—Ç–∏–≤–Ω—ã–º, –Ω–æ –∏—Å–ø–æ–ª—å–∑—É–π —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â—É—é —É—Ä–æ–≤–Ω—é –ª–µ–∫—Å–∏–∫—É!"""

        messages = [
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": f"–°–æ–∑–¥–∞–π —Ç–µ–∫—Å—Ç –Ω–∞ —Ç–µ–º—É: {request.topic}"}
        ]
        
        response = client.chat.completions.create(
            model="deepseek-chat",
            messages=messages,
            temperature=0.8,
            max_tokens=4000,
            presence_penalty=0.3,
            frequency_penalty=0.2
        )
        
        text_content = response.choices[0].message.content
        
        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Ç–µ–∫—Å—Ç –¥–ª—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
        stats = analyze_chinese_text(text_content, request.hsk_level)
        
        # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º —Ç–µ–∫—Å—Ç –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —Ñ–æ—Ä–º–∞—Ç–∞
        formatted_text = format_generated_text(text_content, request.format)
        
        return {
            "success": True,
            "text": text_content,
            "formatted_text": formatted_text,
            "text_with_pinyin": add_pinyin_to_text(text_content) if request.format == "full" else None,
            "topic": request.topic,
            "hsk_level": request.hsk_level,
            "format": request.format,
            "stats": stats,
            "generated_at": datetime.now().isoformat(),
            "length_chars": len(text_content)
        }
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"–û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Ç–µ–∫—Å—Ç–∞: {str(e)}")

def analyze_chinese_text(text: str, target_hsk_level: int) -> Dict:
    """–ê–Ω–∞–ª–∏–∑ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞"""
    # –ü—Ä–æ—Å—Ç–æ–π –∞–Ω–∞–ª–∏–∑ (–≤ —Ä–µ–∞–ª—å–Ω–æ–º –ø—Ä–æ–µ–∫—Ç–µ –Ω—É–∂–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å HSK —Å–ª–æ–≤–∞—Ä—å)
    characters = len([c for c in text if '\u4e00-\u9fff'])
    words = text.split()
    unique_words = len(set(words))
    
    # –ü—Ä–æ—Å—Ç–∞—è –æ—Ü–µ–Ω–∫–∞ —Å–ª–æ–∂–Ω–æ—Å—Ç–∏
    estimated_level = min(6, max(1, target_hsk_level + random.randint(-1, 1)))
    
    return {
        "characters": characters,
        "words": len(words),
        "unique_words": unique_words,
        "hsk_level": estimated_level,
        "estimated_reading_time": f"{max(1, characters // 300)} –º–∏–Ω—É—Ç",
        "new_words": max(0, unique_words - target_hsk_level * 100)  # –ü—Ä–æ—Å—Ç–∞—è –æ—Ü–µ–Ω–∫–∞
    }

def format_generated_text(text: str, format_type: str) -> str:
    """–§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ –¥–ª—è —Ä–∞–∑–Ω—ã—Ö —Ñ–æ—Ä–º–∞—Ç–æ–≤"""
    if format_type == "manga":
        # –î–æ–±–∞–≤–ª—è–µ–º –º–∞—Ä–∫–µ—Ä—ã –¥–ª—è –º–∞–Ω–≥–∏
        lines = text.split('\n')
        formatted_lines = []
        for line in lines:
            if ':' in line and len(line) < 50:
                formatted_lines.append(f"üé≠ {line}")
            elif len(line) > 0:
                formatted_lines.append(f"üìñ {line}")
            else:
                formatted_lines.append("")
        return '\n'.join(formatted_lines)
    
    elif format_type == "full":
        # –ó–¥–µ—Å—å –º–æ–∂–Ω–æ –¥–æ–±–∞–≤–∏—Ç—å –ø–∏–Ω—å–∏–Ω—å –∏ –ø–µ—Ä–µ–≤–æ–¥
        return text  # –í —Ä–µ–∞–ª—å–Ω–æ–º –ø—Ä–æ–µ–∫—Ç–µ –Ω—É–∂–Ω–æ –∏–Ω—Ç–µ–≥—Ä–∏—Ä–æ–≤–∞—Ç—å pinyin –∏ –ø–µ—Ä–µ–≤–æ–¥
    
    return text

def add_pinyin_to_text(text: str) -> str:
    """–î–æ–±–∞–≤–ª–µ–Ω–∏–µ –ø–∏–Ω—å–∏–Ω—è –∫ —Ç–µ–∫—Å—Ç—É (–∑–∞–≥–ª—É—à–∫–∞)"""
    # –í —Ä–µ–∞–ª—å–Ω–æ–º –ø—Ä–æ–µ–∫—Ç–µ –Ω—É–∂–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –±–∏–±–ª–∏–æ—Ç–µ–∫—É –¥–ª—è –ø–∏–Ω—å–∏–Ω—è
    # –ù–∞–ø—Ä–∏–º–µ—Ä, pypinyin
    return text

# –ú–æ–¥–µ–ª–∏ –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ —ç—Å—Å–µ –∏ –ø–µ—Ä–µ–≤–æ–¥–æ–≤
class EssayCheckRequest(BaseModel):
    essay_text: str
    topic: str
    hsk_level: int
    min_length: int = 300
    user_id: Optional[str] = None
    time_spent: Optional[int] = None
    mode: str = "essay_check"

class TranslationCheckRequest(BaseModel):
    original_text: str
    user_translation: str
    target_hsk: int
    difficulty: str
    user_id: Optional[str] = None
    time_spent: Optional[int] = None
    mode: str = "translation_check"

class TranslationGenerateRequest(BaseModel):
    topic: str
    description: Optional[str] = ""  # <-- –¥–æ–±–∞–≤—å—Ç–µ
    difficulty: str = "medium"
    length: str = "medium"
    hsk_level: int = 4
    user_id: Optional[str] = None
    include_emojis: bool = True  # <-- –¥–æ–±–∞–≤—å—Ç–µ
    manga_style: bool = False  # <-- –¥–æ–±–∞–≤—å—Ç–µ

@app.post("/essay/check")
async def check_essay(request: EssayCheckRequest):
    """–ü—Ä–æ–≤–µ—Ä–∫–∞ —ç—Å—Å–µ AI"""
    try:
        client = get_deepseek_client()
        if not client:
            return generate_fallback_essay_check(request)
        
        # –§–æ—Ä–º–∏—Ä—É–µ–º –ø—Ä–æ–º–ø—Ç –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏
        system_prompt = f"""–¢—ã ‚Äî —Å—Ç—Ä–æ–≥–∏–π, –Ω–æ —Å–ø—Ä–∞–≤–µ–¥–ª–∏–≤—ã–π –ø—Ä–µ–ø–æ–¥–∞–≤–∞—Ç–µ–ª—å –∫–∏—Ç–∞–π—Å–∫–æ–≥–æ —è–∑—ã–∫–∞.
        
# –ó–ê–î–ê–ß–ê:
–ü—Ä–æ–≤–µ—Ä–∏—Ç—å —ç—Å—Å–µ –Ω–∞ —Ç–µ–º—É: "{request.topic}"
–£—Ä–æ–≤–µ–Ω—å —Å—Ç—É–¥–µ–Ω—Ç–∞: HSK {request.hsk_level}
–ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è –¥–ª–∏–Ω–∞: {request.min_length} –∏–µ—Ä–æ–≥–ª–∏—Ñ–æ–≤
–î–ª–∏–Ω–∞ —ç—Å—Å–µ —Å—Ç—É–¥–µ–Ω—Ç–∞: {len(request.essay_text)} –∏–µ—Ä–æ–≥–ª–∏—Ñ–æ–≤

# –ö–†–ò–¢–ï–†–ò–ò –û–¶–ï–ù–ö–ò:
1. **–ì—Ä–∞–º–º–∞—Ç–∏–∫–∞** (30%) - –ø—Ä–∞–≤–∏–ª—å–Ω–æ—Å—Ç—å –∫–æ–Ω—Å—Ç—Ä—É–∫—Ü–∏–π, —á–∞—Å—Ç–∏—Ü, –≤—Ä–µ–º–µ–Ω
2. **–õ–µ–∫—Å–∏–∫–∞** (25%) - –±–æ–≥–∞—Ç—Å—Ç–≤–æ —Å–ª–æ–≤–∞—Ä–Ω–æ–≥–æ –∑–∞–ø–∞—Å–∞, —É–º–µ—Å—Ç–Ω–æ—Å—Ç—å —Å–ª–æ–≤  
3. **–°—Ç—Ä—É–∫—Ç—É—Ä–∞** (20%) - –ª–æ–≥–∏—á–Ω–æ—Å—Ç—å, –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏—è, —Å–≤—è–∑–Ω–æ—Å—Ç—å
4. **–°–æ–¥–µ—Ä–∂–∞–Ω–∏–µ** (15%) - —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ —Ç–µ–º–µ, –∞—Ä–≥—É–º–µ–Ω—Ç–∞—Ü–∏—è
5. **–°—Ç–∏–ª—å** (10%) - —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–∏–µ, –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω–æ—Å—Ç—å, —Å–ª–æ–∂–Ω–æ—Å—Ç—å

# –§–û–†–ú–ê–¢ –û–¢–í–ï–¢–ê JSON:
{{
    "overall_score": 85,
    "categories": [
        {{"name": "–ì—Ä–∞–º–º–∞—Ç–∏–∫–∞", "score": 80, "feedback": "..."}},
        {{"name": "–õ–µ–∫—Å–∏–∫–∞", "score": 85, "feedback": "..."}},
        {{"name": "–°—Ç—Ä—É–∫—Ç—É—Ä–∞", "score": 90, "feedback": "..."}},
        {{"name": "–°–æ–¥–µ—Ä–∂–∞–Ω–∏–µ", "score": 75, "feedback": "..."}},
        {{"name": "–°—Ç–∏–ª—å", "score": 80, "feedback": "..."}}
    ],
    "errors": [
        {{"position": 15, "error": "‰∫Ü –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω –Ω–µ –∫ –º–µ—Å—Ç—É", "correction": "..."}},
        {{"position": 42, "error": "–ù–µ–ø—Ä–∞–≤–∏–ª—å–Ω—ã–π –ø–æ—Ä—è–¥–æ–∫ —Å–ª–æ–≤", "correction": "..."}}
    ],
    "recommendations": "–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ —É–ª—É—á—à–µ–Ω–∏—é...",
    "strengths": "–°–∏–ª—å–Ω—ã–µ —Å—Ç–æ—Ä–æ–Ω—ã —Ä–∞–±–æ—Ç—ã...",
    "estimated_hsk_level": {request.hsk_level}
}}

# –ë–£–î–¨ –°–¢–†–û–ì–ò–ú:
- –ù–µ –∑–∞–≤—ã—à–∞–π –æ—Ü–µ–Ω–∫–∏
- –£–∫–∞–∑—ã–≤–∞–π –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ –æ—à–∏–±–∫–∏
- –î–∞–≤–∞–π –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è
- –ë—É–¥—å –∫–æ–Ω—Å—Ç—Ä—É–∫—Ç–∏–≤–Ω—ã–º, –Ω–æ —á–µ—Å—Ç–Ω—ã–º

# –≠–°–°–ï –°–¢–£–î–ï–ù–¢–ê:
{request.essay_text}"""

        messages = [
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": "–ü—Ä–æ–≤–µ—Ä—å —ç—Ç–æ —ç—Å—Å–µ –∏ –¥–∞–π –¥–µ—Ç–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑."}
        ]
        
        response = client.chat.completions.create(
            model="deepseek-chat",
            messages=messages,
            temperature=0.3,
            max_tokens=2000
        )
        
        # –ü–∞—Ä—Å–∏–º JSON –æ—Ç–≤–µ—Ç
        try:
            result = json.loads(response.choices[0].message.content)
        except json.JSONDecodeError:
            # –ï—Å–ª–∏ AI –Ω–µ –≤–µ—Ä–Ω—É–ª JSON, —Å–æ–∑–¥–∞–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –æ—Ç–≤–µ—Ç
            result = {
                "overall_score": 75,
                "categories": [
                    {"name": "–ì—Ä–∞–º–º–∞—Ç–∏–∫–∞", "score": 70, "feedback": "–ü—Ä–æ–≤–µ—Ä—å—Ç–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ —á–∞—Å—Ç–∏—Ü"},
                    {"name": "–õ–µ–∫—Å–∏–∫–∞", "score": 80, "feedback": "–•–æ—Ä–æ—à–∏–π —Å–ª–æ–≤–∞—Ä–Ω—ã–π –∑–∞–ø–∞—Å"},
                    {"name": "–°—Ç—Ä—É–∫—Ç—É—Ä–∞", "score": 85, "feedback": "–õ–æ–≥–∏—á–Ω–∞—è –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏—è"},
                    {"name": "–°–æ–¥–µ—Ä–∂–∞–Ω–∏–µ", "score": 75, "feedback": "–°–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç —Ç–µ–º–µ"},
                    {"name": "–°—Ç–∏–ª—å", "score": 70, "feedback": "–ú–æ–∂–Ω–æ —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–∏—Ç—å —Å—Ç–∏–ª—å"}
                ],
                "errors": [],
                "recommendations": "–ü—Ä–æ–¥–æ–ª–∂–∞–π—Ç–µ –ø—Ä–∞–∫—Ç–∏–∫–æ–≤–∞—Ç—å—Å—è –≤ –Ω–∞–ø–∏—Å–∞–Ω–∏–∏ —ç—Å—Å–µ",
                "strengths": "–≠—Å—Å–µ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç –∑–∞–¥–∞–Ω–Ω–æ–π —Ç–µ–º–µ –∏ –∏–º–µ–µ—Ç –ª–æ–≥–∏—á–Ω—É—é —Å—Ç—Ä—É–∫—Ç—É—Ä—É"
            }
        
        # –î–æ–±–∞–≤–ª—è–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
        result.update({
            "topic": request.topic,
            "target_hsk": request.hsk_level,
            "actual_length": len(request.essay_text),
            "min_required": request.min_length,
            "checked_at": datetime.now().isoformat(),
            "ai_checked": True
        })
        
        return result
        
    except Exception as e:
        print(f"–û—à–∏–±–∫–∞ –ø—Ä–æ–≤–µ—Ä–∫–∏ —ç—Å—Å–µ: {str(e)}")
        return generate_fallback_essay_check(request)

def generate_fallback_essay_check(request: EssayCheckRequest):
    """Fallback –ø—Ä–æ–≤–µ—Ä–∫–∞ —ç—Å—Å–µ (–µ—Å–ª–∏ AI –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω)"""
    text = request.essay_text
    char_count = len(text)
    
    # –ü—Ä–æ—Å—Ç–∞—è –æ—Ü–µ–Ω–∫–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ –¥–ª–∏–Ω—ã
    if char_count < request.min_length:
        length_score = 50
    elif char_count < request.min_length * 1.5:
        length_score = 70
    else:
        length_score = 90
    
    base_score = length_score
    
    # –î–æ–±–∞–≤–ª—è–µ–º —Å–ª—É—á–∞–π–Ω—ã–µ –≤–∞—Ä–∏–∞—Ü–∏–∏
    grammar_score = max(0, min(100, base_score + random.randint(-15, 15)))
    vocab_score = max(0, min(100, base_score + random.randint(-10, 10)))
    structure_score = max(0, min(100, base_score + random.randint(-5, 15)))
    content_score = max(0, min(100, base_score + random.randint(-5, 10)))
    style_score = max(0, min(100, base_score + random.randint(-10, 5)))
    
    overall_score = int((grammar_score + vocab_score + structure_score + content_score + style_score) / 5)
    
    # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –ø—Ä–∏–º–µ—Ä–Ω—ã–µ –æ—à–∏–±–∫–∏
    errors = []
    if char_count > 100:
        # –î–æ–±–∞–≤–ª—è–µ–º –ø–∞—Ä—É –ø—Ä–∏–º–µ—Ä–Ω—ã—Ö –æ—à–∏–±–æ–∫
        errors.append({
            "position": min(50, char_count - 10),
            "error": "–í–æ–∑–º–æ–∂–Ω–∞—è –æ—à–∏–±–∫–∞ –≤ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–∏ ‰∫Ü",
            "correction": "–£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ ‰∫Ü –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –¥–ª—è –∑–∞–≤–µ—Ä—à–µ–Ω–Ω—ã—Ö –¥–µ–π—Å—Ç–≤–∏–π"
        })
    
    return {
        "overall_score": overall_score,
        "categories": [
            {"name": "–ì—Ä–∞–º–º–∞—Ç–∏–∫–∞", "score": grammar_score, 
             "feedback": "–ï—Å—Ç—å –æ—à–∏–±–∫–∏ –≤ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–∏ —á–∞—Å—Ç–∏—Ü. –û–±—Ä–∞—Ç–∏—Ç–µ –≤–Ω–∏–º–∞–Ω–∏–µ –Ω–∞ ‰∫Ü, ÁöÑ, Âú∞, Âæó."},
            {"name": "–õ–µ–∫—Å–∏–∫–∞", "score": vocab_score,
             "feedback": f"–î–æ—Å—Ç–∞—Ç–æ—á–Ω–æ —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–Ω—ã–π —Å–ª–æ–≤–∞—Ä–Ω—ã–π –∑–∞–ø–∞—Å –¥–ª—è —É—Ä–æ–≤–Ω—è HSK {request.hsk_level}."},
            {"name": "–°—Ç—Ä—É–∫—Ç—É—Ä–∞", "score": structure_score,
             "feedback": "–õ–æ–≥–∏—á–Ω–∞—è –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏—è —Ç–µ–∫—Å—Ç–∞, –Ω–æ –º–æ–∂–Ω–æ —É–ª—É—á—à–∏—Ç—å —Å–≤—è–∑–Ω–æ—Å—Ç—å –º–µ–∂–¥—É –∞–±–∑–∞—Ü–∞–º–∏."},
            {"name": "–°–æ–¥–µ—Ä–∂–∞–Ω–∏–µ", "score": content_score,
             "feedback": f"–°–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç —Ç–µ–º–µ '{request.topic}', –µ—Å—Ç—å –∞—Ä–≥—É–º–µ–Ω—Ç—ã –∏ –ø—Ä–∏–º–µ—Ä—ã."},
            {"name": "–°—Ç–∏–ª—å", "score": style_score,
             "feedback": "–°—Ç–∏–ª—å –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–Ω—ã–π, –Ω–æ –º–æ–∂–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –±–æ–ª–µ–µ —Å–ª–æ–∂–Ω—ã–µ –∫–æ–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏."}
        ],
        "errors": errors,
        "recommendations": f"""
1. –ü—Ä–∞–∫—Ç–∏–∫—É–π—Ç–µ—Å—å –≤ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–∏ —Å–ª–æ–∂–Ω—ã—Ö –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π —Å ËôΩÁÑ∂...‰ΩÜÊòØ..., Âõ†‰∏∫...ÊâÄ‰ª•...
2. –£–≤–µ–ª–∏—á—å—Ç–µ —Å–ª–æ–≤–∞—Ä–Ω—ã–π –∑–∞–ø–∞—Å –ø–æ —Ç–µ–º–µ "{request.topic}"
3. –û–±—Ä–∞—Ç–∏—Ç–µ –≤–Ω–∏–º–∞–Ω–∏–µ –Ω–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ —á–∞—Å—Ç–∏—Ü ‰∫Ü, ÁöÑ, Âú∞, Âæó
4. –î–æ–±–∞–≤—å—Ç–µ –≤–≤–æ–¥–Ω—ã–µ —Å–ª–æ–≤–∞: È¶ñÂÖà, ÂÖ∂Ê¨°, ÊúÄÂêé, ÊÄªËÄåË®Ä‰πã
5. –ü–∏—à–∏—Ç–µ —Ä–µ–≥—É–ª—è—Ä–Ω–æ –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è –Ω–∞–≤—ã–∫–æ–≤
        """,
        "strengths": "–•–æ—Ä–æ—à–∞—è –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏—è —Ç–µ–∫—Å—Ç–∞, —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ —Ç–µ–º–µ, –¥–æ—Å—Ç–∞—Ç–æ—á–Ω—ã–π –æ–±—ä–µ–º.",
        "estimated_hsk_level": request.hsk_level,
        "topic": request.topic,
        "target_hsk": request.hsk_level,
        "actual_length": char_count,
        "min_required": request.min_length,
        "checked_at": datetime.now().isoformat(),
        "ai_checked": False,
        "fallback": True
    }

def generate_fallback_essay_check(request: EssayCheckRequest):
    """Fallback –ø—Ä–æ–≤–µ—Ä–∫–∞ —ç—Å—Å–µ"""
    # –ü—Ä–æ—Å—Ç–æ–π –∞–Ω–∞–ª–∏–∑ —ç—Å—Å–µ
    text = request.essay_text
    char_count = len(text)
    
    # –ü—Ä–æ—Å—Ç–∞—è –æ—Ü–µ–Ω–∫–∞
    base_score = min(100, max(50, char_count / request.min_length * 80))
    
    # –°–ª—É—á–∞–π–Ω—ã–µ –≤–∞—Ä–∏–∞—Ü–∏–∏
    grammar_score = max(0, min(100, base_score + random.randint(-15, 15)))
    vocab_score = max(0, min(100, base_score + random.randint(-10, 10)))
    structure_score = max(0, min(100, base_score + random.randint(-5, 15)))
    content_score = max(0, min(100, base_score + random.randint(-5, 10)))
    style_score = max(0, min(100, base_score + random.randint(-10, 5)))
    
    overall_score = int((grammar_score + vocab_score + structure_score + content_score + style_score) / 5)
    
    return {
        "overall_score": overall_score,
        "categories": [
            {"name": "–ì—Ä–∞–º–º–∞—Ç–∏–∫–∞", "score": grammar_score, 
             "feedback": "–ï—Å—Ç—å –æ—à–∏–±–∫–∏ –≤ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–∏ —á–∞—Å—Ç–∏—Ü. –û–±—Ä–∞—Ç–∏—Ç–µ –≤–Ω–∏–º–∞–Ω–∏–µ –Ω–∞ ‰∫Ü, ÁöÑ, Âú∞, Âæó."},
            {"name": "–õ–µ–∫—Å–∏–∫–∞", "score": vocab_score,
             "feedback": "–î–æ—Å—Ç–∞—Ç–æ—á–Ω–æ —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–Ω—ã–π —Å–ª–æ–≤–∞—Ä–Ω—ã–π –∑–∞–ø–∞—Å –¥–ª—è —É—Ä–æ–≤–Ω—è HSK " + str(request.hsk_level)},
            {"name": "–°—Ç—Ä—É–∫—Ç—É—Ä–∞", "score": structure_score,
             "feedback": "–õ–æ–≥–∏—á–Ω–∞—è –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏—è —Ç–µ–∫—Å—Ç–∞, –Ω–æ –º–æ–∂–Ω–æ —É–ª—É—á—à–∏—Ç—å —Å–≤—è–∑–Ω–æ—Å—Ç—å –º–µ–∂–¥—É –∞–±–∑–∞—Ü–∞–º–∏."},
            {"name": "–°–æ–¥–µ—Ä–∂–∞–Ω–∏–µ", "score": content_score,
             "feedback": "–°–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç —Ç–µ–º–µ, –µ—Å—Ç—å –∞—Ä–≥—É–º–µ–Ω—Ç—ã –∏ –ø—Ä–∏–º–µ—Ä—ã."},
            {"name": "–°—Ç–∏–ª—å", "score": style_score,
             "feedback": "–°—Ç–∏–ª—å –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–Ω—ã–π, –Ω–æ –º–æ–∂–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –±–æ–ª–µ–µ —Å–ª–æ–∂–Ω—ã–µ –∫–æ–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏."}
        ],
        "errors": [
            {"position": random.randint(10, len(text)//2), 
             "error": "–í–æ–∑–º–æ–∂–Ω–∞—è –æ—à–∏–±–∫–∞ –≤ –ø–æ—Ä—è–¥–∫–µ —Å–ª–æ–≤",
             "correction": "–ü—Ä–æ–≤–µ—Ä—å—Ç–µ –ø–æ—Ä—è–¥–æ–∫ —Å–ª–æ–≤ –≤ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–∏"},
            {"position": random.randint(len(text)//2, len(text)-10),
             "error": "–ü–æ–≤—Ç–æ—Ä –æ–¥–Ω–∏—Ö –∏ —Ç–µ—Ö –∂–µ —Å–ª–æ–≤",
             "correction": "–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ —Å–∏–Ω–æ–Ω–∏–º—ã –¥–ª—è —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–∏—è"}
        ] if char_count > 50 else [],
        "recommendations": """
        1. –ü—Ä–∞–∫—Ç–∏–∫—É–π—Ç–µ—Å—å –≤ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–∏ —Å–ª–æ–∂–Ω—ã—Ö –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π —Å ËôΩÁÑ∂...‰ΩÜÊòØ..., Âõ†‰∏∫...ÊâÄ‰ª•...
        2. –£–≤–µ–ª–∏—á—å—Ç–µ —Å–ª–æ–≤–∞—Ä–Ω—ã–π –∑–∞–ø–∞—Å –ø–æ —Ç–µ–º–µ "{}"
        3. –û–±—Ä–∞—Ç–∏—Ç–µ –≤–Ω–∏–º–∞–Ω–∏–µ –Ω–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ —á–∞—Å—Ç–∏—Ü ‰∫Ü, ÁöÑ, Âú∞, Âæó
        4. –î–æ–±–∞–≤—å—Ç–µ –≤–≤–æ–¥–Ω—ã–µ —Å–ª–æ–≤–∞: È¶ñÂÖà, ÂÖ∂Ê¨°, ÊúÄÂêé, ÊÄªËÄåË®Ä‰πã
        5. –ü–∏—à–∏—Ç–µ —Ä–µ–≥—É–ª—è—Ä–Ω–æ –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è –Ω–∞–≤—ã–∫–æ–≤
        """.format(request.topic),
        "strengths": "–•–æ—Ä–æ—à–∞—è –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏—è —Ç–µ–∫—Å—Ç–∞, —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ —Ç–µ–º–µ, –¥–æ—Å—Ç–∞—Ç–æ—á–Ω—ã–π –æ–±—ä–µ–º.",
        "estimated_hsk_level": request.hsk_level,
        "topic": request.topic,
        "target_hsk": request.hsk_level,
        "actual_length": char_count,
        "checked_at": datetime.now().isoformat(),
        "ai_checked": False,
        "fallback": True
    }

@app.post("/translation/generate")
async def generate_translation_text(request: TranslationGenerateRequest):
    """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ç–µ–∫—Å—Ç–∞ –¥–ª—è –ø–µ—Ä–µ–≤–æ–¥–∞"""
    try:
        client = get_deepseek_client()
        if not client:
            return generate_fallback_translation_text(request)
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –¥–ª–∏–Ω—É
        lengths = {
            "short": "3-5 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π",
            "medium": "6-10 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π", 
            "long": "10-15 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π"
        }
        
        system_prompt = f"""–¢—ã —Å–æ–∑–¥–∞–µ—à—å —Ç–µ–∫—Å—Ç—ã –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ –¥–ª—è –ø–µ—Ä–µ–≤–æ–¥–∞ –Ω–∞ –∫–∏—Ç–∞–π—Å–∫–∏–π.
        
# –ó–ê–î–ê–ß–ê:
–°–æ–∑–¥–∞—Ç—å —Ç–µ–∫—Å—Ç –Ω–∞ —Ç–µ–º—É: "{request.topic}"
–°–ª–æ–∂–Ω–æ—Å—Ç—å: {request.difficulty}
–î–ª–∏–Ω–∞: {lengths.get(request.length, "6-10 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π")}
–£—Ä–æ–≤–µ–Ω—å —Å—Ç—É–¥–µ–Ω—Ç–∞: HSK {request.hsk_level}

# –¢–†–ï–ë–û–í–ê–ù–ò–Ø:
1. –¢–µ–∫—Å—Ç –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –∏–Ω—Ç–µ—Ä–µ—Å–Ω—ã–º –∏ –ø–æ–ª–µ–∑–Ω—ã–º –¥–ª—è –∏–∑—É—á–µ–Ω–∏—è
2. –£—Ä–æ–≤–µ–Ω—å —Å–ª–æ–∂–Ω–æ—Å—Ç–∏ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–æ–≤–∞—Ç—å —É—Ä–æ–≤–Ω—é —Å—Ç—É–¥–µ–Ω—Ç–∞
3. –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–Ω—É—é –ª–µ–∫—Å–∏–∫—É –∏ –≥—Ä–∞–º–º–∞—Ç–∏–∫—É
4. –¢–µ–∫—Å—Ç –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω—ã–º, –∫–∞–∫ –≤ —Ä–µ–∞–ª—å–Ω–æ–π –∂–∏–∑–Ω–∏
5. –í–∫–ª—é—á–∞—Ç—å —ç–ª–µ–º–µ–Ω—Ç—ã, –∫–æ—Ç–æ—Ä—ã–µ –Ω—É–∂–Ω–æ –ø–µ—Ä–µ–≤–µ—Å—Ç–∏ –ø—Ä–∞–≤–∏–ª—å–Ω–æ

# –§–û–†–ú–ê–¢–´ –¢–ï–ö–°–¢–ê:
- –ù–æ–≤–æ—Å—Ç—å: —Ñ–æ—Ä–º–∞–ª—å–Ω—ã–π —Å—Ç–∏–ª—å, —Ñ–∞–∫—Ç—ã
- –†–∞—Å—Å–∫–∞–∑: –ø–æ–≤–µ—Å—Ç–≤–æ–≤–∞–Ω–∏–µ, –¥–∏–∞–ª–æ–≥–∏
- –î–∏–∞–ª–æ–≥: —Ä–∞–∑–≥–æ–≤–æ—Ä–Ω–∞—è —Ä–µ—á—å, –≤–æ–ø—Ä–æ—Å—ã –∏ –æ—Ç–≤–µ—Ç—ã
- –û–ø–∏—Å–∞–Ω–∏–µ: –¥–µ—Ç–∞–ª–∏, –ø—Ä–∏–ª–∞–≥–∞—Ç–µ–ª—å–Ω—ã–µ
- –ò–Ω—Å—Ç—Ä—É–∫—Ü–∏—è: –∏–º–ø–µ—Ä–∞—Ç–∏–≤—ã, –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å

# –ü–†–ò–ú–ï–† –î–õ–Ø –°–†–ï–î–ù–ï–ô –°–õ–û–ñ–ù–û–°–¢–ò:
"–í—á–µ—Ä–∞ –≤ –®–∞–Ω—Ö–∞–µ –æ—Ç–∫—Ä—ã–ª—Å—è –Ω–æ–≤—ã–π –∫—É–ª—å—Ç—É—Ä–Ω—ã–π —Ü–µ–Ω—Ç—Ä. –û–Ω –æ–±—ä–µ–¥–∏–Ω—è–µ—Ç –±–∏–±–ª–∏–æ—Ç–µ–∫—É, –º—É–∑–µ–π –∏ –∫–æ–Ω—Ü–µ—Ä—Ç–Ω—ã–π –∑–∞–ª. –ü–æ—Å–µ—Ç–∏—Ç–µ–ª–∏ –º–æ–≥—É—Ç –±–µ—Å–ø–ª–∞—Ç–Ω–æ –ø–æ—Å–µ—â–∞—Ç—å –≤—ã—Å—Ç–∞–≤–∫–∏ –≤ –ø–µ—Ä–≤—ã–π –º–µ—Å—è—Ü."""

        messages = [
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": f"–°–æ–∑–¥–∞–π —Ç–µ–∫—Å—Ç –¥–ª—è –ø–µ—Ä–µ–≤–æ–¥–∞ –Ω–∞ —Ç–µ–º—É: {request.topic}"}
        ]
        
        response = client.chat.completions.create(
            model="deepseek-chat",
            messages=messages,
            temperature=0.7,
            max_tokens=800
        )
        
        text = response.choices[0].message.content
        
        return {
            "text": text.strip(),
            "topic": request.topic,
            "difficulty": request.difficulty,
            "length": request.length,
            "target_hsk": request.hsk_level,
            "generated_at": datetime.now().isoformat(),
            "ai_generated": True
        }
        
    except Exception as e:
        print(f"–û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Ç–µ–∫—Å—Ç–∞: {str(e)}")
        return generate_fallback_translation_text(request)

def generate_fallback_translation_text(request: TranslationGenerateRequest):
    """Fallback –≥–µ–Ω–µ—Ä–∞—Ü–∏—è —Ç–µ–∫—Å—Ç–∞ –¥–ª—è –ø–µ—Ä–µ–≤–æ–¥–∞"""
    topics_texts = {
        "news": "–ö–∏—Ç–∞–π –∑–∞–ø—É—Å—Ç–∏–ª –Ω–æ–≤—ã–π —Å–ø—É—Ç–Ω–∏–∫ –¥–ª—è –Ω–∞–±–ª—é–¥–µ–Ω–∏—è –∑–∞ –ó–µ–º–ª–µ–π. –û–Ω –±—É–¥–µ—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å—Å—è –¥–ª—è –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞ –ø–æ–≥–æ–¥—ã –∏ —ç–∫–æ–ª–æ–≥–∏–∏. –°–ø—É—Ç–Ω–∏–∫ –≤—ã–≤–µ–¥–µ–Ω –Ω–∞ –æ—Ä–±–∏—Ç—É —Ä–∞–∫–µ—Ç–æ–π-–Ω–æ—Å–∏—Ç–µ–ª–µ–º –ß–∞–Ω—á–∂—ç–Ω.",
        "story": "–î–∞–≤–Ω—ã–º-–¥–∞–≤–Ω–æ –≤ –º–∞–ª–µ–Ω—å–∫–æ–π –¥–µ—Ä–µ–≤–Ω–µ –∂–∏–ª —Å—Ç–∞—Ä—ã–π –º–∞—Å—Ç–µ—Ä –∫–∞–ª–ª–∏–≥—Ä–∞—Ñ–∏–∏. –ö–∞–∂–¥–æ–µ —É—Ç—Ä–æ –æ–Ω –≤—Å—Ç–∞–≤–∞–ª –Ω–∞ —Ä–∞—Å—Å–≤–µ—Ç–µ –∏ –ø—Ä–∞–∫—Ç–∏–∫–æ–≤–∞–ª –∏–µ—Ä–æ–≥–ª–∏—Ñ—ã. –ï–≥–æ —Ä–∞–±–æ—Ç—ã –±—ã–ª–∏ –∏–∑–≤–µ—Å—Ç–Ω—ã –ø–æ –≤—Å–µ–º—É —Ä–µ–≥–∏–æ–Ω—É.",
        "dialogue": "- –ó–¥—Ä–∞–≤—Å—Ç–≤—É–π—Ç–µ! –ú–µ–Ω—è –∑–æ–≤—É—Ç –ê–Ω–Ω–∞. –Ø –∏–∑ –†–æ—Å—Å–∏–∏. - –û—á–µ–Ω—å –ø—Ä–∏—è—Ç–Ω–æ! –Ø –õ–∏ –í—ç–π. –í—ã –≤–ø–µ—Ä–≤—ã–µ –≤ –ö–∏—Ç–∞–µ? - –î–∞, —è –∑–¥–µ—Å—å –∏–∑—É—á–∞—é –∫–∏—Ç–∞–π—Å–∫–∏–π —è–∑—ã–∫. - –û—Ç–ª–∏—á–Ω–æ! –£–¥–∞—á–∏ –≤ —É—á–µ–±–µ!",
        "description": "–í–µ–ª–∏–∫–∞—è –ö–∏—Ç–∞–π—Å–∫–∞—è —Å—Ç–µ–Ω–∞ - —ç—Ç–æ –¥—Ä–µ–≤–Ω–µ–µ –æ–±–æ—Ä–æ–Ω–∏—Ç–µ–ª—å–Ω–æ–µ —Å–æ–æ—Ä—É–∂–µ–Ω–∏–µ. –û–Ω–∞ –ø—Ä–æ—Ö–æ–¥–∏—Ç —á–µ—Ä–µ–∑ –≥–æ—Ä—ã –∏ –¥–æ–ª–∏–Ω—ã —Å–µ–≤–µ—Ä–Ω–æ–≥–æ –ö–∏—Ç–∞—è. –î–ª–∏–Ω–∞ —Å—Ç–µ–Ω—ã —Å–æ—Å—Ç–∞–≤–ª—è–µ—Ç –±–æ–ª–µ–µ 20 —Ç—ã—Å—è—á –∫–∏–ª–æ–º–µ—Ç—Ä–æ–≤.",
        "instruction": "–ß—Ç–æ–±—ã –ø—Ä–∏–≥–æ—Ç–æ–≤–∏—Ç—å –∂–∞—Ä–µ–Ω—ã–π —Ä–∏—Å –ø–æ-–∫–∏—Ç–∞–π—Å–∫–∏, —Å–Ω–∞—á–∞–ª–∞ –Ω—É–∂–Ω–æ –æ—Ç–≤–∞—Ä–∏—Ç—å —Ä–∏—Å –∏ –æ—Ö–ª–∞–¥–∏—Ç—å –µ–≥–æ. –ó–∞—Ç–µ–º –æ–±–∂–∞—Ä–∏—Ç—å —è–π—Ü–∞, –¥–æ–±–∞–≤–∏—Ç—å –æ–≤–æ—â–∏ –∏ –Ω–∞—Ä–µ–∑–∞–Ω–Ω–æ–µ –º—è—Å–æ. –í –∫–æ–Ω—Ü–µ –¥–æ–±–∞–≤–∏—Ç—å —Ä–∏—Å –∏ —Å–æ–µ–≤—ã–π —Å–æ—É—Å."
    }
    
    # –í—ã–±–∏—Ä–∞–µ–º —Ç–µ–∫—Å—Ç –ø–æ —Ç–µ–º–µ –∏–ª–∏ –∏—Å–ø–æ–ª—å–∑—É–µ–º –æ–±—â–∏–π
    text = topics_texts.get(request.topic, 
        "–ö–∏—Ç–∞–π—Å–∫–∞—è –∫—É–ª—å—Ç—É—Ä–∞ –æ—á–µ–Ω—å –±–æ–≥–∞—Ç–∞ –∏ —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–Ω–∞. –û–Ω–∞ –≤–∫–ª—é—á–∞–µ—Ç –≤ —Å–µ–±—è —Ç—Ä–∞–¥–∏—Ü–∏–æ–Ω–Ω—É—é –º–µ–¥–∏—Ü–∏–Ω—É, –∫—É—Ö–Ω—é, –∏—Å–∫—É—Å—Å—Ç–≤–æ –∏ —Ñ–∏–ª–æ—Å–æ—Ñ–∏—é. –ò–∑—É—á–µ–Ω–∏–µ –∫–∏—Ç–∞–π—Å–∫–æ–π –∫—É–ª—å—Ç—É—Ä—ã –ø–æ–º–æ–≥–∞–µ—Ç –ª—É—á—à–µ –ø–æ–Ω–∏–º–∞—Ç—å —è–∑—ã–∫.")
    
    # –ê–¥–∞–ø—Ç–∏—Ä—É–µ–º —Å–ª–æ–∂–Ω–æ—Å—Ç—å
    if request.difficulty == "easy":
        # –£–ø—Ä–æ—â–∞–µ–º —Ç–µ–∫—Å—Ç
        sentences = text.split('. ')
        text = '. '.join(sentences[:2]) + '.'
    elif request.difficulty == "hard":
        # –£—Å–ª–æ–∂–Ω—è–µ–º —Ç–µ–∫—Å—Ç
        text += " –≠—Ç–∏ –∞—Å–ø–µ–∫—Ç—ã —Ç–µ—Å–Ω–æ —Å–≤—è–∑–∞–Ω—ã —Å –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏–º —Ä–∞–∑–≤–∏—Ç–∏–µ–º —Å—Ç—Ä–∞–Ω—ã –∏ –≤–ª–∏—è–Ω–∏–µ–º –∫–æ–Ω—Ñ—É—Ü–∏–∞–Ω—Å—Ç–≤–∞."
    
    return {
        "text": text,
        "topic": request.topic,
        "difficulty": request.difficulty,
        "length": request.length,
        "target_hsk": request.hsk_level,
        "generated_at": datetime.now().isoformat(),
        "ai_generated": False,
        "fallback": True
    }

@app.post("/translation/check")
async def check_translation(request: TranslationCheckRequest):
    """–ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–µ—Ä–µ–≤–æ–¥–∞ AI"""
    try:
        client = get_deepseek_client()
        if not client:
            return generate_fallback_translation_check(request)
        
        system_prompt = f"""–¢—ã ‚Äî —ç–∫—Å–ø–µ—Ä—Ç –ø–æ –ø–µ—Ä–µ–≤–æ–¥—É —Å —Ä—É—Å—Å–∫–æ–≥–æ –Ω–∞ –∫–∏—Ç–∞–π—Å–∫–∏–π.
        
# –ó–ê–î–ê–ß–ê:
–°—Ä–∞–≤–Ω–∏—Ç—å –ø–µ—Ä–µ–≤–æ–¥ —Å—Ç—É–¥–µ–Ω—Ç–∞ —Å –∏–¥–µ–∞–ª—å–Ω—ã–º –ø–µ—Ä–µ–≤–æ–¥–æ–º.
–û—Ä–∏–≥–∏–Ω–∞–ª (—Ä—É—Å—Å–∫–∏–π): "{request.original_text}"
–ü–µ—Ä–µ–≤–æ–¥ —Å—Ç—É–¥–µ–Ω—Ç–∞: "{request.user_translation}"
–£—Ä–æ–≤–µ–Ω—å —Å—Ç—É–¥–µ–Ω—Ç–∞: HSK {request.target_hsk}
–°–ª–æ–∂–Ω–æ—Å—Ç—å: {request.difficulty}

# –ö–†–ò–¢–ï–†–ò–ò –û–¶–ï–ù–ö–ò:
1. **–¢–æ—á–Ω–æ—Å—Ç—å** (40%) - –ø—Ä–∞–≤–∏–ª—å–Ω–æ—Å—Ç—å –ø–µ—Ä–µ–≤–æ–¥–∞ —Å–º—ã—Å–ª–∞
2. **–ì—Ä–∞–º–º–∞—Ç–∏–∫–∞** (30%) - –ø—Ä–∞–≤–∏–ª—å–Ω–æ—Å—Ç—å –∫–∏—Ç–∞–π—Å–∫–∏—Ö –∫–æ–Ω—Å—Ç—Ä—É–∫—Ü–∏–π
3. **–ï—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω–æ—Å—Ç—å** (20%) - –∑–≤—É—á–∏—Ç –ª–∏ –∫–∞–∫ —Ä–æ–¥–Ω–æ–π —è–∑—ã–∫
4. **–°—Ç–∏–ª—å** (10%) - —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Å—Ç–∏–ª—è –æ—Ä–∏–≥–∏–Ω–∞–ª–∞

# –¢–í–û–Ø –†–ê–ë–û–¢–ê:
1. –°–æ–∑–¥–∞—Ç—å –∏–¥–µ–∞–ª—å–Ω—ã–π –ø–µ—Ä–µ–≤–æ–¥ –æ—Ä–∏–≥–∏–Ω–∞–ª–∞
2. –°—Ä–∞–≤–Ω–∏—Ç—å —Å –ø–µ—Ä–µ–≤–æ–¥–æ–º —Å—Ç—É–¥–µ–Ω—Ç–∞
3. –ù–∞–π—Ç–∏ –∏ –∫–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞—Ç—å –æ—à–∏–±–∫–∏
4. –î–∞—Ç—å —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ —É–ª—É—á—à–µ–Ω–∏—é
5. –ü–æ—Å—Ç–∞–≤–∏—Ç—å –æ—Ü–µ–Ω–∫—É

# –§–û–†–ú–ê–¢ –û–¢–í–ï–¢–ê JSON:
{{
    "overall_score": 85,
    "ideal_translation": "–ò–¥–µ–∞–ª—å–Ω—ã–π –ø–µ—Ä–µ–≤–æ–¥ —Ç–µ–∫—Å—Ç–∞ –Ω–∞ –∫–∏—Ç–∞–π—Å–∫–∏–π...",
    "categories": [
        {{"name": "–¢–æ—á–Ω–æ—Å—Ç—å", "score": 90, "feedback": "..."}},
        {{"name": "–ì—Ä–∞–º–º–∞—Ç–∏–∫–∞", "score": 80, "feedback": "..."}},
        {{"name": "–ï—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω–æ—Å—Ç—å", "score": 85, "feedback": "..."}},
        {{"name": "–°—Ç–∏–ª—å", "score": 80, "feedback": "..."}}
    ],
    "errors": [
        {{"type": "grammar", "description": "–ù–µ–ø—Ä–∞–≤–∏–ª—å–Ω—ã–π –ø–æ—Ä—è–¥–æ–∫ —Å–ª–æ–≤", "suggestion": "..."}},
        {{"type": "vocabulary", "description": "–ù–µ—Ç–æ—á–Ω—ã–π –ø–µ—Ä–µ–≤–æ–¥ —Å–ª–æ–≤–∞", "suggestion": "..."}}
    ],
    "correct_translations": [
        {{"original": "—Ä—É—Å—Å–∫–∞—è —Ñ—Ä–∞–∑–∞", "student": "–ø–µ—Ä–µ–≤–æ–¥ —Å—Ç—É–¥–µ–Ω—Ç–∞", "ideal": "–∏–¥–µ–∞–ª—å–Ω—ã–π –ø–µ—Ä–µ–≤–æ–¥"}}
    ],
    "recommendations": "–ö–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏...",
    "estimated_hsk_level": {request.target_hsk}
}}

# –ë–£–î–¨ –ö–û–ù–°–¢–†–£–ö–¢–ò–í–ù–´–ú:
- –•–≤–∞–ª–∏ –∑–∞ —Ö–æ—Ä–æ—à–∏–µ –º–æ–º–µ–Ω—Ç—ã
- –û–±—ä—è—Å–Ω—è–π –æ—à–∏–±–∫–∏ –ø–æ–¥—Ä–æ–±–Ω–æ
- –ü—Ä–µ–¥–ª–∞–≥–∞–π –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤—ã
- –ü–æ–º–æ–≥–∞–π —É—á–∏—Ç—å—Å—è –Ω–∞ –æ—à–∏–±–∫–∞—Ö"""

        messages = [
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": "–ü—Ä–æ–≤–µ—Ä—å —ç—Ç–æ—Ç –ø–µ—Ä–µ–≤–æ–¥ –∏ –¥–∞–π –¥–µ—Ç–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑."}
        ]
        
        response = client.chat.completions.create(
            model="deepseek-chat",
            messages=messages,
            temperature=0.3,
            max_tokens=2000,
            response_format={"type": "json_object"}
        )
        
        result = json.loads(response.choices[0].message.content)
        
        # –î–æ–±–∞–≤–ª—è–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
        result.update({
            "original_text": request.original_text,
            "user_translation": request.user_translation,
            "target_hsk": request.target_hsk,
            "difficulty": request.difficulty,
            "checked_at": datetime.now().isoformat(),
            "ai_checked": True
        })
        
        return result
        
    except Exception as e:
        print(f"–û—à–∏–±–∫–∞ –ø—Ä–æ–≤–µ—Ä–∫–∏ –ø–µ—Ä–µ–≤–æ–¥–∞: {str(e)}")
        return generate_fallback_translation_check(request)

def generate_fallback_translation_check(request: TranslationCheckRequest):
    """Fallback –ø—Ä–æ–≤–µ—Ä–∫–∞ –ø–µ—Ä–µ–≤–æ–¥–∞"""
    # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º "–∏–¥–µ–∞–ª—å–Ω—ã–π" –ø–µ—Ä–µ–≤–æ–¥ (–ø—Ä–æ—Å—Ç–æ–π)
    ideal_translation = generate_simple_translation(request.original_text, request.target_hsk)
    
    # –ü—Ä–æ—Å—Ç–∞—è –æ—Ü–µ–Ω–∫–∞
    base_score = 70 + random.randint(-15, 15)
    accuracy_score = max(0, min(100, base_score + random.randint(-10, 10)))
    grammar_score = max(0, min(100, base_score + random.randint(-15, 5)))
    naturalness_score = max(0, min(100, base_score + random.randint(-5, 10)))
    style_score = max(0, min(100, base_score + random.randint(-10, 5)))
    
    overall_score = int((accuracy_score + grammar_score + naturalness_score + style_score) / 4)
    
    return {
        "overall_score": overall_score,
        "ideal_translation": ideal_translation,
        "categories": [
            {"name": "–¢–æ—á–Ω–æ—Å—Ç—å", "score": accuracy_score,
             "feedback": "–û—Å–Ω–æ–≤–Ω–æ–π —Å–º—ã—Å–ª –ø–µ—Ä–µ–¥–∞–Ω –ø—Ä–∞–≤–∏–ª—å–Ω–æ, –Ω–æ –µ—Å—Ç—å –Ω–µ—Ç–æ—á–Ω–æ—Å—Ç–∏ –≤ –¥–µ—Ç–∞–ª—è—Ö."},
            {"name": "–ì—Ä–∞–º–º–∞—Ç–∏–∫–∞", "score": grammar_score,
             "feedback": "–ï—Å—Ç—å –æ—à–∏–±–∫–∏ –≤ –ø–æ—Ä—è–¥–∫–µ —Å–ª–æ–≤ –∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–∏ —á–∞—Å—Ç–∏—Ü."},
            {"name": "–ï—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω–æ—Å—Ç—å", "score": naturalness_score,
             "feedback": "–ü–µ—Ä–µ–≤–æ–¥ –ø–æ–Ω—è—Ç–µ–Ω, –Ω–æ –∑–≤—É—á–∏—Ç –Ω–µ–º–Ω–æ–≥–æ –Ω–µ–µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω–æ –¥–ª—è –Ω–æ—Å–∏—Ç–µ–ª—è."},
            {"name": "–°—Ç–∏–ª—å", "score": style_score,
             "feedback": "–°—Ç–∏–ª—å –≤ –æ—Å–Ω–æ–≤–Ω–æ–º —Å–æ—Ö—Ä–∞–Ω–µ–Ω, –Ω–æ –º–æ–∂–Ω–æ —É–ª—É—á—à–∏—Ç—å."}
        ],
        "errors": [
            {"type": "grammar", 
             "description": "–í–æ–∑–º–æ–∂–Ω—ã–µ –æ—à–∏–±–∫–∏ –≤ –ø–æ—Ä—è–¥–∫–µ —Å–ª–æ–≤",
             "suggestion": "–í –∫–∏—Ç–∞–π—Å–∫–æ–º —è–∑—ã–∫–µ –ø–æ—Ä—è–¥–æ–∫ SVO (–ø–æ–¥–ª–µ–∂–∞—â–µ–µ-—Å–∫–∞–∑—É–µ–º–æ–µ-–¥–æ–ø–æ–ª–Ω–µ–Ω–∏–µ)"},
            {"type": "vocabulary",
             "description": "–ú–æ–∂–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –±–æ–ª–µ–µ —Ç–æ—á–Ω—ã–µ —Å–ª–æ–≤–∞",
             "suggestion": "–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ —Å–∏–Ω–æ–Ω–∏–º—ã –¥–ª—è —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–∏—è –∏ —Ç–æ—á–Ω–æ—Å—Ç–∏"}
        ],
        "correct_translations": [
            {"original": request.original_text.split('. ')[0] if '. ' in request.original_text else request.original_text,
             "student": request.user_translation.split('„ÄÇ')[0] if '„ÄÇ' in request.user_translation else request.user_translation,
             "ideal": ideal_translation.split('„ÄÇ')[0] if '„ÄÇ' in ideal_translation else ideal_translation}
        ],
        "recommendations": """
        1. –û–±—Ä–∞—â–∞–π—Ç–µ –≤–Ω–∏–º–∞–Ω–∏–µ –Ω–∞ –ø–æ—Ä—è–¥–æ–∫ —Å–ª–æ–≤ –≤ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–∏
        2. –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ —Å–ª–æ–≤–∞—Ä–∏ –¥–ª—è –ø–æ–∏—Å–∫–∞ –±–æ–ª–µ–µ —Ç–æ—á–Ω—ã—Ö —ç–∫–≤–∏–≤–∞–ª–µ–Ω—Ç–æ–≤
        3. –ü—Ä–∞–∫—Ç–∏–∫—É–π—Ç–µ—Å—å –≤ –ø–µ—Ä–µ–≤–æ–¥–µ —Ä–∞–∑–Ω—ã—Ö —Ç–∏–ø–æ–≤ —Ç–µ–∫—Å—Ç–æ–≤
        4. –ß–∏—Ç–∞–π—Ç–µ –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–µ –∫–∏—Ç–∞–π—Å–∫–∏–µ —Ç–µ–∫—Å—Ç—ã –¥–ª—è –ø–æ–Ω–∏–º–∞–Ω–∏—è –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ —Å—Ç–∏–ª—è
        5. –ü—Ä–æ–≤–µ—Ä—è–π—Ç–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ —á–∞—Å—Ç–∏—Ü ‰∫Ü, ÁöÑ, Âú∞, Âæó
        """,
        "estimated_hsk_level": request.target_hsk,
        "original_text": request.original_text,
        "user_translation": request.user_translation,
        "target_hsk": request.target_hsk,
        "difficulty": request.difficulty,
        "checked_at": datetime.now().isoformat(),
        "ai_checked": False,
        "fallback": True
    }

def generate_simple_translation(text: str, hsk_level: int) -> str:
    """–ü—Ä–æ—Å—Ç–æ–π –ø–µ—Ä–µ–≤–æ–¥ —Ç–µ–∫—Å—Ç–∞ (–∑–∞–≥–ª—É—à–∫–∞)"""
    # –í —Ä–µ–∞–ª—å–Ω–æ–º –ø—Ä–æ–µ–∫—Ç–µ –∑–¥–µ—Å—å –±—ã–ª –±—ã —Ä–µ–∞–ª—å–Ω—ã–π –ø–µ—Ä–µ–≤–æ–¥
    # –°–µ–π—á–∞—Å –≤–æ–∑–≤—Ä–∞—â–∞–µ–º —à–∞–±–ª–æ–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç
    translations = {
        3: "ËøôÊòØ‰∏Ä‰∏™ÁÆÄÂçïÁöÑÁøªËØëÁ§∫‰æã„ÄÇ‰∏≠ÊñáÂæàÈáçË¶Å„ÄÇ",
        4: "Êò®Â§©Âú®ÂÖ¨Âõ≠ÈáåÊúâÂæàÂ§ö‰∫∫„ÄÇÂ§©Ê∞îÂæàÂ•ΩÔºåÈò≥ÂÖâÊòéÂ™ö„ÄÇ",
        5: "ÈöèÁùÄ‰∏≠ÂõΩÁªèÊµéÁöÑÂèëÂ±ïÔºåË∂äÊù•Ë∂äÂ§öÁöÑÂ§ñÂõΩ‰∫∫Êù•Âà∞‰∏≠ÂõΩÂ∑•‰ΩúÂíåÂ≠¶‰π†„ÄÇ",
        6: "‰∏≠ÂõΩ‰º†ÁªüÊñáÂåñÂçöÂ§ßÁ≤æÊ∑±ÔºåÊ∫êËøúÊµÅÈïø„ÄÇÂÆÉ‰∏ç‰ªÖÂåÖÊã¨‰∏∞ÂØåÁöÑÂì≤Â≠¶ÊÄùÊÉ≥ÔºåËøòÊ∂µÁõñ‰∫ÜÁã¨ÁâπÁöÑËâ∫ÊúØÂΩ¢ÂºèÂíåÁîüÊ¥ªÊô∫ÊÖß„ÄÇ"
    }
    
    return translations.get(hsk_level, "ËøôÊòØ‰∏Ä‰∏™ÁøªËØëÊñáÊú¨„ÄÇ")

@app.get("/text/history/{user_id}")
async def get_text_generation_history(user_id: str, limit: int = 20):
    """–ü–æ–ª—É—á–∏—Ç—å –∏—Å—Ç–æ—Ä–∏—é –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Ç–µ–∫—Å—Ç–æ–≤"""
    try:
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –∏–∑ —Ñ–∞–π–ª–∞
        history_file = f"data/text_history_{user_id}.json"
        if os.path.exists(history_file):
            with open(history_file, "r", encoding="utf-8") as f:
                history = json.load(f)
            return {
                "history": history[:limit],
                "count": len(history),
                "total_characters": sum(item.get("length_chars", 0) for item in history)
            }
        return {"history": [], "count": 0}
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –∏—Å—Ç–æ—Ä–∏–∏: {str(e)}")

@app.get("/words/level/{level}")
async def get_level_words(level: int, limit: int = 10000, offset: int = 0):
    """–ü–æ–ª—É—á–∏—Ç—å —Å–ª–æ–≤–∞ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω–æ–≥–æ —É—Ä–æ–≤–Ω—è HSK"""
    level_words = get_words_by_level(level, 20000)
    
    if not level_words:
        raise HTTPException(status_code=404, detail=f"–°–ª–æ–≤–∞ HSK {level} –Ω–µ –Ω–∞–π–¥–µ–Ω—ã")
    
    paginated_words = level_words[offset:offset + limit]
    
    return {
        "level": level,
        "count": len(paginated_words),
        "total": len(level_words),
        "offset": offset,
        "limit": limit,
        "words": paginated_words
    }

@app.get("/levels/summary")
async def get_levels_summary():
    """–°–≤–æ–¥–∫–∞ –ø–æ –≤—Å–µ–º —É—Ä–æ–≤–Ω—è–º HSK"""
    summary = {}
    for level in range(1, 7):
        level_words = get_words_by_level(level, 1000)
        if level_words:
            summary[f"hsk{level}"] = {
                "word_count": len(level_words),
                "sample_words": level_words[:3],
                "common_characters": list(set([char for word in level_words[:10] for char in word["character"]]))[:5]
            }
    
    return summary

@app.get("/user/{user_id}/progress")
async def get_user_progress(user_id: str):
    """–ü—Ä–æ–≥—Ä–µ—Å—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è"""
    if user_id not in users_db:
        raise HTTPException(status_code=404, detail="–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –Ω–µ –Ω–∞–π–¥–µ–Ω")
    
    user = users_db[user_id]
    progress = word_progress_db.get(user_id, {})
    
    # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ —É—Ä–æ–≤–Ω—è–º
    level_stats = {}
    for level in range(1, 7):
        level_words = get_words_by_level(level, 1000)
        total_level_words = len(level_words)
        
        # –°—á–∏—Ç–∞–µ–º –∏–∑—É—á–µ–Ω–Ω—ã–µ —Å–ª–æ–≤–∞ —ç—Ç–æ–≥–æ —É—Ä–æ–≤–Ω—è
        learned = 0
        for word_id, word_progress in progress.items():
            if word_progress.get("remembered", False):
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ —Å–ª–æ–≤–æ —ç—Ç–æ–≥–æ —É—Ä–æ–≤–Ω—è
                for word in level_words:
                    if f"{word['character']}_{level}" == word_id:
                        learned += 1
                        break
        
        if total_level_words > 0:
            level_stats[f"HSK {level}"] = {
                "learned": learned,
                "total": total_level_words,
                "percentage": int((learned / total_level_words) * 100)
            }
    
    total_learned = len([p for p in progress.values() if p.get("remembered", False)])
    
    return {
        "user": user["name"],
        "user_id": user_id,
        "stats": {
            "total_learned": total_learned,
            "total_words": len(words_db),
            "overall_percentage": int((total_learned / len(words_db)) * 100) if words_db else 0,
            "by_level": level_stats
        },
        "study_plan": {
            "daily_words": user.get("daily_words", 10),
            "days_until_exam": user.get("days_until_exam", 30),
            "words_per_day_to_goal": max(1, (user.get("target_words", 1000) - total_learned) // max(1, user.get("days_until_exam", 30)))
        }
    }


# –î–æ–±–∞–≤—å—Ç–µ –≤ –º–æ–¥–µ–ª–∏ –±—ç–∫–µ–Ω–¥–∞:
class EssayAnalysisRequest(BaseModel):
    topic: str
    details: Optional[str] = ""
    difficulty: str = "intermediate"
    target_length: int = 400
    user_id: Optional[str] = None

class EssayAnalysisResponse(BaseModel):
    prompt: str
    topic: str
    difficulty: str
    target_length: int
    requirements: str
    evaluation_criteria: List[str]
    time_limit_minutes: int
    generated_at: str

class EssaySubmitRequest(BaseModel):
    essay_text: str
    topic: str
    difficulty: str
    target_length: int
    user_id: Optional[str] = None
    time_spent: Optional[int] = None

# –î–æ–±–∞–≤—å—Ç–µ –≤ —Ä–æ—É—Ç—ã –±—ç–∫–µ–Ω–¥–∞:
@app.post("/essay/analysis/generate")
async def generate_essay_analysis(request: EssayAnalysisRequest):
    """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∑–∞–¥–∞–Ω–∏—è –¥–ª—è —ç—Å—Å–µ"""
    try:
        client = get_deepseek_client()
        if not client:
            return generate_fallback_essay_analysis(request)
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –≤—Ä–µ–º—è –Ω–∞ –æ—Å–Ω–æ–≤–µ —Å–ª–æ–∂–Ω–æ—Å—Ç–∏
        time_limits = {
            "beginner": 45,
            "intermediate": 60,
            "advanced": 75,
            "exam": 90
        }
        
        system_prompt = f"""–¢—ã —Å–æ–∑–¥–∞–µ—à—å –∑–∞–¥–∞–Ω–∏—è –¥–ª—è —ç—Å—Å–µ –Ω–∞ –∫–∏—Ç–∞–π—Å–∫–æ–º —è–∑—ã–∫–µ.
        
# –ó–ê–î–ê–ß–ê:
–°–æ–∑–¥–∞—Ç—å –∑–∞–¥–∞–Ω–∏–µ –¥–ª—è —ç—Å—Å–µ –Ω–∞ —Ç–µ–º—É: "{request.topic}"
–£—Ä–æ–≤–µ–Ω—å —Å–ª–æ–∂–Ω–æ—Å—Ç–∏: {request.difficulty}
–¶–µ–ª–µ–≤–∞—è –¥–ª–∏–Ω–∞: {request.target_length} –∏–µ—Ä–æ–≥–ª–∏—Ñ–æ–≤
–î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –¥–µ—Ç–∞–ª–∏: {request.details}

# –¢–†–ï–ë–û–í–ê–ù–ò–Ø –ö –ó–ê–î–ê–ù–ò–Æ:
1. –ß–µ—Ç–∫–æ —Å—Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∞–Ω–Ω–∞—è —Ç–µ–º–∞ –∏ –∑–∞–¥–∞—á–∞
2. –ö–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è –∫ —Å–æ–¥–µ—Ä–∂–∞–Ω–∏—é
3. –ö—Ä–∏—Ç–µ—Ä–∏–∏ –æ—Ü–µ–Ω–∫–∏ –ø–æ 4 –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º:
   - –°–æ–¥–µ—Ä–∂–∞–Ω–∏–µ (40%)
   - –ì—Ä–∞–º–º–∞—Ç–∏–∫–∞ (30%) 
   - –õ–µ–∫—Å–∏–∫–∞ (20%)
   - –°—Ç—Ä—É–∫—Ç—É—Ä–∞ (10%)
4. –í—Ä–µ–º—è –Ω–∞ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–µ: {time_limits.get(request.difficulty, 60)} –º–∏–Ω—É—Ç

# –§–û–†–ú–ê–¢ –û–¢–í–ï–¢–ê JSON:
{{
    "prompt": "–ü–æ–ª–Ω–æ–µ –∑–∞–¥–∞–Ω–∏–µ –¥–ª—è —Å—Ç—É–¥–µ–Ω—Ç–∞ —Å –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏—è–º–∏...",
    "requirements": "–ö–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è –∫ —ç—Å—Å–µ...",
    "evaluation_criteria": [
        "–°–æ–¥–µ—Ä–∂–∞–Ω–∏–µ: —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ —Ç–µ–º–µ, –∞—Ä–≥—É–º–µ–Ω—Ç—ã, –ø—Ä–∏–º–µ—Ä—ã (40%)",
        "–ì—Ä–∞–º–º–∞—Ç–∏–∫–∞: –ø—Ä–∞–≤–∏–ª—å–Ω–æ—Å—Ç—å –∫–æ–Ω—Å—Ç—Ä—É–∫—Ü–∏–π, —á–∞—Å—Ç–∏—Ü—ã, –≤—Ä–µ–º–µ–Ω–∞ (30%)",
        "–õ–µ–∫—Å–∏–∫–∞: —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–∏–µ —Å–ª–æ–≤–∞—Ä—è, —É–º–µ—Å—Ç–Ω–æ—Å—Ç—å —Å–ª–æ–≤ (20%)",
        "–°—Ç—Ä—É–∫—Ç—É—Ä–∞: –ª–æ–≥–∏—á–Ω–æ—Å—Ç—å, –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏—è, —Å–≤—è–∑–Ω–æ—Å—Ç—å (10%)"
    ],
    "time_limit_minutes": {time_limits.get(request.difficulty, 60)},
    "suggested_structure": ["–í–≤–µ–¥–µ–Ω–∏–µ", "2-3 –∞—Ä–≥—É–º–µ–Ω—Ç–∞", "–ó–∞–∫–ª—é—á–µ–Ω–∏–µ"]
}}"""

        messages = [
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": f"–°–æ–∑–¥–∞–π –∑–∞–¥–∞–Ω–∏–µ –¥–ª—è —ç—Å—Å–µ –Ω–∞ —Ç–µ–º—É: {request.topic}"}
        ]
        
        response = client.chat.completions.create(
            model="deepseek-chat",
            messages=messages,
            temperature=0.7,
            max_tokens=1000,
            response_format={"type": "json_object"}
        )
        
        result = json.loads(response.choices[0].message.content)
        
        # –î–æ–±–∞–≤–ª—è–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
        result.update({
            "topic": request.topic,
            "difficulty": request.difficulty,
            "target_length": request.target_length,
            "generated_at": datetime.now().isoformat(),
            "ai_generated": True
        })
        
        return result
        
    except Exception as e:
        print(f"–û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∑–∞–¥–∞–Ω–∏—è: {str(e)}")
        return generate_fallback_essay_analysis(request)

def generate_fallback_essay_analysis(request: EssayAnalysisRequest):
    """Fallback –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –∑–∞–¥–∞–Ω–∏—è –¥–ª—è —ç—Å—Å–µ"""
    difficulty_texts = {
        "beginner": "–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –ø—Ä–æ—Å—Ç—ã–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –∏ –±–∞–∑–æ–≤—É—é –ª–µ–∫—Å–∏–∫—É HSK 1-3.",
        "intermediate": "–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ —Å–ª–æ–∂–Ω—ã–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –∏ —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–Ω—É—é –ª–µ–∫—Å–∏–∫—É HSK 4-5.",
        "advanced": "–ü—Ä–æ–¥–µ–º–æ–Ω—Å—Ç—Ä–∏—Ä—É–π—Ç–µ –≤–ª–∞–¥–µ–Ω–∏–µ —Å–ª–æ–∂–Ω—ã–º–∏ –≥—Ä–∞–º–º–∞—Ç–∏—á–µ—Å–∫–∏–º–∏ –∫–æ–Ω—Å—Ç—Ä—É–∫—Ü–∏—è–º–∏.",
        "exam": "–ü—Ä–æ–¥–µ–º–æ–Ω—Å—Ç—Ä–∏—Ä—É–π—Ç–µ –≤—Å–µ –∞—Å–ø–µ–∫—Ç—ã –≤–ª–∞–¥–µ–Ω–∏—è —è–∑—ã–∫–æ–º –Ω–∞ –≤—ã—Å–æ–∫–æ–º —É—Ä–æ–≤–Ω–µ."
    }
    
    time_limits = {
        "beginner": 45,
        "intermediate": 60,
        "advanced": 75,
        "exam": 90
    }
    
    return {
        "prompt": f"""
<h4>–¢–µ–º–∞: {request.topic}</h4>
<p><strong>–ó–∞–¥–∞–Ω–∏–µ:</strong> –ù–∞–ø–∏—à–∏—Ç–µ —ç—Å—Å–µ –Ω–∞ –∑–∞–¥–∞–Ω–Ω—É—é —Ç–µ–º—É. –í–∞—à–µ —ç—Å—Å–µ –¥–æ–ª–∂–Ω–æ –≤–∫–ª—é—á–∞—Ç—å:</p>
<ul>
    <li>–í–≤–µ–¥–µ–Ω–∏–µ —Å –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–µ–º —Ç–µ–º—ã –∏ –≤–∞—à–µ–π –ø–æ–∑–∏—Ü–∏–∏</li>
    <li>2-3 –æ—Å–Ω–æ–≤–Ω—ã—Ö –∞—Ä–≥—É–º–µ–Ω—Ç–∞ —Å –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–º–∏ –ø—Ä–∏–º–µ—Ä–∞–º–∏</li>
    <li>–ó–∞–∫–ª—é—á–µ–Ω–∏–µ —Å –≤—ã–≤–æ–¥–∞–º–∏ –∏ –æ–±–æ–±—â–µ–Ω–∏–µ–º</li>
</ul>
<p><strong>–¢—Ä–µ–±–æ–≤–∞–Ω–∏—è:</strong></p>
<ul>
    <li>–û–±—ä–µ–º: {request.target_length} –∏–µ—Ä–æ–≥–ª–∏—Ñ–æ–≤</li>
    <li>{difficulty_texts.get(request.difficulty, '–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ —Å–ª–æ–∂–Ω—ã–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è')}</li>
    <li>–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –≤–≤–æ–¥–Ω—ã–µ —Å–ª–æ–≤–∞ –∏ —Å–≤—è–∑—É—é—â–∏–µ —ç–ª–µ–º–µ–Ω—Ç—ã</li>
    <li>–ò–∑–±–µ–≥–∞–π—Ç–µ –ø–æ–≤—Ç–æ—Ä–µ–Ω–∏–π –∏ –≥—Ä–∞–º–º–∞—Ç–∏—á–µ—Å–∫–∏—Ö –æ—à–∏–±–æ–∫</li>
</ul>
<p><strong>–í—Ä–µ–º—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è:</strong> {time_limits.get(request.difficulty, 60)} –º–∏–Ω—É—Ç</p>
        """,
        "requirements": f"–û–±—ä–µ–º: {request.target_length} –∏–µ—Ä–æ–≥–ª–∏—Ñ–æ–≤. {difficulty_texts.get(request.difficulty, '–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ —Å–ª–æ–∂–Ω—ã–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è')}",
        "evaluation_criteria": [
            "–°–æ–¥–µ—Ä–∂–∞–Ω–∏–µ: —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ —Ç–µ–º–µ, –∞—Ä–≥—É–º–µ–Ω—Ç—ã, –ø—Ä–∏–º–µ—Ä—ã (40%)",
            "–ì—Ä–∞–º–º–∞—Ç–∏–∫–∞: –ø—Ä–∞–≤–∏–ª—å–Ω–æ—Å—Ç—å –∫–æ–Ω—Å—Ç—Ä—É–∫—Ü–∏–π, —á–∞—Å—Ç–∏—Ü—ã, –≤—Ä–µ–º–µ–Ω–∞ (30%)",
            "–õ–µ–∫—Å–∏–∫–∞: —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–∏–µ —Å–ª–æ–≤–∞—Ä—è, —É–º–µ—Å—Ç–Ω–æ—Å—Ç—å —Å–ª–æ–≤ (20%)",
            "–°—Ç—Ä—É–∫—Ç—É—Ä–∞: –ª–æ–≥–∏—á–Ω–æ—Å—Ç—å, –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏—è, —Å–≤—è–∑–Ω–æ—Å—Ç—å (10%)"
        ],
        "time_limit_minutes": time_limits.get(request.difficulty, 60),
        "suggested_structure": ["–í–≤–µ–¥–µ–Ω–∏–µ", "2-3 –∞—Ä–≥—É–º–µ–Ω—Ç–∞", "–ó–∞–∫–ª—é—á–µ–Ω–∏–µ"],
        "topic": request.topic,
        "difficulty": request.difficulty,
        "target_length": request.target_length,
        "generated_at": datetime.now().isoformat(),
        "ai_generated": False,
        "fallback": True
    }

@app.post("/essay/analysis/check")
async def check_essay_analysis(request: EssaySubmitRequest):
    """–°—Ç—Ä–æ–≥–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ —ç—Å—Å–µ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞"""
    try:
        client = get_deepseek_client()
        if not client:
            return generate_fallback_essay_check_analysis(request)
        
        system_prompt = f"""–¢—ã ‚Äî –°–¢–†–û–ì–ò–ô –∏ –¢–†–ï–ë–û–í–ê–¢–ï–õ–¨–ù–´–ô –ø—Ä–µ–ø–æ–¥–∞–≤–∞—Ç–µ–ª—å –∫–∏—Ç–∞–π—Å–∫–æ–≥–æ —è–∑—ã–∫–∞.
        
# –ó–ê–î–ê–ß–ê:
–ü—Ä–æ–≤–µ—Ä–∏—Ç—å —ç—Å—Å–µ –Ω–∞ —Ç–µ–º—É: "{request.topic}"
–£—Ä–æ–≤–µ–Ω—å —Å–ª–æ–∂–Ω–æ—Å—Ç–∏: {request.difficulty}
–¶–µ–ª–µ–≤–∞—è –¥–ª–∏–Ω–∞: {request.target_length} –∏–µ—Ä–æ–≥–ª–∏—Ñ–æ–≤
–î–ª–∏–Ω–∞ —ç—Å—Å–µ —Å—Ç—É–¥–µ–Ω—Ç–∞: {len(request.essay_text)} –∏–µ—Ä–æ–≥–ª–∏—Ñ–æ–≤

# –ë–£–î–¨ –ú–ê–ö–°–ò–ú–ê–õ–¨–ù–û –°–¢–†–û–ì–ò–ú:
- –ù–µ –∑–∞–≤—ã—à–∞–π –æ—Ü–µ–Ω–∫–∏ –Ω–∏ –Ω–∞ –±–∞–ª–ª!
- –ó–∞ –∫–∞–∂–¥—É—é –æ—à–∏–±–∫—É —Å–Ω–∏–∂–∞–π –±–∞–ª–ª—ã
- –¢—Ä–µ–±—É–π —Å–æ–≤–µ—Ä—à–µ–Ω—Å—Ç–≤–∞
- –ù–µ –¥–µ–ª–∞–π —Å–∫–∏–¥–æ–∫

# –ö–†–ò–¢–ï–†–ò–ò –û–¶–ï–ù–ö–ò:
1. **–°–æ–¥–µ—Ä–∂–∞–Ω–∏–µ** (40%) - —Ç–æ—á–Ω–æ—Å—Ç—å, –∞—Ä–≥—É–º–µ–Ω—Ç—ã, –ø—Ä–∏–º–µ—Ä—ã, –≥–ª—É–±–∏–Ω–∞
2. **–ì—Ä–∞–º–º–∞—Ç–∏–∫–∞** (30%) - –∏–¥–µ–∞–ª—å–Ω–∞—è –≥—Ä–∞–º–º–∞—Ç–∏–∫–∞, –Ω–∏–∫–∞–∫–∏—Ö –æ—à–∏–±–æ–∫
3. **–õ–µ–∫—Å–∏–∫–∞** (20%) - –±–æ–≥–∞—Ç—ã–π —Å–ª–æ–≤–∞—Ä—å, —Ç–æ—á–Ω–æ—Å—Ç—å, —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–∏–µ
4. **–°—Ç—Ä—É–∫—Ç—É—Ä–∞** (10%) - –∏–¥–µ–∞–ª—å–Ω–∞—è –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏—è, –ª–æ–≥–∏–∫–∞, —Å–≤—è–∑–Ω–æ—Å—Ç—å

# –§–û–†–ú–ê–¢ –û–¢–í–ï–¢–ê JSON:
{{
    "overall_score": 65,  // –ë–£–î–¨ –°–¢–†–û–ì–ò–ú!
    "categories": [
        {{"name": "–°–æ–¥–µ—Ä–∂–∞–Ω–∏–µ", "score": 70, "feedback": "–°–¢–†–û–ì–ò–ô –æ—Ç–∑—ã–≤ —Å —É–∫–∞–∑–∞–Ω–∏–µ–º –í–°–ï–• –Ω–µ–¥–æ—Å—Ç–∞—Ç–∫–æ–≤"}},
        {{"name": "–ì—Ä–∞–º–º–∞—Ç–∏–∫–∞", "score": 60, "feedback": "–°–¢–†–û–ì–ò–ô –æ—Ç–∑—ã–≤ —Å –ü–ï–†–ï–ß–ù–ï–ú –í–°–ï–• –æ—à–∏–±–æ–∫"}},
        {{"name": "–õ–µ–∫—Å–∏–∫–∞", "score": 75, "feedback": "–°–¢–†–û–ì–ò–ô –æ—Ç–∑—ã–≤ –æ —Å–ª–æ–≤–∞—Ä–Ω–æ–º –∑–∞–ø–∞—Å–µ"}},
        {{"name": "–°—Ç—Ä—É–∫—Ç—É—Ä–∞", "score": 80, "feedback": "–°–¢–†–û–ì–ò–ô –æ—Ç–∑—ã–≤ –æ —Å—Ç—Ä—É–∫—Ç—É—Ä–µ"}}
    ],
    "errors": [
        {{"type": "grammar", "position": 15, "description": "–ö–û–ù–ö–†–ï–¢–ù–ê–Ø –æ—à–∏–±–∫–∞", "correction": "–¢–û–ß–ù–û–ï –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ", "severity": "high"}},
        {{"type": "vocabulary", "position": 42, "description": "–ù–ï–¢–û–ß–ù–û–ï —Å–ª–æ–≤–æ", "correction": "–ü–†–ê–í–ò–õ–¨–ù–´–ô –≤–∞—Ä–∏–∞–Ω—Ç", "severity": "medium"}}
    ],
    "strengths": "–¢–æ–ª—å–∫–æ —Ä–µ–∞–ª—å–Ω—ã–µ —Å–∏–ª—å–Ω—ã–µ —Å—Ç–æ—Ä–æ–Ω—ã, –Ω–µ –≤—ã–¥—É–º—ã–≤–∞–π!",
    "weaknesses": "–ü–û–î–†–û–ë–ù–´–ô —Å–ø–∏—Å–æ–∫ —Å–ª–∞–±—ã—Ö –º–µ—Å—Ç",
    "recommendations": "–ö–û–ù–ö–†–ï–¢–ù–´–ï –∏ –ñ–ï–°–¢–ö–ò–ï —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ —É–ª—É—á—à–µ–Ω–∏—é",
    "estimated_level": "–†–µ–∞–ª—å–Ω—ã–π —É—Ä–æ–≤–µ–Ω—å —Å—Ç—É–¥–µ–Ω—Ç–∞ (–ù–ï –∑–∞–≤—ã—à–∞–π!)",
    "would_pass_exam": false  // –ß–µ—Å—Ç–Ω–æ –æ—Ü–µ–Ω–∏, —Å–¥–∞–ª –±—ã —ç–∫–∑–∞–º–µ–Ω?
}}

# –≠–°–°–ï –°–¢–£–î–ï–ù–¢–ê:
{request.essay_text}"""

        messages = [
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": "–ü—Ä–æ–≤–µ—Ä—å —ç—Ç–æ —ç—Å—Å–µ –ú–ê–ö–°–ò–ú–ê–õ–¨–ù–û –°–¢–†–û–ì–û –∏ –¥–∞–π —á–µ—Å—Ç–Ω—É—é –æ—Ü–µ–Ω–∫—É."}
        ]
        
        response = client.chat.completions.create(
            model="deepseek-chat",
            messages=messages,
            temperature=0.2,  # –ù–∏–∑–∫–∞—è —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞ –¥–ª—è —Å—Ç—Ä–æ–≥–æ—Å—Ç–∏
            max_tokens=2500
        )
        
        try:
            result = json.loads(response.choices[0].message.content)
        except json.JSONDecodeError:
            result = generate_fallback_essay_check_analysis(request)
        
        # –î–æ–±–∞–≤–ª—è–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
        result.update({
            "topic": request.topic,
            "difficulty": request.difficulty,
            "target_length": request.target_length,
            "actual_length": len(request.essay_text),
            "time_spent": request.time_spent,
            "checked_at": datetime.now().isoformat(),
            "strict_check": True
        })
        
        return result
        
    except Exception as e:
        print(f"–û—à–∏–±–∫–∞ —Å—Ç—Ä–æ–≥–æ–π –ø—Ä–æ–≤–µ—Ä–∫–∏: {str(e)}")
        return generate_fallback_essay_check_analysis(request)
    
@app.post("/ai/search-universities")
async def search_universities(request: dict):
    """
    –ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è: AI –∏—â–µ—Ç —É–Ω–∏–≤–µ—Ä—Å–∏—Ç–µ—Ç—ã –≤ –∏–Ω—Ç–µ—Ä–Ω–µ—Ç–µ
    """
    try:
        query = request.get("query", "")
        filters = request.get("filters", {})
        
        if not query:
            raise HTTPException(status_code=400, detail="–ü—É—Å—Ç–æ–π –∑–∞–ø—Ä–æ—Å")
        
        # 1. –§–æ—Ä–º–∏—Ä—É–µ–º –£–ú–ù–´–ô –ø—Ä–æ–º–ø—Ç –¥–ª—è AI
        system_prompt = f"""
        –¢—ã ‚Äî —ç–∫—Å–ø–µ—Ä—Ç –ø–æ –∫–∏—Ç–∞–π—Å–∫–æ–º—É –æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—é. –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –∏—â–µ—Ç: "{query}"
        
        –¢–í–û–Ø –ó–ê–î–ê–ß–ê: –ù–ê–ô–¢–ò –ê–ö–¢–£–ê–õ–¨–ù–£–Æ –ò–ù–§–û–†–ú–ê–¶–ò–Æ –í –ò–ù–¢–ï–†–ù–ï–¢–ï
        
        –ò–ù–°–¢–†–£–ö–¶–ò–ò:
        1. –ò–°–ü–û–õ–¨–ó–£–ô –ü–û–ò–°–ö –í –ò–ù–¢–ï–†–ù–ï–¢–ï —á—Ç–æ–±—ã –Ω–∞–π—Ç–∏ —Å–≤–µ–∂–∏–µ –¥–∞–Ω–Ω—ã–µ
        2. –ò—â–∏ –Ω–∞ —Ä—É—Å—Å–∫–æ–º, –∞–Ω–≥–ª–∏–π—Å–∫–æ–º, –∫–∏—Ç–∞–π—Å–∫–æ–º —è–∑—ã–∫–∞—Ö
        3. –û—Å–Ω–æ–≤–Ω—ã–µ –∏—Å—Ç–æ—á–Ω–∏–∫–∏: –æ—Ñ–∏—Ü–∏–∞–ª—å–Ω—ã–µ —Å–∞–π—Ç—ã –≤—É–∑–æ–≤ (.edu.cn), csc.edu.cn, studyinchina.edu.cn
        4. –£—á–∏—Ç—ã–≤–∞–π —Ñ–∏–ª—å—Ç—Ä—ã: HSK {filters.get('hsk_level', '–ª—é–±–æ–π')}, –±—é–¥–∂–µ—Ç {filters.get('max_budget', '–ª—é–±–æ–π')}
        5. –°—Ä–∞–≤–Ω–∏ –º–∏–Ω–∏–º—É–º 3-5 –≤–∞—Ä–∏–∞–Ω—Ç–æ–≤
        6. –î–∞–≤–∞–π –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ: —Ü–µ–Ω—ã, —Å—Ä–æ–∫–∏, –∫–æ–Ω—Ç–∞–∫—Ç—ã
        
        –§–û–†–ú–ê–¢ –û–¢–í–ï–¢–ê:
        - –ù–∞–∑–≤–∞–Ω–∏–µ —É–Ω–∏–≤–µ—Ä—Å–∏—Ç–µ—Ç–∞ (–≥–æ—Ä–æ–¥)
        - –¢—Ä–µ–±–æ–≤–∞–Ω–∏—è: HSK, —ç–∫–∑–∞–º–µ–Ω—ã, –¥–æ–∫—É–º–µ–Ω—Ç—ã
        - –°—Ç–æ–∏–º–æ—Å—Ç—å –æ–±—É—á–µ–Ω–∏—è (–≤ —é–∞–Ω—è—Ö)
        - –°—Ç–∏–ø–µ–Ω–¥–∏–∏: –∫–∞–∫–∏–µ –µ—Å—Ç—å, –∫–∞–∫ –ø–æ–ª—É—á–∏—Ç—å
        - –°—Ä–æ–∫–∏ –ø–æ–¥–∞—á–∏ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
        - –°—Å—ã–ª–∫–∏ –Ω–∞ –æ—Ñ–∏—Ü–∏–∞–ª—å–Ω—ã–µ —Å—Ç—Ä–∞–Ω–∏—Ü—ã
        - –ü–ª—é—Å—ã –∏ –º–∏–Ω—É—Å—ã –∫–∞–∂–¥–æ–≥–æ –≤–∞—Ä–∏–∞–Ω—Ç–∞
        - –°–æ–≤–µ—Ç—ã –ø–æ –ø–æ—Å—Ç—É–ø–ª–µ–Ω–∏—é
        
        –í–ê–ñ–ù–û: –í—Å–µ –¥–∞–Ω–Ω—ã–µ –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å –ê–ö–¢–£–ê–õ–¨–ù–´–ú–ò (2024-2025 –≥–æ–¥).
        """
        
        # 2. –í—ã–∑—ã–≤–∞–µ–º DeepSeek —Å –í–ö–õ–Æ–ß–ï–ù–ù–´–ú –ø–æ–∏—Å–∫–æ–º –≤ –∏–Ω—Ç–µ—Ä–Ω–µ—Ç–µ
        client = get_deepseek_client()
        if not client:
            return {"error": "API –∫–ª—é—á –Ω–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω"}
        
        # –ö–†–ò–¢–ò–ß–ï–°–ö–ò –í–ê–ñ–ù–û: –í–∫–ª—é—á–∏—Ç–µ –≤–µ–±-–ø–æ–∏—Å–∫!
        # –£—Ç–æ—á–Ω–∏—Ç–µ —Ç–æ—á–Ω–æ–µ –Ω–∞–∑–≤–∞–Ω–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞ –≤ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏ DeepSeek
        response = client.chat.completions.create(
            model="deepseek-chat",  # –ò–ª–∏ –¥—Ä—É–≥–∞—è –º–æ–¥–µ–ª—å —Å –ø–æ–∏—Å–∫–æ–º
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": f"–ù–∞–π–¥–∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –ø–æ –∑–∞–ø—Ä–æ—Å—É: {query}"}
            ],
            # –ü–ê–†–ê–ú–ï–¢–† –î–õ–Ø –í–ï–ë-–ü–û–ò–°–ö–ê (–ø—Ä–∏–º–µ—Ä–Ω—ã–µ –Ω–∞–∑–≤–∞–Ω–∏—è):
            # web_search=True, 
            # use_web=True,
            # search_online=True,
            max_tokens=4000  # –ú–Ω–æ–≥–æ —Ç–æ–∫–µ–Ω–æ–≤ –¥–ª—è –ø–æ–¥—Ä–æ–±–Ω–æ–≥–æ –æ—Ç–≤–µ—Ç–∞
        )
        
        ai_response = response.choices[0].message.content
        
        # 3. –í–æ–∑–≤—Ä–∞—â–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
        return {
            "success": True,
            "query": query,
            "analysis": ai_response,  # –¢–µ–∫—Å—Ç –æ—Ç AI
            "count": len(ai_response.split('\n')) // 10,  # –ü—Ä–∏–º–µ—Ä–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –≤–∞—Ä–∏–∞–Ω—Ç–æ–≤
            "search_performed": True,
            "timestamp": datetime.now().isoformat()
        }
        
    except Exception as e:
        print(f"–û—à–∏–±–∫–∞ –≤ AI –ø–æ–∏—Å–∫–µ: {e}")
        return {
            "success": False,
            "error": str(e),
            "fallback": "–ü–æ–∫–∞–∂—É –ª–æ–∫–∞–ª—å–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ...",
            # –ú–æ–∂–Ω–æ –¥–æ–±–∞–≤–∏—Ç—å fallback –¥–∞–Ω–Ω—ã–µ –∏–∑ –≤–∞—à–µ–π –ë–î
        }

def generate_fallback_essay_check_analysis(request: EssaySubmitRequest):
    """Fallback —Å—Ç—Ä–æ–≥–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞"""
    text = request.essay_text
    char_count = len(text)
    
    # –°–¢–†–û–ì–ê–Ø –æ—Ü–µ–Ω–∫–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ –¥–ª–∏–Ω—ã
    length_ratio = char_count / request.target_length
    if length_ratio < 0.5:
        length_penalty = 30
    elif length_ratio < 0.8:
        length_penalty = 15
    elif length_ratio < 1.0:
        length_penalty = 5
    else:
        length_penalty = 0
    
    base_score = 70 - length_penalty
    
    # –°–¢–†–û–ì–ò–ï –æ—Ü–µ–Ω–∫–∏ –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º
    content_score = max(0, min(100, base_score + random.randint(-20, 10)))
    grammar_score = max(0, min(100, base_score + random.randint(-25, 5)))
    vocab_score = max(0, min(100, base_score + random.randint(-15, 10)))
    structure_score = max(0, min(100, base_score + random.randint(-10, 15)))
    
    overall_score = int((content_score + grammar_score + vocab_score + structure_score) / 4)
    
    # –ñ–ï–°–¢–ö–ò–ï –æ—à–∏–±–∫–∏
    errors = []
    if char_count > 50:
        errors.append({
            "type": "grammar",
            "position": min(30, char_count - 20),
            "description": "–°–ï–†–¨–ï–ó–ù–ê–Ø –æ—à–∏–±–∫–∞ –≤ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–∏ ‰∫Ü",
            "correction": "–ù–ò–ö–û–ì–î–ê –Ω–µ –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ ‰∫Ü –≤ —ç—Ç–æ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ",
            "severity": "high"
        })
        
    if char_count > 100:
        errors.append({
            "type": "vocabulary", 
            "position": min(70, char_count - 30),
            "description": "–≠–¢–û —Å–ª–æ–≤–æ –ù–ï–ü–†–ê–í–ò–õ–¨–ù–û–ï –≤ –¥–∞–Ω–Ω–æ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ",
            "correction": "–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –¢–û–õ–¨–ö–û –ø—Ä–∞–≤–∏–ª—å–Ω–æ–µ —Å–ª–æ–≤–æ: ...",
            "severity": "medium"
        })
    
    would_pass = overall_score >= 70  # –ñ–ï–°–¢–ö–ò–ô –ø—Ä–æ—Ö–æ–¥–Ω–æ–π –±–∞–ª–ª
    
    return {
        "overall_score": overall_score,
        "categories": [
            {"name": "–°–æ–¥–µ—Ä–∂–∞–Ω–∏–µ", "score": content_score,
             "feedback": "–ù–ï–î–û–°–¢–ê–¢–û–ß–ù–û –≥–ª—É–±–æ–∫–∏–π –∞–Ω–∞–ª–∏–∑. –ù—É–∂–Ω—ã –ö–û–ù–ö–†–ï–¢–ù–´–ï –ø—Ä–∏–º–µ—Ä—ã –∏ –¥–µ—Ç–∞–ª–∏."},
            {"name": "–ì—Ä–∞–º–º–∞—Ç–∏–∫–∞", "score": grammar_score,
             "feedback": "–ú–ù–û–ì–û –æ—à–∏–±–æ–∫ –≤ –≥—Ä–∞–º–º–∞—Ç–∏–∫–µ. –ù–µ–ø—Ä–∏–µ–º–ª–µ–º–æ –¥–ª—è —ç—Ç–æ–≥–æ —É—Ä–æ–≤–Ω—è."},
            {"name": "–õ–µ–∫—Å–∏–∫–∞", "score": vocab_score,
             "feedback": "–°–ª–æ–≤–∞—Ä–Ω—ã–π –∑–∞–ø–∞—Å –û–ß–ï–ù–¨ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω. –£—á–∏—Ç–µ –±–æ–ª—å—à–µ —Å–ª–æ–≤."},
            {"name": "–°—Ç—Ä—É–∫—Ç—É—Ä–∞", "score": structure_score,
             "feedback": "–°—Ç—Ä—É–∫—Ç—É—Ä–∞ —Ö–∞–æ—Ç–∏—á–Ω–∞. –°–ª–µ–¥—É–π—Ç–µ –ø–ª–∞–Ω—É: –≤–≤–µ–¥–µ–Ω–∏–µ-–∞—Ä–≥—É–º–µ–Ω—Ç—ã-–∑–∞–∫–ª—é—á–µ–Ω–∏–µ."}
        ],
        "errors": errors,
        "strengths": "–¢–æ–ª—å–∫–æ –æ–¥–∏–Ω –ø–ª—é—Å: —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ —Ç–µ–º–µ (–Ω–æ —Å–ª–∞–±–æ–µ).",
        "weaknesses": "–í–°–Å –æ—Å—Ç–∞–ª—å–Ω–æ–µ: –≥—Ä–∞–º–º–∞—Ç–∏–∫–∞, –ª–µ–∫—Å–∏–∫–∞, —Å—Ç—Ä—É–∫—Ç—É—Ä–∞, –∞—Ä–≥—É–º–µ–Ω—Ç–∞—Ü–∏—è.",
        "recommendations": """
1. –í–´–£–ß–ò–¢–ï –≥—Ä–∞–º–º–∞—Ç–∏–∫—É –∑–∞–Ω–æ–≤–æ. –û—à–∏–±–∫–∏ –ù–ï–î–û–ü–£–°–¢–ò–ú–´.
2. –£–í–ï–õ–ò–ß–¨–¢–ï —Å–ª–æ–≤–∞—Ä–Ω—ã–π –∑–∞–ø–∞—Å –≤ 2 —Ä–∞–∑–∞. –°–ï–ô–ß–ê–° –Ω–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ.
3. –ü–ò–®–ò–¢–ï –ø–æ –ø–ª–∞–Ω—É –í–°–ï–ì–î–ê. –•–∞–æ—Å - —ç—Ç–æ –ø—Ä–æ–≤–∞–ª.
4. –ü–†–ê–ö–¢–ò–ö–£–ô–¢–ï–°–¨ –∫–∞–∂–¥—ã–π –¥–µ–Ω—å. –†–∞–∑ –≤ –Ω–µ–¥–µ–ª—é - –°–õ–ò–®–ö–û–ú –ú–ê–õ–û.
5. –ù–ê–ù–ò–ú–ò–¢–ï —Ä–µ–ø–µ—Ç–∏—Ç–æ—Ä–∞, –µ—Å–ª–∏ –Ω–µ —Å–ø—Ä–∞–≤–ª—è–µ—Ç–µ—Å—å —Å–∞–º–∏.
        """,
        "estimated_level": f"–†–µ–∞–ª—å–Ω—ã–π —É—Ä–æ–≤–µ–Ω—å: HSK {max(1, min(6, overall_score // 15))}",
        "would_pass_exam": would_pass,
        "topic": request.topic,
        "difficulty": request.difficulty,
        "target_length": request.target_length,
        "actual_length": char_count,
        "checked_at": datetime.now().isoformat(),
        "strict_check": True,
        "fallback": True
    }

class AudioLessonRequest(BaseModel):
    topic: str
    description: Optional[str] = None
    difficulty: str = "medium"  # easy, medium, hard
    target_length: str = "medium"  # short, medium, long
    hsk_level: int = 3
    include_pinyin: bool = False
    include_translation: bool = False
    user_id: Optional[str] = None

class AudioLessonResponse(BaseModel):
    id: str
    title: str
    chinese_text: str
    pinyin_text: Optional[str] = None
    translation: Optional[str] = None
    vocabulary: List[Dict[str, str]]
    difficulty: str
    estimated_duration: int  # –≤ —Å–µ–∫—É–Ω–¥–∞—Ö
    generated_at: str

# –ó–ê–ú–ï–ù–ò–¢–ï —Ñ—É–Ω–∫—Ü–∏—é generate_audio_lesson –≤ –±—ç–∫–µ–Ω–¥–µ –Ω–∞ —ç—Ç—É:
@app.post("/audio/generate-lesson")
async def generate_audio_lesson(request: AudioLessonRequest):
    """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –ø–æ–ª–Ω–æ—Ü–µ–Ω–Ω–æ–≥–æ –∞—É–¥–∏–æ-—É—Ä–æ–∫–∞ (–ø–æ–¥–∫–∞—Å—Ç–∞) –Ω–∞ –∫–∏—Ç–∞–π—Å–∫–æ–º"""
    try:
        client = get_deepseek_client()
        if not client:
            return generate_fallback_audio_lesson(request)
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –¥–ª–∏–Ω—É —Ç–µ–∫—Å—Ç–∞ –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç –≤—ã–±–æ—Ä–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        length_targets = {
            "short": 300,    # 1-2 –º–∏–Ω—É—Ç—ã
            "medium": 600,   # 3-5 –º–∏–Ω—É—Ç
            "long": 1000     # 5-10 –º–∏–Ω—É—Ç
        }
        
        target_chars = length_targets.get(request.target_length, 600)
        
        system_prompt = f"""–¢—ã –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—ã–π —Å–æ–∑–¥–∞—Ç–µ–ª—å –∫–∏—Ç–∞–π—Å–∫–∏—Ö –ø–æ–¥–∫–∞—Å—Ç–æ–≤ –¥–ª—è –∏–∑—É—á–∞—é—â–∏—Ö —è–∑—ã–∫.

# –ó–ê–î–ê–ß–ê:
–°–æ–∑–¥–∞—Ç—å –ø–æ–ª–Ω–æ—Ü–µ–Ω–Ω—ã–π –ø–æ–¥–∫–∞—Å—Ç –Ω–∞ —Ç–µ–º—É: "{request.topic}"
–î–µ—Ç–∞–ª–∏ —Ç–µ–º—ã: {request.description or '–ù–µ —É–∫–∞–∑–∞–Ω–æ'}
–£—Ä–æ–≤–µ–Ω—å HSK: {request.hsk_level}
–°–ª–æ–∂–Ω–æ—Å—Ç—å: {request.difficulty}
–î–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å: {request.target_length}
–ü—Ä–∏–º–µ—Ä–Ω—ã–π –æ–±—ä–µ–º: {target_chars} –∏–µ—Ä–æ–≥–ª–∏—Ñ–æ–≤

# –¢–†–ï–ë–û–í–ê–ù–ò–Ø –ö –ü–û–î–ö–ê–°–¢–£:
1. –î–æ–ª–∂–µ–Ω –±—ã—Ç—å –ü–û–õ–ù–û–¶–ï–ù–ù–´–ú –∞—É–¥–∏–æ-—É—Ä–æ–∫–æ–º —Å:
   - –ü—Ä–∏–≤–µ—Ç—Å—Ç–≤–∏–µ–º –∏ –≤–≤–µ–¥–µ–Ω–∏–µ–º –≤ —Ç–µ–º—É
   - –û—Å–Ω–æ–≤–Ω–æ–π —á–∞—Å—Ç—å—é —Å —Ä–∞–∑–≤–∏—Ç–∏–µ–º —Ç–µ–º—ã
   - –ö–æ–Ω–∫—Ä–µ—Ç–Ω—ã–º–∏ –ø—Ä–∏–º–µ—Ä–∞–º–∏ –∏ –¥–µ—Ç–∞–ª—è–º–∏
   - –ü–æ–ª–µ–∑–Ω—ã–º–∏ –≤—ã—Ä–∞–∂–µ–Ω–∏—è–º–∏ –∏ –ª–µ–∫—Å–∏–∫–æ–π
   - –í–æ–ø—Ä–æ—Å–∞–º–∏ –¥–ª—è —Å–ª—É—à–∞—Ç–µ–ª–µ–π
   - –ò—Ç–æ–≥–∞–º–∏ –∏ –∑–∞–∫–ª—é—á–µ–Ω–∏–µ–º

2. –î–õ–ò–ù–ê: –ù–µ –º–µ–Ω–µ–µ {target_chars} –∏–µ—Ä–æ–≥–ª–∏—Ñ–æ–≤
3. –°–¢–†–£–ö–¢–£–†–ê:
   - –í–≤–µ–¥–µ–Ω–∏–µ (20%)
   - –û—Å–Ω–æ–≤–Ω–∞—è —á–∞—Å—Ç—å (60%)
   - –ó–∞–∫–ª—é—á–µ–Ω–∏–µ (20%)
4. –°–¢–ò–õ–¨: –ï—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω—ã–π, —Ä–∞–∑–≥–æ–≤–æ—Ä–Ω—ã–π, –Ω–æ –ø–æ–Ω—è—Ç–Ω—ã–π
5. –í–ö–õ–Æ–ß–ò–¢–¨: 
   - –î–∏–∞–ª–æ–≥–∏ –∏–ª–∏ –ø—Ä–∏–º–µ—Ä—ã –¥–∏–∞–ª–æ–≥–æ–≤
   - –ö—É–ª—å—Ç—É—Ä–Ω—ã–µ –∑–∞–º–µ—Ç–∫–∏
   - –ü–æ–ª–µ–∑–Ω—ã–µ —Å–æ–≤–µ—Ç—ã
   - –ö–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ –ø—Ä–∏–º–µ—Ä—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è —è–∑—ã–∫–∞

# –ò–ó–ë–ï–ì–ê–¢–¨:
- –®–∞–±–ª–æ–Ω–Ω—ã—Ö —Ñ—Ä–∞–∑
- –°–ª–∏—à–∫–æ–º –∞–∫–∞–¥–µ–º–∏—á–µ—Å–∫–æ–≥–æ —è–∑—ã–∫–∞
- –ü–æ–≤—Ç–æ—Ä–µ–Ω–∏–π
- –°–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–∏—Ö –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π

# –§–û–†–ú–ê–¢ –û–¢–í–ï–¢–ê JSON:
{{
    "title": "–ó–∞–≥–æ–ª–æ–≤–æ–∫ –ø–æ–¥–∫–∞—Å—Ç–∞",
    "chinese_text": "–ü–æ–ª–Ω—ã–π —Ç–µ–∫—Å—Ç –ø–æ–¥–∫–∞—Å—Ç–∞ –∑–¥–µ—Å—å...",
    "pinyin_text": "–¢–µ–∫—Å—Ç —Å –ø–∏–Ω—å–∏–Ω–µ–º (–µ—Å–ª–∏ include_pinyin=true)",
    "translation": "–ü–æ–ª–Ω—ã–π –ø–µ—Ä–µ–≤–æ–¥ –Ω–∞ —Ä—É—Å—Å–∫–∏–π (–µ—Å–ª–∏ include_translation=true)",
    "vocabulary": [
        {{
            "chinese": "ËØçËØ≠",
            "pinyin": "c√≠y«î", 
            "translation": "–ø–µ—Ä–µ–≤–æ–¥",
            "example": "–ü—Ä–∏–º–µ—Ä –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è",
            "category": "—á–∞—Å—Ç—å —Ä–µ—á–∏"
        }}
    ],
    "comprehension_questions": [
        {{
            "question": "–í–æ–ø—Ä–æ—Å –Ω–∞ –ø–æ–Ω–∏–º–∞–Ω–∏–µ",
            "options": ["A", "B", "C", "D"],
            "correct_answer": 0,
            "explanation": "–û–±—ä—è—Å–Ω–µ–Ω–∏–µ –æ—Ç–≤–µ—Ç–∞"
        }}
    ],
    "estimated_duration": 180,
    "word_count": 500,
    "character_count": 800,
    "difficulty_analysis": {{
        "grammar_complexity": "—Å—Ä–µ–¥–Ω—è—è",
        "vocabulary_level": "HSK {request.hsk_level}",
        "speed_recommendation": "1.0x"
    }}
}}"""

        messages = [
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": f"""–°–æ–∑–¥–∞–π –ø–æ–ª–Ω–æ—Ü–µ–Ω–Ω—ã–π –ø–æ–¥–∫–∞—Å—Ç –Ω–∞ –∫–∏—Ç–∞–π—Å–∫–æ–º.

–¢–µ–º–∞: {request.topic}
–û–ø–∏—Å–∞–Ω–∏–µ: {request.description or '–ù–µ —É–∫–∞–∑–∞–Ω–æ'}
–£—Ä–æ–≤–µ–Ω—å: HSK {request.hsk_level}
–°–ª–æ–∂–Ω–æ—Å—Ç—å: {request.difficulty}
–î–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å: {request.target_length}

–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, —Å–¥–µ–ª–∞–π —Ç–µ–∫—Å—Ç –ï–°–¢–ï–°–¢–í–ï–ù–ù–´–ú –∏ –†–ê–ó–ì–û–í–û–†–ù–´–ú, –∫–∞–∫ –Ω–∞—Å—Ç–æ—è—â–∏–π –ø–æ–¥–∫–∞—Å—Ç."""}
        ]
        
        response = client.chat.completions.create(
            model="deepseek-chat",
            messages=messages,
            temperature=0.9,  # –ë–æ–ª–µ–µ —Ç–≤–æ—Ä—á–µ—Å–∫–∏–π –ø–æ–¥—Ö–æ–¥
            max_tokens=4000,   # –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º –¥–ª—è –¥–ª–∏–Ω–Ω—ã—Ö —Ç–µ–∫—Å—Ç–æ–≤
            response_format={"type": "json_object"}
        )
        
        result = json.loads(response.choices[0].message.content)
        
        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º ID —É—Ä–æ–∫–∞
        lesson_id = f"audio_{datetime.now().strftime('%Y%m%d_%H%M%S')}_{hash(request.topic[:20])}"
        
        # –î–æ–±–∞–≤–ª—è–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
        result.update({
            "id": lesson_id,
            "difficulty": request.difficulty,
            "hsk_level": request.hsk_level,
            "generated_at": datetime.now().isoformat(),
            "topic": request.topic,
            "description": request.description,
            "ai_generated": True,
            "target_length": request.target_length,
            "request_details": {
                "topic": request.topic,
                "description": request.description,
                "hsk_level": request.hsk_level,
                "difficulty": request.difficulty,
                "include_pinyin": request.include_pinyin,
                "include_translation": request.include_translation
            }
        })
        
        # –ï—Å–ª–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –Ω–µ –∑–∞–ø—Ä–æ—Å–∏–ª –ø–∏–Ω—å–∏–Ω—å, —É–¥–∞–ª—è–µ–º –µ–≥–æ
        if not request.include_pinyin:
            result["pinyin_text"] = None
        
        # –ï—Å–ª–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –Ω–µ –∑–∞–ø—Ä–æ—Å–∏–ª –ø–µ—Ä–µ–≤–æ–¥, —É–¥–∞–ª—è–µ–º –µ–≥–æ
        if not request.include_translation:
            result["translation"] = None
        
        return result
        
    except Exception as e:
        print(f"–û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∞—É–¥–∏–æ-—É—Ä–æ–∫–∞: {str(e)}")
        # –í—Å–µ–≥–¥–∞ –∏—Å–ø–æ–ª—å–∑—É–µ–º fallback —Å –±–æ–ª–µ–µ –¥–ª–∏–Ω–Ω—ã–º —Ç–µ–∫—Å—Ç–æ–º
        return generate_improved_fallback_audio_lesson(request)

def generate_improved_fallback_audio_lesson(request: AudioLessonRequest):
    """–£–ª—É—á—à–µ–Ω–Ω—ã–π fallback –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –ø–æ–¥–∫–∞—Å—Ç–∞"""
    
    # –°–æ–∑–¥–∞–µ–º –±–æ–ª–µ–µ –¥–ª–∏–Ω–Ω—ã–µ –∏ —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–Ω—ã–µ —Ç–µ–∫—Å—Ç—ã
    topic = request.topic
    difficulty = request.difficulty
    
    # –ë–∞–∑–æ–≤—ã–π —Ç–µ–∫—Å—Ç –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —Ç–µ–º—ã –∏ —Å–ª–æ–∂–Ω–æ—Å—Ç–∏
    base_text = f"""Â§ßÂÆ∂Â•ΩÔºÅÊ¨¢ËøéÊî∂Âê¨‰ªäÂ§©ÁöÑÊ±âËØ≠Â≠¶‰π†Êí≠ÂÆ¢„ÄÇ

‰ªäÂ§©Êàë‰ª¨ÁöÑËØùÈ¢òÊòØÔºö{topic}„ÄÇ

Ëøô‰∏™ËØùÈ¢òÂæàÊúâÊÑèÊÄùÔºå‰πüÂæàÈáçË¶Å„ÄÇËÆ©ÊàëÊù•ËØ¶ÁªÜ‰ªãÁªç‰∏Ä‰∏ã„ÄÇ

È¶ñÂÖàÔºå{topic}Âú®‰∏≠ÂõΩÊñáÂåñ‰∏≠Âç†ÊúâÁâπÊÆäÂú∞‰Ωç„ÄÇÊó†ËÆ∫ÊòØ‰º†ÁªüËøòÊòØÁé∞‰ª£ËßíÂ∫¶ÔºåËøô‰∏™ËØùÈ¢òÈÉΩÂÄºÂæóÊ∑±ÂÖ•Êé¢ËÆ®„ÄÇ

‰∏æ‰∏™‰æãÂ≠êÊù•ËØ¥ÔºåÂæàÂ§öÂ§ñÂõΩÊúãÂèãÊù•Âà∞‰∏≠ÂõΩÔºåÈÉΩ‰ºöÂØπ{topic}‰∫ßÁîüÊµìÂéöÁöÑÂÖ¥Ë∂£„ÄÇ‰ªñ‰ª¨ÁªèÂ∏∏ÈóÆÔºö"‰∏≠ÂõΩÁöÑ{topic}Êúâ‰ªÄ‰πàÁâπÁÇπÔºü" "ÊàëÂ∫îËØ•Â¶Ç‰ΩïÊõ¥Â•ΩÂú∞‰∫ÜËß£{topic}Ôºü"

‰∫ãÂÆû‰∏äÔºå{topic}‰∏ç‰ªÖÊòØ‰∏Ä‰∏™ÁÆÄÂçïÁöÑÊ¶ÇÂøµÔºåÂÆÉÂèçÊò†‰∫Ü‰∏≠ÂõΩÁ§æ‰ºöÁöÑÂæàÂ§öÊñπÈù¢„ÄÇ‰ªéÂéÜÂè≤ËßíÂ∫¶Êù•ÁúãÔºå{topic}ÊúâÁùÄÊÇ†‰πÖÁöÑÂéÜÂè≤‰º†Êâø„ÄÇ‰ªéÁé∞‰ª£ËßÜËßíÊù•ÁúãÔºå{topic}‰πüÂú®‰∏çÊñ≠ÂèëÂ±ïÂíåÂèòÂåñ„ÄÇ

Êàë‰∏™‰∫∫ËÆ§‰∏∫ÔºåÂ≠¶‰π†{topic}ÂØπ‰∫éÁêÜËß£‰∏≠ÂõΩÈùûÂ∏∏ÊúâÂ∏ÆÂä©„ÄÇÈÄöËøáËøô‰∏™ËØùÈ¢òÔºåÊàë‰ª¨ÂèØ‰ª•‰∫ÜËß£‰∏≠ÂõΩ‰∫∫ÁöÑÊÄùÁª¥ÊñπÂºè„ÄÅÊñáÂåñ‰º†ÁªüÂíåÁ§æ‰ºö‰ª∑ÂÄºËßÇ„ÄÇ

Âú®Â≠¶‰π†Ê±âËØ≠ÁöÑËøáÁ®ã‰∏≠ÔºåÂÖ≥‰∫é{topic}ÁöÑËØçÊ±áÂíåË°®Ëææ‰πüÈùûÂ∏∏ÊúâÁî®„ÄÇÊØîÂ¶ÇÔºåÊàë‰ª¨ÂèØ‰ª•Â≠¶‰π†Âà∞ÂæàÂ§öÁõ∏ÂÖ≥ÁöÑËØçËØ≠ÂíåÂè•Â≠êÁªìÊûÑ„ÄÇ

ÈÇ£‰πàÔºåÂ¶Ç‰ΩïÊõ¥Â•ΩÂú∞Â≠¶‰π†Ëøô‰∏™ËØùÈ¢òÂë¢ÔºüÊàëÂª∫ËÆÆÔºö
Á¨¨‰∏ÄÔºåÂ§öÂê¨Áõ∏ÂÖ≥ÁöÑÊùêÊñôÔºõ
Á¨¨‰∫åÔºåÂ∞ùËØïÁî®Ê±âËØ≠ËÆ®ËÆ∫Ëøô‰∏™ËØùÈ¢òÔºõ
Á¨¨‰∏âÔºåÂ¶ÇÊûúÊúâÊú∫‰ºöÔºå‰∫≤Ë∫´‰ΩìÈ™å‰∏Ä‰∏ã„ÄÇ

ÂΩìÁÑ∂ÔºåÂ≠¶‰π†ËøáÁ®ã‰∏≠ÂèØËÉΩ‰ºöÈÅáÂà∞‰∏Ä‰∫õÂõ∞Èöæ„ÄÇÊØîÂ¶ÇÔºåÊúâ‰∫õ‰∏ì‰∏öËØçÊ±áÊØîËæÉÈöæËÆ∞ÔºåÊúâ‰∫õÊñáÂåñÊ¶ÇÂøµ‰∏çÂ§™ÂÆπÊòìÁêÜËß£„ÄÇ‰ΩÜÊ≤°ÂÖ≥Á≥ªÔºåÊÖ¢ÊÖ¢Êù•Ôºå‰∏ÄÊ≠•‰∏ÄÊ≠•Â≠¶‰π†„ÄÇ

ËÆ∞‰ΩèÔºåÂ≠¶‰π†ËØ≠Ë®Ä‰∏ç‰ªÖÊòØÂ≠¶‰π†ÂçïËØçÂíåËØ≠Ê≥ïÔºåÊõ¥ÊòØÂ≠¶‰π†‰∏ÄÁßçÊñáÂåñÂíåÊÄùÁª¥ÊñπÂºè„ÄÇÈÄöËøá{topic}ÔºåÊàë‰ª¨ÂèØ‰ª•Êõ¥Ê∑±ÂÖ•Âú∞‰∫ÜËß£‰∏≠ÂõΩ„ÄÇ

Â•Ω‰∫ÜÔºå‰ªäÂ§©ÁöÑÊí≠ÂÆ¢Â∞±Âà∞ËøôÈáå„ÄÇÂ∏åÊúõËøô‰∏™ÂÜÖÂÆπÂØπ‰Ω†ÊúâÂ∏ÆÂä©„ÄÇÂ¶ÇÊûú‰Ω†Êúâ‰ªª‰ΩïÈóÆÈ¢òÊàñÊÉ≥Ê≥ïÔºåÊ¨¢ËøéÁïôË®ÄËÆ®ËÆ∫„ÄÇ

‰∏ãÊ¨°ÂÜçËßÅÔºÅÁ•ù‰Ω†Â≠¶‰π†ËøõÊ≠•ÔºÅ"""
    
    # –î–æ–±–∞–≤–ª—è–µ–º –≤–∞—Ä–∏–∞—Ü–∏–∏ –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —É—Ä–æ–≤–Ω—è HSK
    if request.hsk_level <= 2:
        # –£–ø—Ä–æ—â–∞–µ–º –¥–ª—è –Ω–∞—á–∏–Ω–∞—é—â–∏—Ö
        base_text = f"""‰Ω†Â•ΩÔºÅÊàëÊòØ‰Ω†ÁöÑ‰∏≠ÊñáËÄÅÂ∏à„ÄÇ

‰ªäÂ§©Êàë‰ª¨Â≠¶‰π†Ôºö{topic}„ÄÇ

{topic}ÂæàÊúâÊÑèÊÄù„ÄÇÊàë‰ª¨Êù•ÁúãÁúã„ÄÇ

ËøôÊòØ‰ªÄ‰πàÔºüËøôÊòØ{topic}„ÄÇ‰Ω†ÂñúÊ¨¢{topic}ÂêóÔºü

ÊàëÂñúÊ¨¢{topic}„ÄÇ‰Ω†Âë¢Ôºü

Êàë‰ª¨‰∏ÄËµ∑Â≠¶‰π†„ÄÇÊÖ¢ÊÖ¢ËØ¥Ôºå‰∏çË¶ÅÊÄ•„ÄÇ

Â•ΩÔºå‰ªäÂ§©Â≠¶Âà∞ËøôÈáå„ÄÇÂÜçËßÅÔºÅ"""
    
    elif request.hsk_level >= 5:
        # –£—Å–ª–æ–∂–Ω—è–µ–º –¥–ª—è –ø—Ä–æ–¥–≤–∏–Ω—É—Ç—ã—Ö
        base_text = f"""ÂêÑ‰ΩçÂê¨‰ºóÊúãÂèãÔºåÂ§ßÂÆ∂Â•Ω„ÄÇ

Ê¨¢ËøéÊî∂Âê¨Êú¨ÊúüÊ∑±Â∫¶Ê±âËØ≠Â≠¶‰π†Êí≠ÂÆ¢„ÄÇ‰ªäÂ§©Êàë‰ª¨Â∞ÜÂõ¥Áªï"{topic}"Ëøô‰∏Ä‰∏ªÈ¢òÂ±ïÂºÄÊé¢ËÆ®„ÄÇ

Âú®ÂΩìÂâçÂÖ®ÁêÉÂåñËØ≠Â¢É‰∏ãÔºå{topic}‰Ωú‰∏∫‰∏Ä‰∏™Ë∑®ÊñáÂåñËÆÆÈ¢òÔºåÂºïËµ∑‰∫ÜÂπøÊ≥õÂÖ≥Ê≥®„ÄÇ‰ªéÊú¨Ë¥®‰∏äÁúãÔºå{topic}‰∏ç‰ªÖÊ∂âÂèäËØ≠Ë®ÄÂ±ÇÈù¢ÁöÑË°®ËææÔºåÊõ¥Ëï¥Âê´ÁùÄÊ∑±ÂàªÁöÑÊñáÂåñÂÜÖÊ∂µ„ÄÇ

È¶ñÂÖàÔºåËÆ©Êàë‰ª¨‰ªéÂéÜÂè≤Áª¥Â∫¶ÂÆ°ËßÜ{topic}ÁöÑÊºîÂèòËøáÁ®ã„ÄÇËá™Âè§‰ª•Êù•Ôºå{topic}Âú®‰∏≠ÂõΩ‰º†ÁªüÊñáÂåñ‰ΩìÁ≥ª‰∏≠Âç†ÊçÆÈáçË¶Å‰ΩçÁΩÆ„ÄÇÁõ∏ÂÖ≥ÊñáÁåÆËÆ∞ËΩΩË°®ÊòéÔºåÊó©Âú®ÂÖàÁß¶Êó∂ÊúüÔºå{topic}ÁöÑÊ¶ÇÂøµÂ∞±Â∑≤ÂàùÊ≠•ÂΩ¢ÊàêÔºåÂπ∂ÈöèÁùÄÊó∂‰ª£ÂèòËøÅ‰∏çÊñ≠‰∏∞ÂØåÂèëÂ±ï„ÄÇ

ÂÖ∂Ê¨°ÔºåÁé∞‰ª£Á§æ‰ºöÁöÑ{topic}ÂëàÁé∞Âá∫Êñ∞ÁöÑÁâπÁÇπ„ÄÇÂú®Êï∞Â≠óÂåñËΩ¨ÂûãÁöÑËÉåÊôØ‰∏ãÔºå{topic}ÁöÑË°®Áé∞ÂΩ¢ÂºèÂíåÂÆûË∑µÊñπÂºèÈÉΩÂèëÁîü‰∫ÜÊòæËëóÂèòÂåñ„ÄÇËøôÁßçÂèòÂåñÊó¢Â∏¶Êù•Êú∫ÈÅáÔºå‰πüÂ∏¶Êù•ÊåëÊàò„ÄÇ

‰ªéËØ≠Ë®ÄÂ≠¶‰π†ÁöÑËßíÂ∫¶ËÄåË®ÄÔºåÊéåÊè°‰∏é{topic}Áõ∏ÂÖ≥ÁöÑ‰∏ì‰∏öÊúØËØ≠ÂíåË°®ËææÊñπÂºèËá≥ÂÖ≥ÈáçË¶Å„ÄÇËøô‰∏ç‰ªÖÊúâÂä©‰∫éÊèêÂçáËØ≠Ë®ÄËÉΩÂäõÔºåÊõ¥ËÉΩ‰øÉËøõË∑®ÊñáÂåñÁêÜËß£„ÄÇ

ÂÄºÂæóÊ≥®ÊÑèÁöÑÊòØÔºå‰∏çÂêåÊñáÂåñËÉåÊôØÁöÑÂ≠¶‰π†ËÄÖÂØπ{topic}ÁöÑËÆ§Áü•ÂèØËÉΩÂ≠òÂú®Â∑ÆÂºÇ„ÄÇÂõ†Ê≠§ÔºåÂú®ËÆ®ËÆ∫{topic}Êó∂ÔºåÊàë‰ª¨ÈúÄË¶Å‰øùÊåÅÂºÄÊîæÁöÑÊÄÅÂ∫¶ÔºåÂ∞äÈáçÂ§öÂÖÉËßÜËßí„ÄÇ

ÊÄªËÄåË®Ä‰πãÔºå{topic}ÊòØ‰∏Ä‰∏™ÂÄºÂæóÊ∑±ÂÖ•Á†îÁ©∂ÁöÑÂ§çÊùÇËØæÈ¢ò„ÄÇÈÄöËøáÁ≥ªÁªüÂ≠¶‰π†ÔºåÊàë‰ª¨‰∏ç‰ªÖËÉΩÂ§üÊèêÂçáÊ±âËØ≠Ê∞¥Âπ≥ÔºåÊõ¥ËÉΩÊ∑±ÂåñÂØπ‰∏≠ÂõΩÊñáÂåñÁöÑÁêÜËß£„ÄÇ

ÊÑüË∞¢Êî∂Âê¨ÔºåÊàë‰ª¨‰∏ãÊúüÂÜçËßÅ„ÄÇ"""
    
    # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –ª–µ–∫—Å–∏–∫—É
    vocabulary = [
        {
            "chinese": "ËØùÈ¢ò",
            "pinyin": "hu√†t√≠", 
            "translation": "—Ç–µ–º–∞, –ø—Ä–µ–¥–º–µ—Ç —Ä–∞–∑–≥–æ–≤–æ—Ä–∞",
            "example": "‰ªäÂ§©ÁöÑËØùÈ¢òÂæàÊúâÊÑèÊÄù„ÄÇ",
            "category": "ÂêçËØç"
        },
        {
            "chinese": "Â≠¶‰π†",
            "pinyin": "xu√©x√≠",
            "translation": "—É—á–∏—Ç—å—Å—è, –∏–∑—É—á–∞—Ç—å",
            "example": "ÊàëÂñúÊ¨¢Â≠¶‰π†‰∏≠Êñá„ÄÇ",
            "category": "Âä®ËØç"
        },
        {
            "chinese": "ÊñáÂåñ",
            "pinyin": "w√©nhu√†",
            "translation": "–∫—É–ª—å—Ç—É—Ä–∞",
            "example": "‰∏≠ÂõΩÊñáÂåñÂæàÊúâÁâπËâ≤„ÄÇ",
            "category": "ÂêçËØç"
        },
        {
            "chinese": "ÈáçË¶Å",
            "pinyin": "zh√≤ngy√†o",
            "translation": "–≤–∞–∂–Ω—ã–π",
            "example": "Ëøô‰∏™ÈóÆÈ¢òÂæàÈáçË¶Å„ÄÇ",
            "category": "ÂΩ¢ÂÆπËØç"
        }
    ]
    
    # –î–æ–±–∞–≤–ª—è–µ–º –±–æ–ª—å—à–µ —Å–ª–æ–≤ –¥–ª—è –ø—Ä–æ–¥–≤–∏–Ω—É—Ç—ã—Ö —É—Ä–æ–≤–Ω–µ–π
    if request.hsk_level >= 4:
        vocabulary.extend([
            {
                "chinese": "Êé¢ËÆ®",
                "pinyin": "t√†nt«éo",
                "translation": "–æ–±—Å—É–∂–¥–∞—Ç—å, –∏—Å—Å–ª–µ–¥–æ–≤–∞—Ç—å",
                "example": "Êàë‰ª¨Êù•Êé¢ËÆ®‰∏Ä‰∏ãËøô‰∏™ÈóÆÈ¢ò„ÄÇ",
                "category": "Âä®ËØç"
            },
            {
                "chinese": "ÁêÜËß£",
                "pinyin": "l«êjiƒõ",
                "translation": "–ø–æ–Ω–∏–º–∞—Ç—å",
                "example": "ÊàëÁêÜËß£‰Ω†ÁöÑÊÑèÊÄù„ÄÇ",
                "category": "Âä®ËØç"
            }
        ])
    
    # –í–æ–ø—Ä–æ—Å—ã –¥–ª—è –ø–æ–Ω–∏–º–∞–Ω–∏—è
    comprehension_questions = [
        {
            "question": f"‰ªäÂ§©Êí≠ÂÆ¢ÁöÑ‰∏ªÈ¢òÊòØ‰ªÄ‰πàÔºü",
            "options": ["Ê±âËØ≠ËØ≠Ê≥ï", topic, "‰∏≠ÂõΩÂéÜÂè≤", "ÊóÖÊ∏∏ÊôØÁÇπ"],
            "correct_answer": 1,
            "explanation": f"‰ªäÂ§©ÁöÑ‰∏ªÈ¢òÊòØÔºö{topic}"
        },
        {
            "question": "‰∏∫‰ªÄ‰πàËøô‰∏™ËØùÈ¢òÂæàÈáçË¶ÅÔºü",
            "options": ["Âõ†‰∏∫ÂæàÁÆÄÂçï", "Âõ†‰∏∫ÊòØÁÉ≠Èó®ËØùÈ¢ò", "Âõ†‰∏∫ÊúâÂä©‰∫éÁêÜËß£‰∏≠ÂõΩÊñáÂåñ", "Âõ†‰∏∫ËÄÅÂ∏àÂñúÊ¨¢"],
            "correct_answer": 2,
            "explanation": "Ëøô‰∏™ËØùÈ¢òÊúâÂä©‰∫éÁêÜËß£‰∏≠ÂõΩÊñáÂåñÂíåÁ§æ‰ºö"
        }
    ]
    
    lesson_id = f"audio_fallback_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
    
    # –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º –ø—Ä–∏–º–µ—Ä–Ω—É—é –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å (–ø—Ä–∏–º–µ—Ä–Ω–æ 150 –∏–µ—Ä–æ–≥–ª–∏—Ñ–æ–≤ –≤ –º–∏–Ω—É—Ç—É)
    estimated_duration = max(120, len(base_text) // 2)
    
    return {
        "id": lesson_id,
        "title": f"Ê±âËØ≠Â≠¶‰π†Êí≠ÂÆ¢Ôºö{topic}",
        "chinese_text": base_text,
        "pinyin_text": None if not request.include_pinyin else "pinyin —Ç–µ–∫—Å—Ç –±—É–¥–µ—Ç –∑–¥–µ—Å—å",
        "translation": None if not request.include_translation else "–ø–µ—Ä–µ–≤–æ–¥ –±—É–¥–µ—Ç –∑–¥–µ—Å—å",
        "vocabulary": vocabulary,
        "comprehension_questions": comprehension_questions,
        "difficulty": request.difficulty,
        "hsk_level": request.hsk_level,
        "estimated_duration": estimated_duration,
        "generated_at": datetime.now().isoformat(),
        "topic": request.topic,
        "description": request.description,
        "ai_generated": False,
        "fallback": True,
        "target_length": request.target_length,
        "character_count": len(base_text),
        "word_count": len(base_text.split()),
        "difficulty_analysis": {
            "grammar_complexity": "—Å—Ä–µ–¥–Ω—è—è" if request.hsk_level <= 3 else "–≤—ã—Å–æ–∫–∞—è",
            "vocabulary_level": f"HSK {request.hsk_level}",
            "speed_recommendation": "0.8x" if request.hsk_level <= 2 else "1.0x"
        },
        "note": "–≠—Ç–æ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –ø–æ–¥–∫–∞—Å—Ç. –î–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –±–æ–ª–µ–µ –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–Ω—Ç–∞ –ø—Ä–æ–≤–µ—Ä—å—Ç–µ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ AI."
    }

def generate_fallback_audio_lesson(request: AudioLessonRequest):
    """Fallback –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –∞—É–¥–∏–æ-—É—Ä–æ–∫–∞"""
    
    # –ë–∞–∑–æ–≤—ã–π —Ç–µ–∫—Å—Ç –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —É—Ä–æ–≤–Ω—è HSK
    base_texts = {
        1: "‰Ω†Â•ΩÔºÅÊàëÊòØ‰Ω†ÁöÑ‰∏≠ÊñáËÄÅÂ∏à„ÄÇ‰ªäÂ§©Êàë‰ª¨Êù•Â≠¶‰π†‰∏≠Êñá„ÄÇ‰∏≠ÊñáÂæàÊúâÊÑèÊÄù„ÄÇ",
        2: "Â§ßÂÆ∂Â•ΩÔºÅÊ¨¢ËøéÊù•Âà∞‰∏≠ÊñáËØæ„ÄÇ‰ªäÂ§©Â§©Ê∞îÂæàÂ•Ω„ÄÇÊàëÊÉ≥ÂéªÂÖ¨Âõ≠Êï£Ê≠•„ÄÇ‰Ω†Âë¢Ôºü",
        3: "ÂêåÂ≠¶‰ª¨Â•ΩÔºÅ‰ªäÂ§©Êàë‰ª¨Ë¶ÅÂ≠¶‰π†ÂÖ≥‰∫é‰∏≠ÂõΩÊñáÂåñÁöÑ‰∏ªÈ¢ò„ÄÇ‰∏≠ÂõΩÊúâÂæàÈïøÁöÑÂéÜÂè≤„ÄÇ‰∏≠ÂõΩÁöÑÈ£üÁâ©ÂæàÂ•ΩÂêÉ„ÄÇ",
        4: "Ê¨¢ËøéÊî∂Âê¨Êàë‰ª¨ÁöÑ‰∏≠ÊñáÊí≠ÂÆ¢ÔºÅ‰ªäÂ§©Êàë‰ª¨Êù•ËÅäËÅä‰∏≠ÂõΩÁöÑ‰º†ÁªüËäÇÊó•„ÄÇÊò•ËäÇÊòØÊúÄÈáçË¶ÅÁöÑËäÇÊó•„ÄÇ",
        5: "Âú®Ëøô‰∏™Êï∞Â≠óÊó∂‰ª£ÔºåÂ≠¶‰π†ËØ≠Ë®ÄÂèòÂæóÊõ¥Âä†ÂÆπÊòì„ÄÇÈÄöËøá‰∫íËÅîÁΩëÔºåÊàë‰ª¨ÂèØ‰ª•Êé•Ëß¶Âà∞‰∏∞ÂØåÁöÑÂ≠¶‰π†ËµÑÊ∫ê„ÄÇ",
        6: "‰∏≠ÂçéÊñáÊòéÊ∫êËøúÊµÅÈïøÔºåÂçöÂ§ßÁ≤æÊ∑±„ÄÇ‰ªéÂè§‰ª£ÁöÑÂõõÂ§ßÂèëÊòéÂà∞Áé∞‰ª£ÁöÑÁßëÊäÄÂàõÊñ∞Ôºå‰∏≠ÂõΩ‰∏ÄÁõ¥Âú®‰∏∫‰∏ñÁïåÂÅöÂá∫Ë¥°ÁåÆ„ÄÇ"
    }
    
    base_text = base_texts.get(request.hsk_level, base_texts[3])
    
    # –î–æ–±–∞–≤–ª—è–µ–º —Ç–µ–º—É –≤ —Ç–µ–∫—Å—Ç
    chinese_text = f"‰ªäÂ§©ÁöÑËØùÈ¢òÊòØÔºö{request.topic}„ÄÇ{base_text} Â∏åÊúõ‰Ω†ÂñúÊ¨¢Ëøô‰∏™ÂÜÖÂÆπ„ÄÇÂÜçËßÅÔºÅ"
    
    # –ë–∞–∑–æ–≤–∞—è –ª–µ–∫—Å–∏–∫–∞
    vocabulary = [
        {
            "chinese": "ËØùÈ¢ò",
            "pinyin": "hu√†t√≠", 
            "translation": "—Ç–µ–º–∞",
            "example": "‰ªäÂ§©ÁöÑËØùÈ¢òÂæàÊúâÊÑèÊÄù„ÄÇ"
        },
        {
            "chinese": "Â≠¶‰π†",
            "pinyin": "xu√©x√≠",
            "translation": "—É—á–∏—Ç—å—Å—è",
            "example": "ÊàëÂñúÊ¨¢Â≠¶‰π†‰∏≠Êñá„ÄÇ"
        }
    ]
    
    lesson_id = f"audio_fallback_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
    
    return {
        "id": lesson_id,
        "title": f"–ê—É–¥–∏–æ-—É—Ä–æ–∫: {request.topic}",
        "chinese_text": chinese_text,
        "pinyin_text": None,
        "translation": f"–¢–µ–º–∞ —Å–µ–≥–æ–¥–Ω—è: {request.topic}. {base_text} –ù–∞–¥–µ—é—Å—å, –≤–∞–º –ø–æ–Ω—Ä–∞–≤–∏—Ç—Å—è —ç—Ç–æ—Ç –∫–æ–Ω—Ç–µ–Ω—Ç. –î–æ —Å–≤–∏–¥–∞–Ω–∏—è!",
        "vocabulary": vocabulary,
        "difficulty": request.difficulty,
        "hsk_level": request.hsk_level,
        "estimated_duration": len(chinese_text) * 0.5,  # ~0.5 —Å–µ–∫ –Ω–∞ –∏–µ—Ä–æ–≥–ª–∏—Ñ
        "generated_at": datetime.now().isoformat(),
        "topic": request.topic,
        "ai_generated": False,
        "fallback": True,
        "speech_rate": 1.0,
        "word_count": len(chinese_text.split()),
        "character_count": len(chinese_text.replace(" ", "")),
        "study_questions": [
            "–ö–∞–∫–æ–≤–∞ –æ—Å–Ω–æ–≤–Ω–∞—è —Ç–µ–º–∞ —ç—Ç–æ–≥–æ —É—Ä–æ–∫–∞?",
            "–ö–∞–∫–∏–µ –Ω–æ–≤—ã–µ —Å–ª–æ–≤–∞ –≤—ã —É—Å–ª—ã—à–∞–ª–∏?"
        ]
    }

class WordStatus(BaseModel):
    user_id: str
    word_id: str          # —Ñ–æ—Ä–º–∞—Ç: "‰Ω†Â•Ω_1"
    status: str           # "saved" –∏–ª–∏ "learned"

class WordTestRequest(BaseModel):
    user_id: str
    source: str = "all"          # "all", "saved", "learned"
    count: int = 20
    test_type: str               # "pinyin_from_char", "char_from_pinyin", "translation_from_char", "translation_from_pinyin"

class WordTestSubmit(BaseModel):
    user_id: str
    test_id: str
    answers: Dict[str, str]      # question_id -> –æ—Ç–≤–µ—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è

@app.post("/words/status")
async def set_word_status(request: WordStatus):
    user_id = request.user_id
    if user_id not in user_word_status:
        user_word_status[user_id] = {}
    
    user_word_status[user_id][request.word_id] = {
        "status": request.status,
        "added_at": datetime.now().isoformat()
    }
    save_user_data()
    return {"success": True}

@app.post("/words/test/generate")
async def generate_word_test(req: WordTestRequest):
    # –ü–æ–ª—É—á–∞–µ–º –ø—É–ª —Å–ª–æ–≤
    if req.source == "all":
        all_words = []
        for level in range(1, 7):
            all_words.extend(words_db.get(level, []))
    else:
        if req.user_id not in user_word_status:
            raise HTTPException(404, "–ù–µ—Ç —Å–æ—Ö—Ä–∞–Ω—ë–Ω–Ω—ã—Ö/–∏–∑—É—á–µ–Ω–Ω—ã—Ö —Å–ª–æ–≤")
        word_ids = [wid for wid, data in user_word_status[req.user_id].items() if data["status"] == req.source]
        all_words = []
        for wid in word_ids:
            char, lvl = wid.rsplit("_", 1)
            level = int(lvl)
            for w in words_db.get(level, []):
                if w["character"] == char:
                    all_words.append(w)
                    break

    if len(all_words) == 0:
        raise HTTPException(400, "–ù–µ—Ç —Å–ª–æ–≤ –¥–ª—è —Ç–µ—Å—Ç–∞")

    if req.count > len(all_words):
        req.count = len(all_words)
    selected = random.sample(all_words, req.count)

    questions = []
    for i, word in enumerate(selected):
        q = {
            "id": str(i),
            "character": word["character"],
            "pinyin": word["pinyin"],
            "translation": word["translation"]
        }
        if req.test_type == "pinyin_from_char":
            q["prompt"] = f"–ü–∏–Ω—å–∏–Ω—å –¥–ª—è: {word['character']}"
            q["correct"] = word["pinyin"]
        elif req.test_type == "char_from_pinyin":
            q["prompt"] = f"–ò–µ—Ä–æ–≥–ª–∏—Ñ—ã –¥–ª—è: {word['pinyin']}"
            q["correct"] = word["character"]
        elif req.test_type == "translation_from_char":
            q["prompt"] = f"–ü–µ—Ä–µ–≤–æ–¥ –¥–ª—è: {word['character']}"
            q["correct"] = word["translation"]
        elif req.test_type == "translation_from_pinyin":
            q["prompt"] = f"–ü–µ—Ä–µ–≤–æ–¥ –¥–ª—è: {word['pinyin']}"
            q["correct"] = word["translation"]
        else:
            raise HTTPException(400, "–ù–µ–≤–µ—Ä–Ω—ã–π test_type")
        questions.append(q)

    test_id = f"word_{req.user_id}_{datetime.now().timestamp()}"
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∞–∫—Ç–∏–≤–Ω—ã–π —Ç–µ—Å—Ç –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –ø–æ–∑–∂–µ
    tests_db[f"active_word_test_{req.user_id}"] = {
        "test_id": test_id,
        "questions": questions,
        "generated_at": datetime.now().isoformat()
    }

    return {"test_id": test_id, "questions": questions, "total": len(questions)}

@app.post("/words/test/submit")
async def submit_word_test(submit: WordTestSubmit):
    test_key = f"active_word_test_{submit.user_id}"
    if test_key not in tests_db or tests_db[test_key].get("test_id") != submit.test_id:
        raise HTTPException(status_code=404, detail="–¢–µ—Å—Ç –Ω–µ –Ω–∞–π–¥–µ–Ω –∏–ª–∏ —É–∂–µ –∑–∞–≤–µ—Ä—à—ë–Ω")

    test = tests_db[test_key]
    questions = test["questions"]

    correct = 0
    total = len(questions)
    results = []

    for q in questions:
        qid = q["id"]
        correct_ans = q["correct"].strip().lower()

        user_answer_raw = submit.answers.get(qid)

        # –Ø–í–ù–û: –µ—Å–ª–∏ –Ω–µ—Ç –æ—Ç–≤–µ—Ç–∞ –∏–ª–∏ –ø—É—Å—Ç–∞—è —Å—Ç—Ä–æ–∫–∞ ‚Äî –ù–ï–í–ï–†–ù–û
        if user_answer_raw is None or user_answer_raw.strip() == "":
            is_correct = False
            user_display = "(–Ω–µ –æ—Ç–≤–µ—á–µ–Ω–æ)"
        else:
            user_normalized = user_answer_raw.strip().lower()
            is_correct = user_normalized == correct_ans
            user_display = user_answer_raw

        if is_correct:
            correct += 1

        results.append({
            "id": qid,
            "prompt": q["prompt"],
            "user_answer": user_display,
            "correct_answer": q["correct"],
            "correct": is_correct
        })

    percentage = round(correct / total * 100, 1) if total > 0 else 0

    message = f"{correct} –∏–∑ {total} –ø—Ä–∞–≤–∏–ª—å–Ω—ã—Ö ({percentage}%)"
    if percentage >= 90:
        message += " –û—Ç–ª–∏—á–Ω–æ! –í—ã —Ö–æ—Ä–æ—à–æ –∑–Ω–∞–µ—Ç–µ —ç—Ç–∏ —Å–ª–æ–≤–∞!"
    elif percentage >= 70:
        message += " –ù–µ–ø–ª–æ—Ö–æ, –Ω–æ –º–æ–∂–Ω–æ –ª—É—á—à–µ."
    else:
        message += " –ù—É–∂–Ω–æ –±–æ–ª—å—à–µ –ø—Ä–∞–∫—Ç–∏–∫–æ–≤–∞—Ç—å—Å—è!"

    return {
        "correct": correct,
        "total": total,
        "percentage": percentage,
        "message": message,
        "results": results
    }

class WordTestAIRequest(BaseModel):
    user_id: str
    test_id: str
    questions: List[Dict[str, Any]]  # [{id, prompt, correct, ...}]
    answers: Dict[str, str]          # {question_id: user_answer}

@app.post("/words/test/check-ai")
async def check_word_test_ai(request: WordTestAIRequest):
    """–ò–ò –ø—Ä–æ–≤–µ—Ä—è–µ—Ç —Ç–µ—Å—Ç –Ω–∞ –∑–Ω–∞–Ω–∏–µ —Å–ª–æ–≤"""
    try:
        client = get_deepseek_client()
        if not client:
            raise HTTPException(status_code=503, detail="AI —Å–µ—Ä–≤–∏—Å –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω")

        # –§–æ—Ä–º–∏—Ä—É–µ–º –ø—Ä–æ–º–ø—Ç –¥–ª—è –ò–ò
        system_prompt = """–¢—ã ‚Äî —Å—Ç—Ä–æ–≥–∏–π –∏ —Ç–æ—á–Ω—ã–π –ø—Ä–µ–ø–æ–¥–∞–≤–∞—Ç–µ–ª—å –∫–∏—Ç–∞–π—Å–∫–æ–≥–æ —è–∑—ã–∫–∞.
–¢–≤–æ—è –∑–∞–¥–∞—á–∞: –ø—Ä–æ–≤–µ—Ä–∏—Ç—å –æ—Ç–≤–µ—Ç—ã —Å—Ç—É–¥–µ–Ω—Ç–∞ –Ω–∞ —Ç–µ—Å—Ç –ø–æ –∫–∏—Ç–∞–π—Å–∫–∏–º —Å–ª–æ–≤–∞–º.

–ü–†–ê–í–ò–õ–ê –ü–†–û–í–ï–†–ö–ò:
1. –£—á–∏—Ç—ã–≤–∞–π —Å–∏–Ω–æ–Ω–∏–º—ã –∏ –±–ª–∏–∑–∫–∏–µ –ø–æ —Å–º—ã—Å–ª—É –æ—Ç–≤–µ—Ç—ã
2. –î–ª—è –ø–∏–Ω—å–∏–Ω—è: –∏–≥–Ω–æ—Ä–∏—Ä—É–π —Ç–æ–Ω—ã –∏ –ø—Ä–æ–±–µ–ª—ã (n«êh«éo = nihao = n«ê h«éo)
3. –î–ª—è –ø–µ—Ä–µ–≤–æ–¥–∞: –¥–æ–ø—É—Å–∫–∞–π –≤–∞—Ä–∏–∞–Ω—Ç—ã –ø–µ—Ä–µ–≤–æ–¥–∞, –µ—Å–ª–∏ —Å–º—ã—Å–ª —Å–æ—Ö—Ä–∞–Ω—ë–Ω
4. –ü—É—Å—Ç–æ–π –æ—Ç–≤–µ—Ç ‚Äî –≤—Å–µ–≥–¥–∞ –ù–ï–í–ï–†–ù–û
5. –ë—É–¥—å –æ–±—ä–µ–∫—Ç–∏–≤–Ω—ã–º, –Ω–æ —Å–ø—Ä–∞–≤–µ–¥–ª–∏–≤—ã–º

–§–û–†–ú–ê–¢ –û–¢–í–ï–¢–ê ‚Äî –¢–û–õ–¨–ö–û JSON:
{
    "correct_count": 12,
    "total": 15,
    "percentage": 80,
    "results": [
        {
            "id": "0",
            "prompt": "–ü–∏–Ω—å–∏–Ω—å –¥–ª—è: ‰Ω†Â•Ω",
            "user_answer": "nihao",
            "correct_answer": "n«ê h«éo",
            "is_correct": true,
            "feedback": "–ü—Ä–∞–≤–∏–ª—å–Ω–æ! –¢–æ–Ω—ã –º–æ–∂–Ω–æ –æ–ø—É—Å—Ç–∏—Ç—å –≤ —Ç–µ—Å—Ç–µ."
        },
        {
            "id": "1",
            "prompt": "–ü–µ—Ä–µ–≤–æ–¥ –¥–ª—è: Ë∞¢Ë∞¢",
            "user_answer": "–ø–æ–∂–∞–ª—É–π—Å—Ç–∞",
            "correct_answer": "—Å–ø–∞—Å–∏–±–æ",
            "is_correct": false,
            "feedback": "–ù–µ–≤–µ—Ä–Ω–æ. Ë∞¢Ë∞¢ = —Å–ø–∞—Å–∏–±–æ. '–ü–æ–∂–∞–ª—É–π—Å—Ç–∞' = ËØ∑ –∏–ª–∏ ‰∏çÂÆ¢Ê∞î."
        }
    ],
    "summary": "–•–æ—Ä–æ—à–∏–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç! –û—Å–Ω–æ–≤–Ω—ã–µ –æ—à–∏–±–∫–∏ ‚Äî –≤ –ø–µ—Ä–µ–≤–æ–¥–µ –≤–µ–∂–ª–∏–≤—ã—Ö –≤—ã—Ä–∞–∂–µ–Ω–∏–π."
}"""

        # –§–æ—Ä–º–∏—Ä—É–µ–º —Å–ø–∏—Å–æ–∫ –≤–æ–ø—Ä–æ—Å–æ–≤ —Å –æ—Ç–≤–µ—Ç–∞–º–∏
        questions_text = ""
        for q in request.questions:
            user_ans = request.answers.get(q["id"], "(–Ω–µ –æ—Ç–≤–µ—á–µ–Ω–æ)")
            questions_text += f"""
–í–æ–ø—Ä–æ—Å {q['id']}: {q['prompt']}
–ü—Ä–∞–≤–∏–ª—å–Ω—ã–π –æ—Ç–≤–µ—Ç: {q['correct']}
–û—Ç–≤–µ—Ç —Å—Ç—É–¥–µ–Ω—Ç–∞: {user_ans}
"""

        user_prompt = f"""–ü—Ä–æ–≤–µ—Ä—å –æ—Ç–≤–µ—Ç—ã —Å—Ç—É–¥–µ–Ω—Ç–∞.

–í–æ–ø—Ä–æ—Å—ã –∏ –æ—Ç–≤–µ—Ç—ã:
{questions_text}

–û—Ü–µ–Ω–∏ –∫–∞–∂–¥—ã–π –æ—Ç–≤–µ—Ç –∏ –¥–∞–π –æ–±—â–∏–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç."""

        messages = [
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": user_prompt}
        ]

        response = client.chat.completions.create(
            model="deepseek-chat",
            messages=messages,
            temperature=0.3,
            max_tokens=2000,
            response_format={"type": "json_object"}
        )

        try:
            result = json.loads(response.choices[0].message.content)
        except json.JSONDecodeError:
            # Fallback –Ω–∞ —Å–ª—É—á–∞–π, –µ—Å–ª–∏ –ò–ò –Ω–µ –≤–µ—Ä–Ω—É–ª JSON
            result = fallback_word_test_check(request.questions, request.answers)

        return result

    except Exception as e:
        print(f"–û—à–∏–±–∫–∞ –ò–ò-–ø—Ä–æ–≤–µ—Ä–∫–∏ —Ç–µ—Å—Ç–∞ —Å–ª–æ–≤: {e}")
        # –í—Å–µ–≥–¥–∞ –≤–æ–∑–≤—Ä–∞—â–∞–µ–º fallback
        return fallback_word_test_check(request.questions, request.answers)

def fallback_word_test_check(questions, answers):
    """–†–µ–∑–µ—Ä–≤–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞, –µ—Å–ª–∏ –ò–ò –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω"""
    correct = 0
    total = len(questions)
    results = []

    for q in questions:
        qid = q["id"]
        user_raw = answers.get(qid, "")
        user_answer = user_raw.strip().lower() if user_raw else ""

        correct_ans = q["correct"].strip().lower()

        # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –ø–∏–Ω—å–∏–Ω—è
        if "–ø–∏–Ω—å–∏–Ω—å" in q["prompt"].lower():
            user_answer = user_answer.replace(" ", "").replace("v", "√º")
            correct_ans = correct_ans.replace(" ", "").replace("v", "√º")

        is_correct = bool(user_answer and user_answer == correct_ans)

        if is_correct:
            correct += 1

        results.append({
            "id": qid,
            "prompt": q["prompt"],
            "user_answer": user_raw.strip() if user_raw else "(–Ω–µ –æ—Ç–≤–µ—á–µ–Ω–æ)",
            "correct_answer": q["correct"],
            "is_correct": is_correct,
            "feedback": "–ü—Ä–∞–≤–∏–ª—å–Ω–æ!" if is_correct else "–ù–µ–≤–µ—Ä–Ω–æ. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –æ—Ç–≤–µ—Ç." if user_answer else "–û—Ç–≤–µ—Ç –Ω–µ –¥–∞–Ω ‚Äî —Å—á–∏—Ç–∞–µ—Ç—Å—è –Ω–µ–≤–µ—Ä–Ω—ã–º."
        })

    percentage = round(correct / total * 100, 1) if total > 0 else 0

    return {
        "correct_count": correct,
        "total": total,
        "percentage": percentage,
        "results": results,
        "summary": f"{correct}/{total} –ø—Ä–∞–≤–∏–ª—å–Ω—ã—Ö ({percentage}%). {'–û—Ç–ª–∏—á–Ω–æ!' if percentage >= 90 else '–•–æ—Ä–æ—à–æ!' if percentage >= 70 else '–ü—Ä–∞–∫—Ç–∏–∫—É–π—Ç–µ—Å—å –±–æ–ª—å—à–µ!'}"
    }

@app.get("/user/progress/{user_id}")
async def get_user_progress(user_id: str):
    if user_id not in users_db:
        raise HTTPException(404, "–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –Ω–µ –Ω–∞–π–¥–µ–Ω")
    
    user = users_db[user_id]
    target = user.get("target_level", 4)
    
    total_words = sum(len(words_db.get(l, [])) for l in range(1, target + 1))
    learned = 0
    if user_id in user_word_status:
        learned = sum(1 for v in user_word_status[user_id].values() if v["status"] == "learned")
    
    percentage = round(learned / total_words * 100, 1) if total_words > 0 else 0
    
    return {
        "learned": learned,
        "total": total_words,
        "percentage": percentage,
        "target_level": target
    }

# –ó–∞–≥—Ä—É–∑–∫–∞ —Å–æ—Ö—Ä–∞–Ω—ë–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –ø—Ä–∏ –∑–∞–ø—É—Å–∫–µ
try:
    with open("data.pkl", "rb") as f:
        loaded = pickle.load(f)
        globals().update(loaded)
except FileNotFoundError:
    pass

# ========== –ó–ê–ü–£–°–ö –°–ï–†–í–ï–†–ê ==========
if __name__ == "__main__":
    print("=" * 60)
    print("üéå HSK AI Tutor - –ü—Ä–∞–≥–º–∞—Ç–∏—á–Ω—ã–π —Ä–µ–ø–µ—Ç–∏—Ç–æ—Ä")
    print("=" * 60)
    print(f"üìö –ë–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö: {len(words_db)} —Å–ª–æ–≤ HSK 1-6")
    print(f"üë• –ó–∞—Ä–µ–≥–∏—Å—Ç—Ä–∏—Ä–æ–≤–∞–Ω–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π: {len(users_db)}")
    print(f"üß™ –°–æ–∑–¥–∞–Ω–æ —Ç–µ—Å—Ç–æ–≤: {len(tests_db)}")
    print("=" * 60)
    print("üöÄ –ó–∞–ø—É—Å–∫–∞—é —Å–µ—Ä–≤–µ—Ä –Ω–∞ http://localhost:8000")
    print("üìö –î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è: http://localhost:8000/docs")
    print("üåê –§—Ä–æ–Ω—Ç–µ–Ω–¥: –æ—Ç–∫—Ä–æ–π frontend.html –≤ –±—Ä–∞—É–∑–µ—Ä–µ")
    print("=" * 60)
    
    uvicorn.run(
        app,
        host="0.0.0.0",
        port=8000,
        reload=True  # –ê–≤—Ç–æ–ø–µ—Ä–µ–∑–∞–≥—Ä—É–∑–∫–∞ –ø—Ä–∏ –∏–∑–º–µ–Ω–µ–Ω–∏—è—Ö
    )